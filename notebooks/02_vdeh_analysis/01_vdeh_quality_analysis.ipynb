{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3892be9b",
   "metadata": {},
   "source": [
    "# VDEH Missing Values Analyse\n",
    "\n",
    "**Fokus:** Identifikation l√ºckenbehafteter Spalten und Vollst√§ndigkeits-Statistiken\n",
    "\n",
    "## üéØ Ziel\n",
    "- Schneller √úberblick √ºber fehlende Werte pro Spalte\n",
    "- Vollst√§ndigkeits-Score pro Record\n",
    "- Visualisierung der L√ºcken-Verteilung\n",
    "\n",
    "## üìö Input/Output\n",
    "- **Input**: `data/vdeh/processed/03_language_detected_data.parquet`\n",
    "- **Output**: `data/vdeh/processed/04_quality_analyzed_data.parquet` (mit Quality Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9558dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Konfiguration geladen: /media/sz/Data/Bibo/analysis/config.yaml\n",
      "üìÅ Projektroot: /media/sz/Data/Bibo/analysis\n",
      "‚úÖ Konfiguration geladen\n",
      "üìä Matplotlib konfiguriert: [12, 8]\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è SETUP UND DATEN LADEN\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Projektroot finden\n",
    "current_dir = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "for parent in [current_dir] + list(current_dir.parents):\n",
    "    if (parent / 'config.yaml').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise FileNotFoundError(\"config.yaml nicht gefunden!\")\n",
    "\n",
    "# Config laden\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "from config_loader import load_config\n",
    "config = load_config(project_root / 'config.yaml')\n",
    "\n",
    "# Matplotlib konfigurieren\n",
    "plt.rcParams['figure.figsize'] = config.get('visualization.matplotlib.figure_size', [12, 8])\n",
    "plt.rcParams['figure.dpi'] = config.get('visualization.matplotlib.dpi', 100)\n",
    "\n",
    "if not config.get('debug.verbose_output', True):\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"üìÅ Projektroot: {project_root}\")\n",
    "print(\"‚úÖ Konfiguration geladen\")\n",
    "print(f\"üìä Matplotlib konfiguriert: {config.get('visualization.matplotlib.figure_size')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d9dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Daten geladen aus: /media/sz/Data/Bibo/analysis/data/vdeh/processed/03_language_detected_data.parquet\n",
      "üìä Records: 58,760\n",
      "üìã Spalten: ['id', 'title', 'authors', 'authors_affiliation', 'year', 'publisher', 'isbn', 'issn', 'authors_str', 'num_authors', 'authors_affiliation_str', 'num_authors_affiliation', 'isbn_valid', 'isbn_status', 'issn_valid', 'issn_status', 'lang_code', 'lang_confidence', 'lang_name']\n",
      "üìÖ Vorherige Verarbeitung: 2025-11-05T07:37:03.330582\n",
      "üåç Sprach-Analyse: 40,544 Titel analysiert\n"
     ]
    }
   ],
   "source": [
    "# üìÇ DATEN AUS VORHERIGER STUFE LADEN\n",
    "processed_dir = config.project_root / config.get('paths.data.vdeh.processed')\n",
    "input_path = processed_dir / '03_language_detected_data.parquet'\n",
    "metadata_path = processed_dir / '03_metadata.json'\n",
    "\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Input-Datei nicht gefunden: {input_path}\\n\"\n",
    "                          \"Bitte f√ºhren Sie zuerst 03_vdeh_language_detection.ipynb aus.\")\n",
    "\n",
    "# Daten laden\n",
    "df_vdeh = pd.read_parquet(input_path)\n",
    "\n",
    "# Vorherige Metadaten laden\n",
    "with open(metadata_path, 'r') as f:\n",
    "    prev_metadata = json.load(f)\n",
    "\n",
    "print(f\"üìÇ Daten geladen aus: {input_path}\")\n",
    "print(f\"üìä Records: {len(df_vdeh):,}\")\n",
    "print(f\"üìã Spalten: {list(df_vdeh.columns)}\")\n",
    "print(f\"üìÖ Vorherige Verarbeitung: {prev_metadata['processing_date']}\")\n",
    "print(f\"üåç Sprach-Analyse: {prev_metadata['language_analysis']['total_titles_analyzed']:,} Titel analysiert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a158af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç === MISSING VALUES ANALYSE ===\n",
      "\n",
      "üìä Fehlende Werte pro Spalte (von 58,760 Records):\n",
      "\n",
      "üî¥ issn                   721 ‚úì   58,039 ‚úó   98.8% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "üî¥ isbn                11,415 ‚úì   47,345 ‚úó   80.6% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "üî¥ authors_str         17,011 ‚úì   41,749 ‚úó   71.1% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "üî¥ publisher           23,553 ‚úì   35,207 ‚úó   59.9% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "üü° year                33,687 ‚úì   25,073 ‚úó   42.7% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "üü° title               40,830 ‚úì   17,930 ‚úó   30.5% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n"
     ]
    }
   ],
   "source": [
    "# üîç MISSING VALUES ANALYSE\n",
    "print(\"üîç === MISSING VALUES ANALYSE ===\\n\")\n",
    "\n",
    "# Relevante Spalten f√ºr Analyse\n",
    "analysis_cols = ['title', 'authors_str', 'year', 'publisher', 'isbn', 'issn']\n",
    "\n",
    "# Nur vorhandene Spalten verwenden\n",
    "available_cols = [col for col in analysis_cols if col in df_vdeh.columns]\n",
    "\n",
    "print(f\"üìä Fehlende Werte pro Spalte (von {len(df_vdeh):,} Records):\\n\")\n",
    "\n",
    "# Erstelle √úbersicht sortiert nach Missing Rate\n",
    "missing_stats = []\n",
    "for col in available_cols:\n",
    "    # Spezialbehandlung f√ºr authors_str: auch leere Strings als fehlend betrachten\n",
    "    if col == 'authors_str':\n",
    "        missing_count = (df_vdeh[col].isna() | (df_vdeh[col] == '')).sum()\n",
    "    else:\n",
    "        missing_count = df_vdeh[col].isna().sum()\n",
    "    \n",
    "    missing_pct = (missing_count / len(df_vdeh)) * 100\n",
    "    present_count = len(df_vdeh) - missing_count\n",
    "    missing_stats.append({\n",
    "        'Spalte': col,\n",
    "        'Vorhanden': present_count,\n",
    "        'Fehlend': missing_count,\n",
    "        'Fehlend %': missing_pct\n",
    "    })\n",
    "\n",
    "# Sortiere nach Fehlend %\n",
    "missing_df = pd.DataFrame(missing_stats).sort_values('Fehlend %', ascending=False)\n",
    "\n",
    "# Ausgabe als formatierte Tabelle\n",
    "for _, row in missing_df.iterrows():\n",
    "    bar_length = int(row['Fehlend %'] / 2)  # Balken bis 50 Zeichen\n",
    "    bar = '‚ñà' * bar_length\n",
    "    status = 'üî¥' if row['Fehlend %'] > 50 else 'üü°' if row['Fehlend %'] > 20 else 'üü¢'\n",
    "    print(f\"{status} {row['Spalte']:18} {row['Vorhanden']:7,} ‚úì  {row['Fehlend']:7,} ‚úó  {row['Fehlend %']:5.1f}% {bar}\")\n",
    "\n",
    "# Berechne Vollst√§ndigkeits-Score pro Record\n",
    "# Erstelle Missing Matrix mit Spezialbehandlung f√ºr authors_str\n",
    "missing_matrix = df_vdeh[available_cols].isnull()\n",
    "\n",
    "# F√ºr authors_str: leere Strings auch als fehlend markieren\n",
    "if 'authors_str' in available_cols:\n",
    "    missing_matrix['authors_str'] = df_vdeh['authors_str'].isna() | (df_vdeh['authors_str'] == '')\n",
    "\n",
    "completeness_scores = (1 - missing_matrix.mean(axis=1)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "152f2297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç === L√úCKEN BEI DATENS√ÑTZEN MIT ISBN/ISSN ===\n",
      "\n",
      "üìö Datens√§tze mit ISBN: 11,415\n",
      "\n",
      "   Fehlende Autoren:   3,423 ( 30.0%)\n",
      "   Fehlender Verlag:   1,252 ( 11.0%)\n",
      "   Fehlendes Jahr:       879 (  7.7%)\n",
      "\n",
      "   ‚ö†Ô∏è  Mind. 1 Feld fehlt:  3,734 ( 32.7%)\n",
      "   ‚úÖ Alle Felder da:      7,681 ( 67.3%)\n",
      "\n",
      "üì∞ Datens√§tze mit ISSN: 721\n",
      "\n",
      "   Fehlende Autoren:     667 ( 92.5%)\n",
      "   Fehlender Verlag:      20 (  2.8%)\n",
      "   Fehlendes Jahr:       650 ( 90.2%)\n",
      "\n",
      "   ‚ö†Ô∏è  Mind. 1 Feld fehlt:    680 ( 94.3%)\n",
      "   ‚úÖ Alle Felder da:         41 (  5.7%)\n"
     ]
    }
   ],
   "source": [
    "# üîç ANALYSE: L√úCKEN BEI DATENS√ÑTZEN MIT ISBN/ISSN\n",
    "print(\"\\nüîç === L√úCKEN BEI DATENS√ÑTZEN MIT ISBN/ISSN ===\\n\")\n",
    "\n",
    "# Datens√§tze mit ISBN\n",
    "has_isbn = df_vdeh['isbn'].notna()\n",
    "isbn_count = has_isbn.sum()\n",
    "\n",
    "if isbn_count > 0:\n",
    "    print(f\"üìö Datens√§tze mit ISBN: {isbn_count:,}\\n\")\n",
    "    \n",
    "    # Pr√ºfe fehlende Felder bei ISBN-Datens√§tzen\n",
    "    isbn_records = df_vdeh[has_isbn]\n",
    "    \n",
    "    missing_authors_isbn = (isbn_records['authors_str'].isna() | (isbn_records['authors_str'] == '')).sum()\n",
    "    missing_publisher_isbn = isbn_records['publisher'].isna().sum()\n",
    "    missing_year_isbn = isbn_records['year'].isna().sum()\n",
    "    \n",
    "    print(f\"   Fehlende Autoren:  {missing_authors_isbn:6,} ({missing_authors_isbn/isbn_count*100:5.1f}%)\")\n",
    "    print(f\"   Fehlender Verlag:  {missing_publisher_isbn:6,} ({missing_publisher_isbn/isbn_count*100:5.1f}%)\")\n",
    "    print(f\"   Fehlendes Jahr:    {missing_year_isbn:6,} ({missing_year_isbn/isbn_count*100:5.1f}%)\")\n",
    "    \n",
    "    # Mindestens ein Feld fehlt\n",
    "    any_missing_isbn = (\n",
    "        (isbn_records['authors_str'].isna() | (isbn_records['authors_str'] == '')) |\n",
    "        isbn_records['publisher'].isna() |\n",
    "        isbn_records['year'].isna()\n",
    "    ).sum()\n",
    "    \n",
    "    print(f\"\\n   ‚ö†Ô∏è  Mind. 1 Feld fehlt: {any_missing_isbn:6,} ({any_missing_isbn/isbn_count*100:5.1f}%)\")\n",
    "    print(f\"   ‚úÖ Alle Felder da:     {isbn_count - any_missing_isbn:6,} ({(isbn_count - any_missing_isbn)/isbn_count*100:5.1f}%)\")\n",
    "\n",
    "# Datens√§tze mit ISSN\n",
    "has_issn = df_vdeh['issn'].notna()\n",
    "issn_count = has_issn.sum()\n",
    "\n",
    "if issn_count > 0:\n",
    "    print(f\"\\nüì∞ Datens√§tze mit ISSN: {issn_count:,}\\n\")\n",
    "    \n",
    "    # Pr√ºfe fehlende Felder bei ISSN-Datens√§tzen\n",
    "    issn_records = df_vdeh[has_issn]\n",
    "    \n",
    "    missing_authors_issn = (issn_records['authors_str'].isna() | (issn_records['authors_str'] == '')).sum()\n",
    "    missing_publisher_issn = issn_records['publisher'].isna().sum()\n",
    "    missing_year_issn = issn_records['year'].isna().sum()\n",
    "    \n",
    "    print(f\"   Fehlende Autoren:  {missing_authors_issn:6,} ({missing_authors_issn/issn_count*100:5.1f}%)\")\n",
    "    print(f\"   Fehlender Verlag:  {missing_publisher_issn:6,} ({missing_publisher_issn/issn_count*100:5.1f}%)\")\n",
    "    print(f\"   Fehlendes Jahr:    {missing_year_issn:6,} ({missing_year_issn/issn_count*100:5.1f}%)\")\n",
    "    \n",
    "    # Mindestens ein Feld fehlt\n",
    "    any_missing_issn = (\n",
    "        (issn_records['authors_str'].isna() | (issn_records['authors_str'] == '')) |\n",
    "        issn_records['publisher'].isna() |\n",
    "        issn_records['year'].isna()\n",
    "    ).sum()\n",
    "    \n",
    "    print(f\"\\n   ‚ö†Ô∏è  Mind. 1 Feld fehlt: {any_missing_issn:6,} ({any_missing_issn/issn_count*100:5.1f}%)\")\n",
    "    print(f\"   ‚úÖ Alle Felder da:     {issn_count - any_missing_issn:6,} ({(issn_count - any_missing_issn)/issn_count*100:5.1f}%)\")\n",
    "\n",
    "# Datens√§tze mit ISBN ODER ISSN\n",
    "has_isbn_or_issn = has_isbn | has_issn\n",
    "isbn_or_issn_count = has_isbn_or_issn.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc783b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibo-analysis-DoEGeq_l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
