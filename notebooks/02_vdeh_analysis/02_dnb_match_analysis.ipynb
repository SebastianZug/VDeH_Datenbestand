{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# DNB Match-Analyse\n",
    "\n",
    "**Zweck:** Analyse warum DNB-Abgleiche fehlschlagen\n",
    "\n",
    "## Fragestellungen\n",
    "1. Warum werden DNB-Matches abgelehnt?\n",
    "2. Welche Muster gibt es bei nicht gefundenen Records?\n",
    "3. Wie können wir die Match-Rate verbessern?\n",
    "\n",
    "## Analyse-Bereiche\n",
    "- Abgelehnte DNB-Matches (KI-Entscheidung: falsches Buch)\n",
    "- Nicht gefundene Records bei ISBN/ISSN-Suche\n",
    "- Nicht gefundene Records bei Titel/Autor-Suche\n",
    "- Vergleich der Datenqualität zwischen erfolgreichen und fehlgeschlagenen Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup und Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Project setup\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / 'config.yaml').exists() and project_root.parent != project_root:\n",
    "    project_root = project_root.parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from utils.notebook_utils import setup_notebook\n",
    "project_root, config = setup_notebook()\n",
    "\n",
    "# Paths\n",
    "processed_dir = config.project_root / config.get('paths.data.vdeh.processed')\n",
    "\n",
    "print(f\"Project: {config.get('project.name')}\")\n",
    "print(f\"Data: {processed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "print(\"Lade Daten...\\n\")\n",
    "\n",
    "# Fused data (mit KI-Entscheidungen)\n",
    "df_fused = pd.read_parquet(processed_dir / '05_fused_data.parquet')\n",
    "\n",
    "# Original data (vor Enrichment)\n",
    "df_original = pd.read_parquet(processed_dir / '03_language_detected_data.parquet')\n",
    "\n",
    "# DNB Raw data (ISBN/ISSN Queries)\n",
    "df_dnb_raw = pd.read_parquet(processed_dir / 'dnb_raw_data.parquet')\n",
    "\n",
    "# DNB Title/Author data\n",
    "df_dnb_ta = pd.read_parquet(processed_dir / 'dnb_title_author_data.parquet')\n",
    "\n",
    "print(f\"Fused: {len(df_fused):,} records\")\n",
    "print(f\"Original: {len(df_original):,} records\")\n",
    "print(f\"DNB ISBN/ISSN: {len(df_dnb_raw):,} queries\")\n",
    "print(f\"DNB Titel/Autor: {len(df_dnb_ta):,} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-overview",
   "metadata": {},
   "source": [
    "## 1. Übersicht: Wo schlägt der Abgleich fehl?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overview-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht der Fehlschläge\n",
    "print(\"=\" * 60)\n",
    "print(\"ÜBERSICHT: FEHLGESCHLAGENE ABGLEICHE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. DNB ISBN/ISSN nicht gefunden\n",
    "isbn_not_found = (~df_dnb_raw['dnb_found']).sum()\n",
    "isbn_total = len(df_dnb_raw)\n",
    "print(f\"\\n1. ISBN/ISSN-Suche nicht gefunden: {isbn_not_found:,} / {isbn_total:,} ({isbn_not_found/isbn_total*100:.1f}%)\")\n",
    "\n",
    "# 2. DNB Titel/Autor nicht gefunden\n",
    "ta_not_found = (~df_dnb_ta['dnb_found']).sum()\n",
    "ta_total = len(df_dnb_ta)\n",
    "print(f\"2. Titel/Autor-Suche nicht gefunden: {ta_not_found:,} / {ta_total:,} ({ta_not_found/ta_total*100:.1f}%)\")\n",
    "\n",
    "# 3. KI hat DNB-Match abgelehnt\n",
    "if 'fusion_title_source' in df_fused.columns:\n",
    "    rejected = (df_fused['fusion_title_source'] == 'vdeh').sum()\n",
    "    fusion_total = df_fused['fusion_title_source'].notna().sum()\n",
    "    print(f\"3. KI-Ablehnung (falscher Match): {rejected:,} / {fusion_total:,} ({rejected/fusion_total*100:.1f}%)\")\n",
    "\n",
    "# Gesamt\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "total_records = len(df_original)\n",
    "no_dnb_data = total_records - fusion_total\n",
    "print(f\"Records ohne DNB-Daten: {no_dnb_data:,} / {total_records:,} ({no_dnb_data/total_records*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-rejected",
   "metadata": {},
   "source": [
    "## 2. Analyse: Abgelehnte DNB-Matches\n",
    "\n",
    "Warum hat die KI entschieden, dass der DNB-Treffer nicht zum VDEH-Record passt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rejected-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abgelehnte Matches analysieren\n",
    "rejected_records = df_fused[df_fused['fusion_title_source'] == 'vdeh'].copy()\n",
    "\n",
    "print(f\"Abgelehnte DNB-Matches: {len(rejected_records):,}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Ablehnungsgründe analysieren\n",
    "if 'fusion_rejection_reason' in rejected_records.columns:\n",
    "    print(\"\\nAblehnungsgründe (aus KI-Reasoning):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sammle alle Gründe\n",
    "    reasons = rejected_records['fusion_rejection_reason'].dropna()\n",
    "    \n",
    "    if len(reasons) > 0:\n",
    "        # Zeige einige Beispiele\n",
    "        print(f\"\\nBeispiele ({min(10, len(reasons))} von {len(reasons)}):\")\n",
    "        for i, reason in enumerate(reasons.head(10)):\n",
    "            print(f\"\\n{i+1}. {reason[:200]}...\" if len(str(reason)) > 200 else f\"\\n{i+1}. {reason}\")\n",
    "    else:\n",
    "        print(\"Keine expliziten Ablehnungsgründe gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rejected-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detaillierte Beispiele von abgelehnten Matches\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BEISPIELE: Abgelehnte DNB-Matches\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Zeige 5 zufällige Beispiele\n",
    "sample_rejected = rejected_records.sample(min(5, len(rejected_records)), random_state=42)\n",
    "\n",
    "for idx, row in sample_rejected.iterrows():\n",
    "    print(f\"\\n{'─' * 60}\")\n",
    "    print(f\"Record ID: {idx}\")\n",
    "    print(f\"\\nVDEH-Daten:\")\n",
    "    print(f\"  Titel: {row.get('title', 'N/A')}\")\n",
    "    print(f\"  Autor: {row.get('authors_str', 'N/A')}\")\n",
    "    print(f\"  Jahr: {row.get('year', 'N/A')}\")\n",
    "    print(f\"  Publisher: {row.get('publisher', 'N/A')}\")\n",
    "    \n",
    "    # DNB-Daten (die abgelehnt wurden)\n",
    "    print(f\"\\nDNB-Daten (abgelehnt):\")\n",
    "    if pd.notna(row.get('dnb_title')):\n",
    "        print(f\"  Titel: {row.get('dnb_title', 'N/A')}\")\n",
    "        print(f\"  Autor: {row.get('dnb_authors', 'N/A')}\")\n",
    "        print(f\"  Jahr: {row.get('dnb_year', 'N/A')}\")\n",
    "        print(f\"  Publisher: {row.get('dnb_publisher', 'N/A')}\")\n",
    "    elif pd.notna(row.get('dnb_title_ta')):\n",
    "        print(f\"  Titel: {row.get('dnb_title_ta', 'N/A')}\")\n",
    "        print(f\"  Autor: {row.get('dnb_authors_ta', 'N/A')}\")\n",
    "        print(f\"  Jahr: {row.get('dnb_year_ta', 'N/A')}\")\n",
    "        print(f\"  Publisher: {row.get('dnb_publisher_ta', 'N/A')}\")\n",
    "    \n",
    "    # KI-Reasoning\n",
    "    if pd.notna(row.get('fusion_ai_reasoning')):\n",
    "        reasoning = str(row['fusion_ai_reasoning'])[:300]\n",
    "        print(f\"\\nKI-Begründung: {reasoning}...\" if len(str(row['fusion_ai_reasoning'])) > 300 else f\"\\nKI-Begründung: {reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-isbn-not-found",
   "metadata": {},
   "source": [
    "## 3. Analyse: ISBN/ISSN nicht in DNB gefunden\n",
    "\n",
    "Warum werden manche ISBN/ISSN nicht in der DNB gefunden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isbn-not-found-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBN/ISSN nicht gefunden analysieren\n",
    "not_found_isbn = df_dnb_raw[~df_dnb_raw['dnb_found']].copy()\n",
    "\n",
    "print(f\"ISBN/ISSN nicht gefunden: {len(not_found_isbn):,}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Merge mit Original-Daten für mehr Kontext\n",
    "not_found_with_context = not_found_isbn.merge(\n",
    "    df_original[['title', 'authors_str', 'year', 'publisher', 'isbn', 'issn']],\n",
    "    left_index=True, right_index=True, how='left'\n",
    ")\n",
    "\n",
    "# Analyse nach Jahr\n",
    "print(\"\\nVerteilung nach Erscheinungsjahr:\")\n",
    "print(\"-\" * 40)\n",
    "year_dist = not_found_with_context['year'].dropna().astype(int)\n",
    "if len(year_dist) > 0:\n",
    "    # Dekaden\n",
    "    decades = (year_dist // 10 * 10).value_counts().sort_index()\n",
    "    for decade, count in decades.tail(10).items():\n",
    "        print(f\"  {int(decade)}er: {count:,}\")\n",
    "    \n",
    "    print(f\"\\n  Median Jahr: {int(year_dist.median())}\")\n",
    "    print(f\"  Ältestes: {int(year_dist.min())}\")\n",
    "    print(f\"  Neuestes: {int(year_dist.max())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isbn-format-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBN-Format analysieren\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ISBN-FORMAT ANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ISBN-Längen\n",
    "isbn_values = not_found_with_context['isbn'].dropna().astype(str)\n",
    "\n",
    "if len(isbn_values) > 0:\n",
    "    # Längenverteilung\n",
    "    lengths = isbn_values.str.replace('-', '').str.replace(' ', '').str.len()\n",
    "    print(\"\\nISBN-Längen (ohne Bindestriche):\")\n",
    "    for length, count in lengths.value_counts().sort_index().items():\n",
    "        print(f\"  {length} Zeichen: {count:,}\")\n",
    "    \n",
    "    # Beispiele für ungewöhnliche ISBNs\n",
    "    unusual = isbn_values[lengths < 10]\n",
    "    if len(unusual) > 0:\n",
    "        print(f\"\\nBeispiele für kurze ISBNs ({len(unusual)} Stück):\")\n",
    "        for isbn in unusual.head(10):\n",
    "            print(f\"  '{isbn}'\")\n",
    "    \n",
    "    # ISBNs die mit 3 beginnen (deutsche ISBNs)\n",
    "    german_isbn = isbn_values[isbn_values.str.replace('-', '').str.startswith('3')]\n",
    "    print(f\"\\nDeutsche ISBNs (beginnen mit 3): {len(german_isbn):,} ({len(german_isbn)/len(isbn_values)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isbn-not-found-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiele für nicht gefundene ISBN\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BEISPIELE: ISBN nicht in DNB gefunden\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Zeige Beispiele\n",
    "sample_not_found = not_found_with_context.sample(min(10, len(not_found_with_context)), random_state=42)\n",
    "\n",
    "for idx, row in sample_not_found.iterrows():\n",
    "    print(f\"\\n{'─' * 50}\")\n",
    "    print(f\"ISBN: {row.get('isbn', 'N/A')}\")\n",
    "    print(f\"ISSN: {row.get('issn', 'N/A')}\")\n",
    "    print(f\"Titel: {row.get('title', 'N/A')}\")\n",
    "    print(f\"Autor: {row.get('authors_str', 'N/A')}\")\n",
    "    print(f\"Jahr: {row.get('year', 'N/A')}\")\n",
    "    print(f\"Publisher: {row.get('publisher', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-ta-not-found",
   "metadata": {},
   "source": [
    "## 4. Analyse: Titel/Autor-Suche nicht gefunden\n",
    "\n",
    "Warum findet die Titel/Autor-Suche keinen Treffer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ta-not-found-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titel/Autor nicht gefunden analysieren\n",
    "not_found_ta = df_dnb_ta[~df_dnb_ta['dnb_found']].copy()\n",
    "\n",
    "print(f\"Titel/Autor nicht gefunden: {len(not_found_ta):,}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Merge mit Original-Daten\n",
    "not_found_ta_context = not_found_ta.merge(\n",
    "    df_original[['title', 'authors_str', 'year', 'publisher', 'lang_code']],\n",
    "    left_index=True, right_index=True, how='left'\n",
    ")\n",
    "\n",
    "# Analyse nach Sprache\n",
    "print(\"\\nVerteilung nach Sprache:\")\n",
    "print(\"-\" * 40)\n",
    "if 'lang_code' in not_found_ta_context.columns:\n",
    "    lang_dist = not_found_ta_context['lang_code'].value_counts()\n",
    "    for lang, count in lang_dist.head(10).items():\n",
    "        pct = count / len(not_found_ta_context) * 100\n",
    "        print(f\"  {lang}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Titel-Länge analysieren\n",
    "print(\"\\nTitel-Länge:\")\n",
    "print(\"-\" * 40)\n",
    "title_lengths = not_found_ta_context['title'].dropna().str.len()\n",
    "if len(title_lengths) > 0:\n",
    "    print(f\"  Min: {title_lengths.min()}\")\n",
    "    print(f\"  Max: {title_lengths.max()}\")\n",
    "    print(f\"  Median: {title_lengths.median():.0f}\")\n",
    "    print(f\"  Sehr kurze Titel (<20 Zeichen): {(title_lengths < 20).sum():,}\")\n",
    "    print(f\"  Sehr lange Titel (>200 Zeichen): {(title_lengths > 200).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ta-author-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autor-Probleme analysieren\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AUTOR-ANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fehlende Autoren\n",
    "missing_author = not_found_ta_context['authors_str'].isna() | (not_found_ta_context['authors_str'] == '')\n",
    "print(f\"\\nRecords ohne Autor: {missing_author.sum():,} ({missing_author.sum()/len(not_found_ta_context)*100:.1f}%)\")\n",
    "\n",
    "# Autor-Format analysieren\n",
    "authors = not_found_ta_context['authors_str'].dropna()\n",
    "authors = authors[authors != '']\n",
    "\n",
    "if len(authors) > 0:\n",
    "    # Anzahl Autoren pro Record\n",
    "    author_counts = authors.str.count(';') + 1\n",
    "    print(f\"\\nAnzahl Autoren pro Record:\")\n",
    "    print(f\"  1 Autor: {(author_counts == 1).sum():,}\")\n",
    "    print(f\"  2-3 Autoren: {((author_counts >= 2) & (author_counts <= 3)).sum():,}\")\n",
    "    print(f\"  >3 Autoren: {(author_counts > 3).sum():,}\")\n",
    "    \n",
    "    # Beispiele für problematische Autorennamen\n",
    "    print(f\"\\nBeispiele für Autorennamen:\")\n",
    "    for author in authors.sample(min(5, len(authors)), random_state=42):\n",
    "        print(f\"  '{author}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ta-not-found-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiele für nicht gefundene Titel/Autor\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BEISPIELE: Titel/Autor nicht in DNB gefunden\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Zeige Beispiele\n",
    "sample_ta = not_found_ta_context.sample(min(10, len(not_found_ta_context)), random_state=42)\n",
    "\n",
    "for idx, row in sample_ta.iterrows():\n",
    "    print(f\"\\n{'─' * 50}\")\n",
    "    print(f\"Titel: {row.get('title', 'N/A')}\")\n",
    "    print(f\"Autor: {row.get('authors_str', 'N/A')}\")\n",
    "    print(f\"Jahr: {row.get('year', 'N/A')}\")\n",
    "    print(f\"Sprache: {row.get('lang_code', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-comparison",
   "metadata": {},
   "source": [
    "## 5. Vergleich: Erfolgreiche vs. Fehlgeschlagene Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Datenqualität\n",
    "print(\"=\" * 60)\n",
    "print(\"VERGLEICH: Erfolgreiche vs. Fehlgeschlagene Matches\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ISBN/ISSN Suche\n",
    "found_isbn = df_dnb_raw[df_dnb_raw['dnb_found']]\n",
    "not_found_isbn = df_dnb_raw[~df_dnb_raw['dnb_found']]\n",
    "\n",
    "# Merge mit Original für Kontext\n",
    "found_context = found_isbn.merge(df_original[['year', 'lang_code']], left_index=True, right_index=True, how='left')\n",
    "not_found_context = not_found_isbn.merge(df_original[['year', 'lang_code']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "print(\"\\nISBN/ISSN-Suche:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Jahr\n",
    "found_year = found_context['year'].dropna().median()\n",
    "not_found_year = not_found_context['year'].dropna().median()\n",
    "print(f\"  Median Jahr (gefunden): {found_year:.0f}\")\n",
    "print(f\"  Median Jahr (nicht gefunden): {not_found_year:.0f}\")\n",
    "\n",
    "# Sprache\n",
    "print(f\"\\n  Sprache (gefunden):\")\n",
    "for lang, count in found_context['lang_code'].value_counts().head(3).items():\n",
    "    print(f\"    {lang}: {count:,}\")\n",
    "\n",
    "print(f\"\\n  Sprache (nicht gefunden):\")\n",
    "for lang, count in not_found_context['lang_code'].value_counts().head(3).items():\n",
    "    print(f\"    {lang}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "year-distribution-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Jahr-Verteilung\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ISBN/ISSN\n",
    "ax = axes[0]\n",
    "found_years = found_context['year'].dropna()\n",
    "not_found_years = not_found_context['year'].dropna()\n",
    "\n",
    "ax.hist([found_years, not_found_years], bins=30, label=['Gefunden', 'Nicht gefunden'], \n",
    "        alpha=0.7, color=['#2ecc71', '#e74c3c'])\n",
    "ax.set_xlabel('Erscheinungsjahr')\n",
    "ax.set_ylabel('Anzahl')\n",
    "ax.set_title('ISBN/ISSN-Suche: Verteilung nach Jahr')\n",
    "ax.legend()\n",
    "\n",
    "# Titel/Autor\n",
    "ax = axes[1]\n",
    "found_ta = df_dnb_ta[df_dnb_ta['dnb_found']]\n",
    "not_found_ta = df_dnb_ta[~df_dnb_ta['dnb_found']]\n",
    "\n",
    "found_ta_context = found_ta.merge(df_original[['year']], left_index=True, right_index=True, how='left')\n",
    "not_found_ta_context2 = not_found_ta.merge(df_original[['year']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "found_ta_years = found_ta_context['year'].dropna()\n",
    "not_found_ta_years = not_found_ta_context2['year'].dropna()\n",
    "\n",
    "ax.hist([found_ta_years, not_found_ta_years], bins=30, label=['Gefunden', 'Nicht gefunden'], \n",
    "        alpha=0.7, color=['#2ecc71', '#e74c3c'])\n",
    "ax.set_xlabel('Erscheinungsjahr')\n",
    "ax.set_ylabel('Anzahl')\n",
    "ax.set_title('Titel/Autor-Suche: Verteilung nach Jahr')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-patterns",
   "metadata": {},
   "source": [
    "## 6. Muster und Verbesserungspotenzial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pattern-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muster identifizieren\n",
    "print(\"=\" * 60)\n",
    "print(\"IDENTIFIZIERTE MUSTER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Alte Bücher\n",
    "old_threshold = 1970\n",
    "old_not_found = not_found_context[not_found_context['year'] < old_threshold]\n",
    "old_found = found_context[found_context['year'] < old_threshold]\n",
    "\n",
    "print(f\"\\n1. Bücher vor {old_threshold}:\")\n",
    "print(f\"   Gefunden: {len(old_found):,}\")\n",
    "print(f\"   Nicht gefunden: {len(old_not_found):,}\")\n",
    "if len(old_found) + len(old_not_found) > 0:\n",
    "    success_rate = len(old_found) / (len(old_found) + len(old_not_found)) * 100\n",
    "    print(f\"   Erfolgsrate: {success_rate:.1f}%\")\n",
    "\n",
    "# 2. Nicht-deutsche Bücher\n",
    "non_german_not_found = not_found_context[not_found_context['lang_code'] != 'de']\n",
    "non_german_found = found_context[found_context['lang_code'] != 'de']\n",
    "\n",
    "print(f\"\\n2. Nicht-deutschsprachige Bücher:\")\n",
    "print(f\"   Gefunden: {len(non_german_found):,}\")\n",
    "print(f\"   Nicht gefunden: {len(non_german_not_found):,}\")\n",
    "if len(non_german_found) + len(non_german_not_found) > 0:\n",
    "    success_rate = len(non_german_found) / (len(non_german_found) + len(non_german_not_found)) * 100\n",
    "    print(f\"   Erfolgsrate: {success_rate:.1f}%\")\n",
    "\n",
    "# 3. Bücher ohne Autor (für Titel/Autor-Suche)\n",
    "ta_context_full = df_dnb_ta.merge(df_original[['authors_str']], left_index=True, right_index=True, how='left')\n",
    "no_author = ta_context_full['authors_str'].isna() | (ta_context_full['authors_str'] == '')\n",
    "no_author_found = (ta_context_full[no_author]['dnb_found']).sum()\n",
    "no_author_total = no_author.sum()\n",
    "\n",
    "print(f\"\\n3. Titel/Autor-Suche ohne Autorinfo:\")\n",
    "print(f\"   Total: {no_author_total:,}\")\n",
    "print(f\"   Gefunden: {no_author_found:,}\")\n",
    "if no_author_total > 0:\n",
    "    print(f\"   Erfolgsrate: {no_author_found/no_author_total*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empfehlungen\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EMPFEHLUNGEN ZUR VERBESSERUNG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "Basierend auf der Analyse:\n",
    "\n",
    "1. ALTE BÜCHER (vor 1970)\n",
    "   - DNB hat möglicherweise keine vollständige Erfassung\n",
    "   - Alternative: Katalog der Deutschen Staatsbibliothek\n",
    "   - Alternative: WorldCat für internationale Suche\n",
    "\n",
    "2. NICHT-DEUTSCHE BÜCHER\n",
    "   - DNB fokussiert auf deutsche Publikationen\n",
    "   - Empfehlung: Library of Congress, British Library APIs\n",
    "   - Empfehlung: WorldCat OCLC\n",
    "\n",
    "3. FEHLENDE AUTOREN\n",
    "   - Titel/Autor-Suche funktioniert schlecht ohne Autor\n",
    "   - Empfehlung: Nur Titel-Suche mit Jahr als Filter\n",
    "\n",
    "4. ISBN-FORMAT\n",
    "   - Alte ISBN-10 Formate prüfen\n",
    "   - Bindestriche und Leerzeichen normalisieren\n",
    "   - Prüfsummenvalidierung vor DNB-Query\n",
    "\n",
    "5. TITEL-NORMALISIERUNG\n",
    "   - Sonderzeichen entfernen\n",
    "   - Untertitel abtrennen\n",
    "   - Artikelpräfixe entfernen (Der, Die, Das, The, etc.)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-summary",
   "metadata": {},
   "source": [
    "## 7. Zusammenfassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfassung\n",
    "print(\"=\" * 60)\n",
    "print(\"ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Gesamtübersicht der Fehlschläge:\n",
    "\n",
    "1. ISBN/ISSN nicht in DNB gefunden:\n",
    "   {isbn_not_found:,} Records ({isbn_not_found/isbn_total*100:.1f}%)\n",
    "   \n",
    "2. Titel/Autor nicht in DNB gefunden:\n",
    "   {ta_not_found:,} Records ({ta_not_found/ta_total*100:.1f}%)\n",
    "   \n",
    "3. DNB-Match durch KI abgelehnt:\n",
    "   {rejected:,} Records ({rejected/fusion_total*100:.1f}%)\n",
    "\n",
    "Hauptgründe für Fehlschläge:\n",
    "- Alte Publikationen (vor DNB-Erfassung)\n",
    "- Ausländische Publikationen (nicht in DNB)\n",
    "- Fehlende/ungenaue Metadaten (Autor, ISBN)\n",
    "- Titel-Variationen zwischen VDEH und DNB\n",
    "\n",
    "Nächste Schritte:\n",
    "- Alternative Datenquellen für alte/ausländische Bücher\n",
    "- Verbesserte Normalisierung der Suchterme\n",
    "- Fuzzy-Matching für Titel-Suche\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
