{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d807457",
   "metadata": {},
   "source": [
    "# VDEH Data Loading Pipeline\n",
    "\n",
    "**Fokus:** Reine Datenextraktion aus OAI-PMH XML-Format\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "- Parse VDEH XML-Datei (OAI-PMH Format)\n",
    "- Extrahiere Grunddaten: Titel, Autoren, Jahr\n",
    "- Validiere und bereinige Basisdaten\n",
    "- Export als standardisierte Parquet-Datei\n",
    "\n",
    "## ğŸ“š Input/Output\n",
    "- **Input**: `data/vdeh/raw/VDEH_mab_all.xml`\n",
    "- **Output**: `data/vdeh/processed/01_loaded_data.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dcf65f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Projektroot: /media/sz/Data/Bibo/analysis\n",
      "ğŸ”§ Python-Pfad erweitert: /media/sz/Data/Bibo/analysis/src\n"
     ]
    }
   ],
   "source": [
    "# ğŸ› ï¸ SETUP: Konfiguration und Module laden\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Projektroot finden\n",
    "current_dir = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "# Suche nach config.yaml in Parent-Verzeichnissen\n",
    "for parent in [current_dir] + list(current_dir.parents):\n",
    "    if (parent / 'config.yaml').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise FileNotFoundError(\"config.yaml nicht gefunden!\")\n",
    "\n",
    "print(f\"ğŸ“ Projektroot: {project_root}\")\n",
    "\n",
    "# Python-Pfad erweitern\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"ğŸ”§ Python-Pfad erweitert: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae0da05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Konfiguration geladen: /media/sz/Data/Bibo/analysis/config.yaml\n",
      "âœ… Konfiguration geladen\n",
      "ğŸ“„ VDEH Datenquelle: Neuerwerbungen der VDEH Bibliotheken\n",
      "ğŸ“‚ Dateipfad: /media/sz/Data/Bibo/analysis/data/vdeh/raw/VDEH_mab_all.xml\n",
      "ğŸ”¤ Encoding: utf-8\n",
      "ğŸ“Š GeschÃ¤tzte Records: 58,760\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ KONFIGURATION LADEN\n",
    "import importlib\n",
    "\n",
    "# Reload config_loader falls schon importiert\n",
    "if 'config_loader' in sys.modules:\n",
    "    importlib.reload(sys.modules['config_loader'])\n",
    "    \n",
    "from config_loader import load_config\n",
    "\n",
    "config = load_config(project_root / 'config.yaml')\n",
    "print(\"âœ… Konfiguration geladen\")\n",
    "\n",
    "# VDEH spezifische Konfiguration\n",
    "vdeh_config = config.get('data_sources.vdeh')\n",
    "print(f\"ğŸ“„ VDEH Datenquelle: {vdeh_config['description']}\")\n",
    "print(f\"ğŸ“‚ Dateipfad: {config.project_root / vdeh_config['path']}\")\n",
    "print(f\"ğŸ”¤ Encoding: {vdeh_config['encoding']}\")\n",
    "print(f\"ğŸ“Š GeschÃ¤tzte Records: {vdeh_config['estimated_records']:,}\")\n",
    "\n",
    "# Warnings konfigurieren\n",
    "if not config.get('debug.verbose_output', True):\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9100b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Lade VDEH XML-Datei: /media/sz/Data/Bibo/analysis/data/vdeh/raw/VDEH_mab_all.xml\n",
      "ğŸ“Š Max Records: Alle (~58k)\n",
      "ğŸš€ Starte robusten Parser fÃ¼r bibliographische Grunddaten...\n",
      "ğŸ“ Datei: /media/sz/Data/Bibo/analysis/data/vdeh/raw/VDEH_mab_all.xml\n",
      "ğŸ“Š DateigrÃ¶ÃŸe: 118.6 MB\n",
      "ğŸ“š Gefunden: 58,760 OAI-Records\n",
      "ğŸ“ Verarbeitet: 5,000 Records\n",
      "ğŸ“ Verarbeitet: 10,000 Records\n",
      "ğŸ“ Verarbeitet: 15,000 Records\n",
      "ğŸ“ Verarbeitet: 20,000 Records\n",
      "ğŸ“ Verarbeitet: 25,000 Records\n",
      "ğŸ“ Verarbeitet: 30,000 Records\n",
      "ğŸ“ Verarbeitet: 35,000 Records\n",
      "ğŸ“ Verarbeitet: 40,000 Records\n",
      "ğŸ“ Verarbeitet: 45,000 Records\n",
      "ğŸ“ Verarbeitet: 50,000 Records\n",
      "ğŸ“ Verarbeitet: 55,000 Records\n",
      "âœ… 58,760 Records verarbeitet\n",
      "ğŸ¯ DataFrame erstellt:\n",
      "   ğŸ“Š 58,760 Zeilen\n",
      "   ğŸ“‹ 12 Spalten\n",
      "   ğŸ’¾ 31.9 MB\n",
      "\n",
      "âœ… DataFrame erstellt: 58,760 Records\n",
      "ğŸ’¾ Speicherverbrauch: 31.9 MB\n",
      "ğŸ“‹ Spalten: ['id', 'title', 'authors', 'authors_affiliation', 'year', 'publisher', 'isbn', 'issn', 'authors_str', 'num_authors', 'authors_affiliation_str', 'num_authors_affiliation']\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š XML-DATEN LADEN\n",
    "vdeh_config = config.get('data_sources.vdeh')\n",
    "xml_file_path = config.project_root / vdeh_config['path']\n",
    "max_records = config.get('data_processing.vdeh_parser.max_records')\n",
    "\n",
    "print(f\"ğŸ“‚ Lade VDEH XML-Datei: {xml_file_path}\")\n",
    "print(f\"ğŸ“Š Max Records: {max_records or 'Alle (~58k)'}\")\n",
    "\n",
    "# PrÃ¼fe ob Datei existiert\n",
    "if not xml_file_path.exists():\n",
    "    raise FileNotFoundError(f\"VDEH XML-Datei nicht gefunden: {xml_file_path}\")\n",
    "\n",
    "# VDEH Parser importieren\n",
    "from parsers.vdeh_parser import parse_bibliography, analyze_bibliography_data, get_sample_records\n",
    "\n",
    "# Daten laden\n",
    "df_vdeh = parse_bibliography(str(xml_file_path), max_records=max_records)\n",
    "\n",
    "print(f\"\\nâœ… DataFrame erstellt: {len(df_vdeh):,} Records\")\n",
    "print(f\"ğŸ’¾ Speicherverbrauch: {df_vdeh.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"ğŸ“‹ Spalten: {list(df_vdeh.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9407ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                   aleph-publish:000000004\n",
       "title                      Untersuchung der Gleichgewichte zwischen flÃ¼ss...\n",
       "authors                                                      [Thielmann, R.]\n",
       "authors_affiliation                                 [EuropÃ¤ische Kommission]\n",
       "year                                                                  1983.0\n",
       "publisher                                                         Luxembourg\n",
       "isbn                                                                    None\n",
       "issn                                                                    None\n",
       "authors_str                                                    Thielmann, R.\n",
       "num_authors                                                                1\n",
       "authors_affiliation_str                               EuropÃ¤ische Kommission\n",
       "num_authors_affiliation                                                    1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vdeh.iloc[0]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c62b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STANDARDNUMMERN ANALYSE ===\n",
      "\n",
      "ISBN Analyse:\n",
      "Anzahl DatensÃ¤tze mit ISBN: 11,415\n",
      "Prozent der DatensÃ¤tze mit ISBN: 19.43%\n",
      "\n",
      "ISBN LÃ¤ngen:\n",
      "   0 Stellen: 1 ISBNs (0.0%)\n",
      "   1 Stellen: 1 ISBNs (0.0%)\n",
      "   4 Stellen: 2 ISBNs (0.0%)\n",
      "   7 Stellen: 2 ISBNs (0.0%)\n",
      "   8 Stellen: 697 ISBNs (6.1%)\n",
      "   9 Stellen: 22 ISBNs (0.2%)\n",
      "   11 Stellen: 22 ISBNs (0.2%)\n",
      "   12 Stellen: 13 ISBNs (0.1%)\n",
      "   13 Stellen: 8,038 ISBNs (70.4%)\n",
      "   14 Stellen: 1 ISBNs (0.0%)\n",
      "   16 Stellen: 2 ISBNs (0.0%)\n",
      "   17 Stellen: 2,485 ISBNs (21.8%)\n",
      "   20 Stellen: 77 ISBNs (0.7%)\n",
      "   21 Stellen: 1 ISBNs (0.0%)\n",
      "   22 Stellen: 5 ISBNs (0.0%)\n",
      "   23 Stellen: 31 ISBNs (0.3%)\n",
      "   25 Stellen: 1 ISBNs (0.0%)\n",
      "   26 Stellen: 9 ISBNs (0.1%)\n",
      "   27 Stellen: 1 ISBNs (0.0%)\n",
      "   28 Stellen: 1 ISBNs (0.0%)\n",
      "   30 Stellen: 3 ISBNs (0.0%)\n",
      "\n",
      "Beispiel ISBNs:\n",
      "   ISBN: 3-826-56022-1 | Titel: Tribologische Untersuchungen zur Kaltmassivumformung...\n",
      "   ISBN: 9-282-81437-8 | Titel: Mejora de las propiedades mecanicas de piezas forjadas y barras median...\n",
      "   ISBN: 3-527-26149-4 | Titel: Handbook of particle sampling and analysis methods...\n",
      "\n",
      "ISSN Analyse:\n",
      "Anzahl DatensÃ¤tze mit ISSN: 721\n",
      "Prozent der DatensÃ¤tze mit ISSN: 1.23%\n",
      "\n",
      "Beispiel ISSNs:\n",
      "   ISSN: 0369-7290 | Titel: Ogneupory i techniceskaja keramika...\n",
      "   ISSN: 0976-4232 | Titel: Steel Tech : Steel technology for today and tomorrow...\n",
      "   ISSN: 0026-0797 | Titel: mo MetalloberflÃ¤che [gedruckte Ausgabe] : Beschichten von Kunststoff u...\n",
      "\n",
      "\n",
      "=== VERLAGSANALYSE ===\n",
      "Anzahl DatensÃ¤tze mit Verlag: 23,553\n",
      "Prozent der DatensÃ¤tze mit Verlag: 40.08%\n",
      "\n",
      "Beispiel Verlage:\n",
      "   Verlag: Verlag Stahleisen : DÃ¼sseldorf... | Titel: FÃ¶rdertechnik : Trog- und SiebbelÃ¤ge in Sinteranla...\n",
      "   Verlag: Werkstoff-Informationsgesellschaft : Frankfurt am Main... | Titel: Fortschritte in der Metallographie : Votragstexte ...\n",
      "   Verlag: DVT : DÃ¼sseldorf... | Titel: Die Kompetenz technisch-wissenschaftlicher Vereine...\n"
     ]
    }
   ],
   "source": [
    "# Standardnummern-Analyse (ISBN/ISSN)\n",
    "print(\"=== STANDARDNUMMERN ANALYSE ===\")\n",
    "\n",
    "# ISBN Analyse\n",
    "try:\n",
    "    isbn_total = df_vdeh['isbn'].notna().sum()\n",
    "    print(\"\\nISBN Analyse:\")\n",
    "    print(f\"Anzahl DatensÃ¤tze mit ISBN: {isbn_total:,}\")\n",
    "    print(f\"Prozent der DatensÃ¤tze mit ISBN: {(isbn_total/len(df_vdeh)*100):.2f}%\")\n",
    "\n",
    "    if isbn_total > 0:\n",
    "        # ISBN LÃ¤ngenanalyse\n",
    "        df_with_isbn = df_vdeh[df_vdeh['isbn'].notna()]\n",
    "        if not df_with_isbn.empty:\n",
    "            isbn_lengths = df_with_isbn['isbn'].astype(str).str.len().value_counts().sort_index()\n",
    "            print(\"\\nISBN LÃ¤ngen:\")\n",
    "            for length, count in isbn_lengths.items():\n",
    "                print(f\"   {length} Stellen: {count:,} ISBNs ({count/isbn_total*100:.1f}%)\")\n",
    "\n",
    "            print(\"\\nBeispiel ISBNs:\")\n",
    "            try:\n",
    "                sample_with_isbn = df_with_isbn.sample(n=min(3, len(df_with_isbn)), random_state=42)\n",
    "                for _, row in sample_with_isbn.iterrows():\n",
    "                    print(f\"   ISBN: {row['isbn']} | Titel: {row['title'][:70] if row['title'] else 'N/A'}...\")\n",
    "            except ValueError as e:\n",
    "                print(\"   Keine ISBN-Beispiele verfÃ¼gbar.\")\n",
    "except Exception as e:\n",
    "    print(f\"Fehler bei der ISBN-Analyse: {str(e)}\")\n",
    "\n",
    "# ISSN Analyse\n",
    "try:\n",
    "    issn_total = df_vdeh['issn'].notna().sum()\n",
    "    print(\"\\nISSN Analyse:\")\n",
    "    print(f\"Anzahl DatensÃ¤tze mit ISSN: {issn_total:,}\")\n",
    "    print(f\"Prozent der DatensÃ¤tze mit ISSN: {(issn_total/len(df_vdeh)*100):.2f}%\")\n",
    "\n",
    "    if issn_total > 0:\n",
    "        df_with_issn = df_vdeh[df_vdeh['issn'].notna()]\n",
    "        if not df_with_issn.empty:\n",
    "            print(\"\\nBeispiel ISSNs:\")\n",
    "            try:\n",
    "                sample_with_issn = df_with_issn.sample(n=min(3, len(df_with_issn)), random_state=42)\n",
    "                for _, row in sample_with_issn.iterrows():\n",
    "                    print(f\"   ISSN: {row['issn']} | Titel: {row['title'][:70] if row['title'] else 'N/A'}...\")\n",
    "            except ValueError as e:\n",
    "                print(\"   Keine ISSN-Beispiele verfÃ¼gbar.\")\n",
    "except Exception as e:\n",
    "    print(f\"Fehler bei der ISSN-Analyse: {str(e)}\")\n",
    "\n",
    "# Verlagsanalyse\n",
    "if 'publisher' in df_vdeh.columns:\n",
    "    try:\n",
    "        publisher_total = df_vdeh['publisher'].notna().sum()\n",
    "        print(\"\\n\\n=== VERLAGSANALYSE ===\")\n",
    "        print(f\"Anzahl DatensÃ¤tze mit Verlag: {publisher_total:,}\")\n",
    "        print(f\"Prozent der DatensÃ¤tze mit Verlag: {(publisher_total/len(df_vdeh)*100):.2f}%\")\n",
    "        \n",
    "        if publisher_total > 0:\n",
    "            print(\"\\nBeispiel Verlage:\")\n",
    "            df_with_publisher = df_vdeh[df_vdeh['publisher'].notna()]\n",
    "            sample_publisher = df_with_publisher.sample(n=min(3, len(df_with_publisher)), random_state=42)\n",
    "            for _, row in sample_publisher.iterrows():\n",
    "                print(f\"   Verlag: {row['publisher'][:60]}... | Titel: {row['title'][:50] if row['title'] else 'N/A'}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Verlagsanalyse: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8950e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ === VDEH DATENANALYSE ===\n",
      "\n",
      "\n",
      "ğŸ“Š === BIBLIOGRAPHISCHE DATEN ANALYSE ===\n",
      "ğŸ“š Gesamt Records: 58,760\n",
      "ğŸ“‹ Mit Titel: 40,830 (69.5%)\n",
      "ğŸ‘¤ Mit Autoren: 17,011 (28.9%)\n",
      "ğŸ“… Mit Jahr: 33,687 (57.3%)\n",
      "ğŸ¢ Mit Verlag: 23,553 (40.1%)\n",
      "ğŸ“– Mit ISBN: 11,415 (19.4%)\n",
      "ğŸ“° Mit ISSN: 721 (1.2%)\n",
      "âœ… VollstÃ¤ndig: 16,013 (27.3%)\n",
      "ğŸ“… Zeitspanne: 1900 - 2017\n",
      "ğŸ“Š Median-Jahr: 1998\n",
      "ğŸ‘¥ Einzigartige Autoren: 17,758\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ˆ BASIS-DATENANALYSE\n",
    "print(\"ğŸ“ˆ === VDEH DATENANALYSE ===\\n\")\n",
    "\n",
    "# Basis-Analyse der VDEH-Daten\n",
    "analyze_bibliography_data(df_vdeh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "334f5bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ === DATEN LOADING ABGESCHLOSSEN ===\n",
      "âœ… Geladene Daten exportiert: /media/sz/Data/Bibo/analysis/data/vdeh/processed/01_loaded_data.parquet\n",
      "ğŸ“Š Records: 58,760\n",
      "ğŸ“‹ Spalten: 12\n",
      "ğŸ’¾ DateigrÃ¶ÃŸe: 34.8 MB\n",
      "ğŸ“„ Metadaten gespeichert: /media/sz/Data/Bibo/analysis/data/vdeh/processed/01_metadata.json\n",
      "\n",
      "â¡ï¸  NÃ¤chster Schritt: 02_vdeh_data_preprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ GELADENE DATEN EXPORTIEREN\n",
    "processed_dir = config.project_root / config.get('paths.data.vdeh.processed')\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export als Parquet fÃ¼r nÃ¤chste Pipeline-Stufe\n",
    "output_path = processed_dir / '01_loaded_data.parquet'\n",
    "df_vdeh.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"ğŸ’¾ === DATEN LOADING ABGESCHLOSSEN ===\")\n",
    "print(f\"âœ… Geladene Daten exportiert: {output_path}\")\n",
    "print(f\"ğŸ“Š Records: {len(df_vdeh):,}\")\n",
    "print(f\"ğŸ“‹ Spalten: {len(df_vdeh.columns)}\")\n",
    "print(f\"ğŸ’¾ DateigrÃ¶ÃŸe: {df_vdeh.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Metadaten fÃ¼r nÃ¤chste Stufe\n",
    "metadata = {\n",
    "    'stage': '01_data_loading',\n",
    "    'records_loaded': len(df_vdeh),\n",
    "    'columns': list(df_vdeh.columns),\n",
    "    'source_file': str(xml_file_path),\n",
    "    'processing_date': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "import json\n",
    "metadata_path = processed_dir / '01_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"ğŸ“„ Metadaten gespeichert: {metadata_path}\")\n",
    "print(f\"\\nâ¡ï¸  NÃ¤chster Schritt: 02_vdeh_data_preprocessing.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibo-analysis-DoEGeq_l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
