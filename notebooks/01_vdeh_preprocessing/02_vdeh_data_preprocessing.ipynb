{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db7f410",
   "metadata": {},
   "source": [
    "# VDEH Data Preprocessing Pipeline\n",
    "\n",
    "**Fokus:** Datenbereinigung und Optimierung\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "- Datentyp-Optimierung (Memory-Effizienz)\n",
    "- ISBN-Spalte entfernen (leer bei VDEH)\n",
    "- Kategorische Variablen optimieren\n",
    "- Datenvalidierung und -bereinigung\n",
    "\n",
    "## ğŸ“š Input/Output\n",
    "- **Input**: `data/vdeh/processed/01_loaded_data.parquet`\n",
    "- **Output**: `data/vdeh/processed/02_preprocessed_data.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4f3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Konfiguration geladen: /media/sz/Data/Bibo/analysis/config.yaml\n",
      "ğŸ“ Projektroot: /media/sz/Data/Bibo/analysis\n",
      "âœ… Konfiguration geladen\n"
     ]
    }
   ],
   "source": [
    "# ğŸ› ï¸ SETUP UND DATEN LADEN\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Projektroot finden\n",
    "current_dir = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "for parent in [current_dir] + list(current_dir.parents):\n",
    "    if (parent / 'config.yaml').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise FileNotFoundError(\"config.yaml nicht gefunden!\")\n",
    "\n",
    "# Config laden\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "from config_loader import load_config\n",
    "config = load_config(project_root / 'config.yaml')\n",
    "\n",
    "print(f\"ğŸ“ Projektroot: {project_root}\")\n",
    "print(\"âœ… Konfiguration geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b41184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Daten geladen aus: /media/sz/Data/Bibo/analysis/data/vdeh/processed/01_loaded_data.parquet\n",
      "ğŸ“Š Records: 58,760\n",
      "ğŸ“‹ Spalten: ['id', 'title', 'authors', 'authors_affiliation', 'year', 'publisher', 'isbn', 'issn', 'authors_str', 'num_authors', 'authors_affiliation_str', 'num_authors_affiliation']\n",
      "ğŸ“… Vorherige Verarbeitung: 2025-11-06T12:48:38.378116\n",
      "ğŸ’¾ Memory vor Optimierung: 37.4 MB\n",
      "ğŸ’¾ Memory vor Optimierung: 37.4 MB\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ DATEN AUS VORHERIGER STUFE LADEN\n",
    "processed_dir = config.project_root / config.get('paths.data.vdeh.processed')\n",
    "input_path = processed_dir / '01_loaded_data.parquet'\n",
    "metadata_path = processed_dir / '01_metadata.json'\n",
    "\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Input-Datei nicht gefunden: {input_path}\\n\"\n",
    "                          \"Bitte fÃ¼hren Sie zuerst 01_vdeh_data_loading.ipynb aus.\")\n",
    "\n",
    "# Daten laden\n",
    "df_vdeh = pd.read_parquet(input_path)\n",
    "\n",
    "# Vorherige Metadaten laden\n",
    "with open(metadata_path, 'r') as f:\n",
    "    prev_metadata = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“‚ Daten geladen aus: {input_path}\")\n",
    "print(f\"ğŸ“Š Records: {len(df_vdeh):,}\")\n",
    "print(f\"ğŸ“‹ Spalten: {list(df_vdeh.columns)}\")\n",
    "print(f\"ğŸ“… Vorherige Verarbeitung: {prev_metadata['processing_date']}\")\n",
    "print(f\"ğŸ’¾ Memory vor Optimierung: {df_vdeh.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aab14cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ === ISBN/ISSN VALIDIERUNG ===\n",
      "\n",
      "ğŸ“š ISBN Validierung:\n",
      "   Gesamt ISBNs: 11,415\n",
      "   âœ… GÃ¼ltig: 10,350 (90.7%)\n",
      "   âŒ UngÃ¼ltig: 1,065 (9.3%)\n",
      "\n",
      "   ğŸ“‹ Beispiele ungÃ¼ltiger ISBNs:\n",
      "      387011839 â†’ ISBN: UngÃ¼ltige LÃ¤nge (9 Zeichen)\n",
      "      3-885-08990-8 â†’ ISBN-10: UngÃ¼ltige PrÃ¼fziffer\n",
      "      0-895-20419-6 â†’ ISBN-10: UngÃ¼ltige PrÃ¼fziffer\n",
      "\n",
      "ğŸ“° ISSN Validierung:\n",
      "   Gesamt ISBNs: 11,415\n",
      "   âœ… GÃ¼ltig: 10,350 (90.7%)\n",
      "   âŒ UngÃ¼ltig: 1,065 (9.3%)\n",
      "\n",
      "   ğŸ“‹ Beispiele ungÃ¼ltiger ISBNs:\n",
      "      387011839 â†’ ISBN: UngÃ¼ltige LÃ¤nge (9 Zeichen)\n",
      "      3-885-08990-8 â†’ ISBN-10: UngÃ¼ltige PrÃ¼fziffer\n",
      "      0-895-20419-6 â†’ ISBN-10: UngÃ¼ltige PrÃ¼fziffer\n",
      "\n",
      "ğŸ“° ISSN Validierung:\n",
      "   Gesamt ISSNs: 721\n",
      "   âœ… GÃ¼ltig: 716 (99.3%)\n",
      "   âŒ UngÃ¼ltig: 5 (0.7%)\n",
      "\n",
      "   ğŸ“‹ Beispiele ungÃ¼ltiger ISSNs:\n",
      "      0952-2110 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 5)\n",
      "      0016-9733 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 0)\n",
      "      0304-3834 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 5)\n",
      "      3876-7796 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 1)\n",
      "      1984-9899 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 3)\n",
      "\n",
      "   ğŸ“Š Status-Ãœbersicht:\n",
      "      ISSN: 716 (99.3%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 5): 2 (0.3%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 0): 1 (0.1%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 1): 1 (0.1%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 3): 1 (0.1%)\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ Hinweis: UngÃ¼ltige Nummern kÃ¶nnen durch Tippfehler,\n",
      "   fehlerhafte OCR-Erkennung oder Datenfehler entstehen.\n",
      "============================================================\n",
      "   Gesamt ISSNs: 721\n",
      "   âœ… GÃ¼ltig: 716 (99.3%)\n",
      "   âŒ UngÃ¼ltig: 5 (0.7%)\n",
      "\n",
      "   ğŸ“‹ Beispiele ungÃ¼ltiger ISSNs:\n",
      "      0952-2110 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 5)\n",
      "      0016-9733 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 0)\n",
      "      0304-3834 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 5)\n",
      "      3876-7796 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 1)\n",
      "      1984-9899 â†’ ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 3)\n",
      "\n",
      "   ğŸ“Š Status-Ãœbersicht:\n",
      "      ISSN: 716 (99.3%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 5): 2 (0.3%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 0): 1 (0.1%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 1): 1 (0.1%)\n",
      "      ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: 3): 1 (0.1%)\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ Hinweis: UngÃ¼ltige Nummern kÃ¶nnen durch Tippfehler,\n",
      "   fehlerhafte OCR-Erkennung oder Datenfehler entstehen.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ ISBN/ISSN VALIDIERUNG\n",
    "print(\"ğŸ“‹ === ISBN/ISSN VALIDIERUNG ===\")\n",
    "\n",
    "import re\n",
    "\n",
    "def validate_isbn(isbn_str):\n",
    "    \"\"\"\n",
    "    Validiert ISBN-10 oder ISBN-13 Format.\n",
    "    Akzeptiert Formate mit und ohne Bindestriche.\n",
    "    \"\"\"\n",
    "    if pd.isna(isbn_str):\n",
    "        return None, None\n",
    "    \n",
    "    # Entferne alle Bindestriche und Leerzeichen\n",
    "    isbn_clean = str(isbn_str).replace('-', '').replace(' ', '').upper()\n",
    "    \n",
    "    # ISBN-10: 10 Zeichen (letztes kann X sein)\n",
    "    if len(isbn_clean) == 10:\n",
    "        if not re.match(r'^\\d{9}[\\dX]$', isbn_clean):\n",
    "            return False, \"ISBN-10: UngÃ¼ltiges Format\"\n",
    "        \n",
    "        # PrÃ¼fziffer validieren\n",
    "        try:\n",
    "            checksum = sum((10 - i) * (10 if c == 'X' else int(c)) for i, c in enumerate(isbn_clean))\n",
    "            is_valid = checksum % 11 == 0\n",
    "            return is_valid, \"ISBN-10\" if is_valid else \"ISBN-10: UngÃ¼ltige PrÃ¼fziffer\"\n",
    "        except:\n",
    "            return False, \"ISBN-10: Validierungsfehler\"\n",
    "    \n",
    "    # ISBN-13: 13 Zeichen\n",
    "    elif len(isbn_clean) == 13:\n",
    "        if not re.match(r'^\\d{13}$', isbn_clean):\n",
    "            return False, \"ISBN-13: UngÃ¼ltiges Format\"\n",
    "        \n",
    "        # PrÃ¼fziffer validieren\n",
    "        try:\n",
    "            checksum = sum(int(c) * (1 if i % 2 == 0 else 3) for i, c in enumerate(isbn_clean))\n",
    "            is_valid = checksum % 10 == 0\n",
    "            return is_valid, \"ISBN-13\" if is_valid else \"ISBN-13: UngÃ¼ltige PrÃ¼fziffer\"\n",
    "        except:\n",
    "            return False, \"ISBN-13: Validierungsfehler\"\n",
    "    \n",
    "    else:\n",
    "        return False, f\"ISBN: UngÃ¼ltige LÃ¤nge ({len(isbn_clean)} Zeichen)\"\n",
    "\n",
    "def validate_issn(issn_str):\n",
    "    \"\"\"\n",
    "    Validiert ISSN Format (8 Zeichen: XXXX-XXXX).\n",
    "    \"\"\"\n",
    "    if pd.isna(issn_str):\n",
    "        return None, None\n",
    "    \n",
    "    # Entferne alle Bindestriche und Leerzeichen\n",
    "    issn_clean = str(issn_str).replace('-', '').replace(' ', '').upper()\n",
    "    \n",
    "    # ISSN muss genau 8 Zeichen haben\n",
    "    if len(issn_clean) != 8:\n",
    "        return False, f\"ISSN: UngÃ¼ltige LÃ¤nge ({len(issn_clean)} Zeichen)\"\n",
    "    \n",
    "    # Format: 7 Ziffern + PrÃ¼fziffer (kann X sein)\n",
    "    if not re.match(r'^\\d{7}[\\dX]$', issn_clean):\n",
    "        return False, \"ISSN: UngÃ¼ltiges Format\"\n",
    "    \n",
    "    # PrÃ¼fziffer validieren\n",
    "    try:\n",
    "        checksum = sum((8 - i) * int(c) if c != 'X' else 10 for i, c in enumerate(issn_clean[:7]))\n",
    "        check_digit = (11 - (checksum % 11)) % 11\n",
    "        expected = 'X' if check_digit == 10 else str(check_digit)\n",
    "        is_valid = issn_clean[7] == expected\n",
    "        return is_valid, \"ISSN\" if is_valid else f\"ISSN: UngÃ¼ltige PrÃ¼fziffer (erwartet: {expected})\"\n",
    "    except:\n",
    "        return False, \"ISSN: Validierungsfehler\"\n",
    "\n",
    "# ISBN Validierung (falls vorhanden)\n",
    "if 'isbn' in df_vdeh.columns:\n",
    "    print(\"\\nğŸ“š ISBN Validierung:\")\n",
    "    df_vdeh[['isbn_valid', 'isbn_status']] = df_vdeh['isbn'].apply(\n",
    "        lambda x: pd.Series(validate_isbn(x))\n",
    "    )\n",
    "    \n",
    "    isbn_with_values = df_vdeh['isbn'].notna().sum()\n",
    "    if isbn_with_values > 0:\n",
    "        valid_count = df_vdeh['isbn_valid'].sum()\n",
    "        invalid_count = (df_vdeh['isbn_valid'] == False).sum()\n",
    "        \n",
    "        print(f\"   Gesamt ISBNs: {isbn_with_values:,}\")\n",
    "        print(f\"   âœ… GÃ¼ltig: {valid_count:,} ({valid_count/isbn_with_values*100:.1f}%)\")\n",
    "        print(f\"   âŒ UngÃ¼ltig: {invalid_count:,} ({invalid_count/isbn_with_values*100:.1f}%)\")\n",
    "        \n",
    "        # Beispiele ungÃ¼ltiger ISBNs\n",
    "        if invalid_count > 0:\n",
    "            print(\"\\n   ğŸ“‹ Beispiele ungÃ¼ltiger ISBNs:\")\n",
    "            invalid_sample = df_vdeh[df_vdeh['isbn_valid'] == False][['isbn', 'isbn_status']].head(3)\n",
    "            for _, row in invalid_sample.iterrows():\n",
    "                print(f\"      {row['isbn']} â†’ {row['isbn_status']}\")\n",
    "    else:\n",
    "        print(\"   â„¹ï¸  Keine ISBN-Werte vorhanden\")\n",
    "else:\n",
    "    print(\"\\nğŸ“š ISBN: Spalte nicht vorhanden\")\n",
    "\n",
    "# ISSN Validierung\n",
    "if 'issn' in df_vdeh.columns:\n",
    "    print(\"\\nğŸ“° ISSN Validierung:\")\n",
    "    df_vdeh[['issn_valid', 'issn_status']] = df_vdeh['issn'].apply(\n",
    "        lambda x: pd.Series(validate_issn(x))\n",
    "    )\n",
    "    \n",
    "    issn_with_values = df_vdeh['issn'].notna().sum()\n",
    "    if issn_with_values > 0:\n",
    "        valid_count = df_vdeh['issn_valid'].sum()\n",
    "        invalid_count = (df_vdeh['issn_valid'] == False).sum()\n",
    "        \n",
    "        print(f\"   Gesamt ISSNs: {issn_with_values:,}\")\n",
    "        print(f\"   âœ… GÃ¼ltig: {valid_count:,} ({valid_count/issn_with_values*100:.1f}%)\")\n",
    "        print(f\"   âŒ UngÃ¼ltig: {invalid_count:,} ({invalid_count/issn_with_values*100:.1f}%)\")\n",
    "        \n",
    "        # Beispiele ungÃ¼ltiger ISSNs\n",
    "        if invalid_count > 0:\n",
    "            print(\"\\n   ğŸ“‹ Beispiele ungÃ¼ltiger ISSNs:\")\n",
    "            invalid_sample = df_vdeh[df_vdeh['issn_valid'] == False][['issn', 'issn_status']].head(5)\n",
    "            for _, row in invalid_sample.iterrows():\n",
    "                print(f\"      {row['issn']} â†’ {row['issn_status']}\")\n",
    "        \n",
    "        # ISSN-Typen Ãœbersicht\n",
    "        if valid_count > 0:\n",
    "            print(\"\\n   ğŸ“Š Status-Ãœbersicht:\")\n",
    "            status_counts = df_vdeh['issn_status'].value_counts()\n",
    "            for status, count in status_counts.head(10).items():\n",
    "                if pd.notna(status):\n",
    "                    print(f\"      {status}: {count:,} ({count/issn_with_values*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"   â„¹ï¸  Keine ISSN-Werte vorhanden\")\n",
    "else:\n",
    "    print(\"\\nğŸ“° ISSN: Spalte nicht vorhanden\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¡ Hinweis: UngÃ¼ltige Nummern kÃ¶nnen durch Tippfehler,\")\n",
    "print(\"   fehlerhafte OCR-Erkennung oder Datenfehler entstehen.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890fb636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¢ === DATENTYP-OPTIMIERUNG ===\n",
      "ğŸ”§ Konvertiere Year-Spalte zu Int64...\n",
      "âœ… Year-Spalte optimiert: Int64\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¢ DATENTYP-OPTIMIERUNG\n",
    "print(\"ğŸ”¢ === DATENTYP-OPTIMIERUNG ===\")\n",
    "\n",
    "# Jahr-Spalte optimieren\n",
    "year_dtype = config.get('data_processing.dataframe.year_dtype', 'Int64')\n",
    "print(f\"ğŸ”§ Konvertiere Year-Spalte zu {year_dtype}...\")\n",
    "df_vdeh['year'] = df_vdeh['year'].astype(year_dtype)\n",
    "print(f\"âœ… Year-Spalte optimiert: {df_vdeh['year'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcfd4f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” === DATENVALIDIERUNG ===\n",
      "ğŸ“Š Gesamt Records: 58,760\n",
      "ğŸ“‹ Finale Spalten: 16\n",
      "\n",
      "ğŸ“‹ Kritische Felder:\n",
      "   id          :       0 null (  0.0%)\n",
      "   title       :  17,930 null ( 30.5%)\n",
      "   authors_str :       0 null (  0.0%)\n",
      "\n",
      "ğŸ“… Jahr-Statistiken:\n",
      "   Min: 1900.0, Max: 2017.0\n",
      "   Median: 1998.0, Null: 25,073\n",
      "\n",
      "ğŸ’¾ Finale Datentypen:\n",
      "   id             : object\n",
      "   title          : object\n",
      "   authors        : object\n",
      "   authors_affiliation: object\n",
      "   year           : Int64\n",
      "   publisher      : object\n",
      "   isbn           : object\n",
      "   issn           : object\n",
      "   authors_str    : object\n",
      "   num_authors    : int64\n",
      "   authors_affiliation_str: object\n",
      "   num_authors_affiliation: int64\n",
      "   isbn_valid     : object\n",
      "   isbn_status    : object\n",
      "   issn_valid     : object\n",
      "   issn_status    : object\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” DATENVALIDIERUNG\n",
    "print(\"ğŸ” === DATENVALIDIERUNG ===\")\n",
    "\n",
    "# Basis-Validierungen\n",
    "print(f\"ğŸ“Š Gesamt Records: {len(df_vdeh):,}\")\n",
    "print(f\"ğŸ“‹ Finale Spalten: {len(df_vdeh.columns)}\")\n",
    "\n",
    "# PrÃ¼fe kritische Felder\n",
    "critical_fields = ['id', 'title', 'authors_str']\n",
    "print(\"\\nğŸ“‹ Kritische Felder:\")\n",
    "for field in critical_fields:\n",
    "    if field in df_vdeh.columns:\n",
    "        null_count = df_vdeh[field].isnull().sum()\n",
    "        null_pct = null_count / len(df_vdeh) * 100\n",
    "        print(f\"   {field:12}: {null_count:7,} null ({null_pct:5.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   {field:12}: âš ï¸ Spalte fehlt!\")\n",
    "\n",
    "# Jahr-Bereich prÃ¼fen\n",
    "if 'year' in df_vdeh.columns:\n",
    "    year_stats = df_vdeh['year'].describe()\n",
    "    print(f\"\\nğŸ“… Jahr-Statistiken:\")\n",
    "    print(f\"   Min: {year_stats['min']}, Max: {year_stats['max']}\")\n",
    "    print(f\"   Median: {year_stats['50%']}, Null: {df_vdeh['year'].isnull().sum():,}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Finale Datentypen:\")\n",
    "for col, dtype in df_vdeh.dtypes.items():\n",
    "    print(f\"   {col:15}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09c987b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ === DATA PREPROCESSING ABGESCHLOSSEN ===\n",
      "âœ… Preprocessed Daten exportiert: /media/sz/Data/Bibo/analysis/data/vdeh/processed/02_preprocessed_data.parquet\n",
      "ğŸ“Š Records: 58,760\n",
      "ğŸ“‹ Spalten: 16\n",
      "ğŸ’¾ Finale DateigrÃ¶ÃŸe: 46.3 MB\n",
      "ğŸ“„ Metadaten gespeichert: /media/sz/Data/Bibo/analysis/data/vdeh/processed/02_metadata.json\n",
      "\n",
      "â¡ï¸  NÃ¤chster Schritt: 03_vdeh_language_detection.ipynb\n",
      "ğŸ’¾ Finale DateigrÃ¶ÃŸe: 46.3 MB\n",
      "ğŸ“„ Metadaten gespeichert: /media/sz/Data/Bibo/analysis/data/vdeh/processed/02_metadata.json\n",
      "\n",
      "â¡ï¸  NÃ¤chster Schritt: 03_vdeh_language_detection.ipynb\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ PREPROCESSED DATEN EXPORTIEREN\n",
    "output_path = processed_dir / '02_preprocessed_data.parquet'\n",
    "df_vdeh.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"ğŸ’¾ === DATA PREPROCESSING ABGESCHLOSSEN ===\")\n",
    "print(f\"âœ… Preprocessed Daten exportiert: {output_path}\")\n",
    "print(f\"ğŸ“Š Records: {len(df_vdeh):,}\")\n",
    "print(f\"ğŸ“‹ Spalten: {len(df_vdeh.columns)}\")\n",
    "print(f\"ğŸ’¾ Finale DateigrÃ¶ÃŸe: {df_vdeh.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Metadaten fÃ¼r nÃ¤chste Stufe\n",
    "metadata = {\n",
    "    'stage': '02_data_preprocessing',\n",
    "    'records_processed': len(df_vdeh),\n",
    "    'columns': list(df_vdeh.columns),\n",
    "    'data_types': {col: str(dtype) for col, dtype in df_vdeh.dtypes.items()},\n",
    "    'memory_mb': df_vdeh.memory_usage(deep=True).sum() / 1024**2,\n",
    "    'previous_stage': prev_metadata,\n",
    "    'processing_date': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "import json\n",
    "metadata_path = processed_dir / '02_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"ğŸ“„ Metadaten gespeichert: {metadata_path}\")\n",
    "print(f\"\\nâ¡ï¸  NÃ¤chster Schritt: 03_vdeh_language_detection.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibo-analysis-DoEGeq_l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
