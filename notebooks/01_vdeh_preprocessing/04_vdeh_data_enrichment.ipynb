{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b689b192",
   "metadata": {},
   "source": [
    "# VDEH Data Enrichment Pipeline\n",
    "\n",
    "**Fokus:** Datenanreicherung \u00fcber Deutsche Nationalbibliothek (DNB) API\n",
    "\n",
    "## \ud83c\udfaf Ziel\n",
    "- Identifikation unvollst\u00e4ndiger Datens\u00e4tze\n",
    "- Anreicherung fehlender Metadaten via DNB API (ISBN/ISSN)\n",
    "- Konsistenzpr\u00fcfung vorhandener Daten\n",
    "- Validierung und Qualit\u00e4tsverbesserung\n",
    "\n",
    "## \ud83d\udcda Input/Output\n",
    "- **Input**: `data/vdeh/processed/03_language_detected_data.parquet`\n",
    "- **Output**: `data/vdeh/processed/04_enriched_data.parquet`\n",
    "\n",
    "## \ud83d\udd17 API\n",
    "- **DNB SRU API**: https://www.dnb.de/DE/Professionell/Metadatendienste/Datenbezug/SRU/sru_node.html\n",
    "- **Abfrage**: ISBN/ISSN basierte Suche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f0dfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Konfiguration geladen: /media/sz/Data/Bibo/analysis/config.yaml\n",
      "\ud83d\udcc1 Projektroot: /media/sz/Data/Bibo/analysis\n",
      "\u2705 Konfiguration geladen\n",
      "\u2705 DNB API Funktionen geladen\n"
     ]
    }
   ],
   "source": "# \ud83d\udee0\ufe0f SETUP UND DATEN LADEN\nimport sys\nfrom pathlib import Path"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16182926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcc2 Daten geladen aus: /media/sz/Data/Bibo/analysis/data/vdeh/processed/03_language_detected_data.parquet\n",
      "\ud83d\udcca Records: 58,760\n",
      "\ud83d\udccb Spalten: ['id', 'title', 'authors', 'authors_affiliation', 'year', 'publisher', 'isbn', 'issn', 'authors_str', 'num_authors', 'authors_affiliation_str', 'num_authors_affiliation', 'isbn_valid', 'isbn_status', 'issn_valid', 'issn_status', 'lang_code', 'lang_confidence', 'lang_name']\n",
      "\ud83d\udcbe Memory: 49.9 MB\n",
      "\ud83d\udcbe Memory: 49.9 MB\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udcc2 DATEN AUS VORHERIGER STUFE LADEN\n",
    "processed_dir = config.project_root / config.get('paths.data.vdeh.processed')\n",
    "input_path = processed_dir / '03_language_detected_data.parquet'\n",
    "metadata_path = processed_dir / '03_metadata.json'\n",
    "\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Input-Datei nicht gefunden: {input_path}\\n\"\n",
    "                          \"Bitte f\u00fchren Sie zuerst 03_vdeh_language_detection.ipynb aus.\")\n",
    "\n",
    "# Daten laden\n",
    "df_vdeh = pd.read_parquet(input_path)\n",
    "\n",
    "# Vorherige Metadaten laden\n",
    "with open(metadata_path, 'r') as f:\n",
    "    prev_metadata = json.load(f)\n",
    "\n",
    "print(f\"\ud83d\udcc2 Daten geladen aus: {input_path}\")\n",
    "print(f\"\ud83d\udcca Records: {len(df_vdeh):,}\")\n",
    "print(f\"\ud83d\udccb Spalten: {list(df_vdeh.columns)}\")\n",
    "print(f\"\ud83d\udcbe Memory: {df_vdeh.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Quality Scores anzeigen\n",
    "if 'completeness_score' in df_vdeh.columns:\n",
    "    avg_completeness = df_vdeh['completeness_score'].mean()\n",
    "    print(f\"\ud83d\udcca Durchschnittliche Vollst\u00e4ndigkeit: {avg_completeness:.1f}%\")\n",
    "    \n",
    "    if 'quality_category' in df_vdeh.columns:\n",
    "        quality_dist = df_vdeh['quality_category'].value_counts()\n",
    "        print(f\"\ud83d\udcca Qualit\u00e4ts-Verteilung:\")\n",
    "        for cat, count in quality_dist.items():\n",
    "            print(f\"   {cat}: {count:,} ({count/len(df_vdeh)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "003af9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d === KANDIDATEN-IDENTIFIKATION ===\n",
      "\n",
      "\ud83d\udccb Kriterium 1: ISBN vorhanden (Pr\u00fcfung aller Datens\u00e4tze mit ISBN)\n",
      "   ISBN-Kandidaten (alle): 11,415\n",
      "     - Vollst\u00e4ndige Datens\u00e4tze: 7,763\n",
      "     - Unvollst\u00e4ndig (Titel): 655\n",
      "     - Unvollst\u00e4ndig (Autoren): 3,423\n",
      "     - Unvollst\u00e4ndig (Jahr): 879\n",
      "\n",
      "   ISSN-Kandidaten (nur unvollst\u00e4ndig): 679\n",
      "     - Fehlender Titel: 2\n",
      "     - Fehlende Autoren: 667\n",
      "     - Fehlendes Jahr: 650\n",
      "\n",
      "\u2705 Gesamt Anreicherungs-Kandidaten (mit ISBN/ISSN): 11,415\n",
      "\n",
      "\ud83d\udccb Kriterium 2: Ohne ISBN aber mit Titel + Autoren (DNB Titel/Autor-Suche)\n",
      "   Kandidaten: 8,901\n",
      "     - Mit Titel: 8,901\n",
      "     - Mit Autoren: 8,901\n",
      "\n",
      "\ud83c\udfaf Finale Anreicherungs-Kandidaten: 20,316\n",
      "   Mit ISBN: 11,415\n",
      "   Mit ISSN: 721\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udd0d KANDIDATEN F\u00dcR ANREICHERUNG IDENTIFIZIEREN\n",
    "print(\"\ud83d\udd0d === KANDIDATEN-IDENTIFIKATION ===\\n\")\n",
    "\n",
    "# Kriterien f\u00fcr Anreicherungskandidaten\n",
    "enrichment_candidates = pd.DataFrame()\n",
    "\n",
    "# 1. Alle Records mit ISBN (unabh\u00e4ngig von Vollst\u00e4ndigkeit)\n",
    "print(\"\ud83d\udccb Kriterium 1: ISBN vorhanden (Pr\u00fcfung aller Datens\u00e4tze mit ISBN)\")\n",
    "\n",
    "# ISBN-basierte Kandidaten - ALLE mit ISBN\n",
    "if 'isbn' in df_vdeh.columns:\n",
    "    has_isbn = df_vdeh['isbn'].notna()\n",
    "    \n",
    "    isbn_candidates = df_vdeh[has_isbn].copy()\n",
    "    \n",
    "    # Statistiken f\u00fcr \u00dcberblick\n",
    "    missing_title = isbn_candidates['title'].isna()\n",
    "    missing_authors = (isbn_candidates['authors_str'].isna()) | (isbn_candidates['authors_str'] == '')\n",
    "    missing_year = isbn_candidates['year'].isna()\n",
    "    \n",
    "    print(f\"   ISBN-Kandidaten (alle): {len(isbn_candidates):,}\")\n",
    "    print(f\"     - Vollst\u00e4ndige Datens\u00e4tze: {(~missing_title & ~missing_authors & ~missing_year).sum():,}\")\n",
    "    print(f\"     - Unvollst\u00e4ndig (Titel): {missing_title.sum():,}\")\n",
    "    print(f\"     - Unvollst\u00e4ndig (Autoren): {missing_authors.sum():,}\")\n",
    "    print(f\"     - Unvollst\u00e4ndig (Jahr): {missing_year.sum():,}\")\n",
    "\n",
    "# ISSN-basierte Kandidaten - nur bei unvollst\u00e4ndigen Metadaten\n",
    "if 'issn' in df_vdeh.columns:\n",
    "    has_issn = df_vdeh['issn'].notna()\n",
    "    missing_title = df_vdeh['title'].isna()\n",
    "    missing_authors = (df_vdeh['authors_str'].isna()) | (df_vdeh['authors_str'] == '')\n",
    "    missing_year = df_vdeh['year'].isna()\n",
    "    \n",
    "    issn_candidates = df_vdeh[\n",
    "        has_issn & (missing_title | missing_authors | missing_year)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"\\n   ISSN-Kandidaten (nur unvollst\u00e4ndig): {len(issn_candidates):,}\")\n",
    "    print(f\"     - Fehlender Titel: {issn_candidates['title'].isna().sum():,}\")\n",
    "    print(f\"     - Fehlende Autoren: {(issn_candidates['authors_str'].isna() | (issn_candidates['authors_str'] == '')).sum():,}\")\n",
    "    print(f\"     - Fehlendes Jahr: {issn_candidates['year'].isna().sum():,}\")\n",
    "\n",
    "# Kombiniere Kandidaten\n",
    "all_candidates = pd.concat([isbn_candidates, issn_candidates]).drop_duplicates(subset=['id'])\n",
    "print(f\"\\n\u2705 Gesamt Anreicherungs-Kandidaten (mit ISBN/ISSN): {len(all_candidates):,}\")\n",
    "\n",
    "# 2. Records OHNE ISBN aber MIT Titel + Autoren (f\u00fcr DNB-Suche via Titel/Autor)\n",
    "no_isbn_but_searchable = df_vdeh[\n",
    "    (df_vdeh['isbn'].isna()) &\n",
    "    (df_vdeh['title'].notna()) &\n",
    "    (df_vdeh['authors_str'].notna()) &\n",
    "    (df_vdeh['authors_str'] != '')\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Kriterium 2: Ohne ISBN aber mit Titel + Autoren (DNB Titel/Autor-Suche)\")\n",
    "print(f\"   Kandidaten: {len(no_isbn_but_searchable):,}\")\n",
    "print(f\"     - Mit Titel: {no_isbn_but_searchable['title'].notna().sum():,}\")\n",
    "print(f\"     - Mit Autoren: {(no_isbn_but_searchable['authors_str'].notna() & (no_isbn_but_searchable['authors_str'] != '')).sum():,}\")\n",
    "\n",
    "# Finale Kandidatenliste (unique): ISBN-Kandidaten ODER Titel+Autor-Kandidaten\n",
    "final_candidates = df_vdeh[\n",
    "    # ENTWEDER: ISBN vorhanden (unabh\u00e4ngig von Vollst\u00e4ndigkeit)\n",
    "    (df_vdeh['isbn'].notna()) |\n",
    "    # ODER: Kein ISBN aber Titel + Autoren vorhanden\n",
    "    (\n",
    "        (df_vdeh['isbn'].isna()) &\n",
    "        (df_vdeh['title'].notna()) &\n",
    "        (df_vdeh['authors_str'].notna()) &\n",
    "        (df_vdeh['authors_str'] != '')\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Finale Anreicherungs-Kandidaten: {len(final_candidates):,}\")\n",
    "print(f\"   Mit ISBN: {final_candidates['isbn'].notna().sum():,}\")\n",
    "print(f\"   Mit ISSN: {final_candidates['issn'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d57f67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83c\udf10 === DNB API STATUS ===\n",
      "\n",
      "\u2705 DNB API Funktionen aus src/dnb_api.py geladen\n",
      "   Base URL: https://services.dnb.de/sru/dnb\n",
      "   Schema: MARC21-xml\n",
      "   Verf\u00fcgbare Funktionen:\n",
      "     - query_dnb_by_isbn(isbn, max_records=1)\n",
      "     - query_dnb_by_issn(issn, max_records=1)\n",
      "     - query_dnb_by_title_author(title, author=None, max_records=1)\n"
     ]
    }
   ],
   "source": [
    "# \ud83c\udf10 DNB API STATUS\n",
    "print(\"\ud83c\udf10 === DNB API STATUS ===\\n\")\n",
    "\n",
    "print(\"\u2705 DNB API Funktionen aus src/dnb_api.py geladen\")\n",
    "print(f\"   Base URL: {DNB_SRU_BASE}\")\n",
    "print(f\"   Schema: MARC21-xml\")\n",
    "print(f\"   Verf\u00fcgbare Funktionen:\")\n",
    "print(f\"     - query_dnb_by_isbn(isbn, max_records=1)\")\n",
    "print(f\"     - query_dnb_by_issn(issn, max_records=1)\")\n",
    "print(f\"     - query_dnb_by_title_author(title, author=None, max_records=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e86af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 === DNB DATENABFRAGE ===\n",
      "\n",
      "\u2699\ufe0f  Konfiguration:\n",
      "   Rate Limit: 0.5s pro Anfrage\n",
      "   Save Interval: Alle 50 Queries\n",
      "   Output: dnb_raw_data.parquet\n",
      "\n",
      "\ud83d\udcc2 Lade vorhandene DNB-Daten...\n",
      "   Bereits abgefragt: 11,383\n",
      "   Davon erfolgreich: 6,232\n",
      "\n",
      "\ud83d\udccb Extrahiere ISBN/ISSN aus 20,316 Kandidaten...\n",
      "   ISBN-Queries: 11,415\n",
      "   ISSN-Queries: 0\n",
      "   Gesamt: 11,415\n",
      "\n",
      "\ud83d\udd0d Abgleich mit vorhandenen Daten:\n",
      "   Bereits vorhanden: 11,415\n",
      "   Neu abzufragen: 0\n",
      "\n",
      "\u2705 Alle ISBN/ISSN bereits in DNB-Daten vorhanden - keine neuen Abfragen n\u00f6tig\n",
      "\n",
      "\ud83d\udcca === GESAMT DNB-DATEN ===\n",
      "   Total Records: 11,383\n",
      "   Erfolgreich: 6,232\n",
      "   Nicht gefunden: 5,151\n",
      "\n",
      "\u2705 DNB-Daten verf\u00fcgbar als: dnb_data_df\n",
      "   Shape: (11383, 8)\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\ude80 DNB DATENABFRAGE\n",
    "print(\"\ud83d\ude80 === DNB DATENABFRAGE ===\\n\")\n",
    "\n",
    "# Konfiguration\n",
    "RATE_LIMIT_DELAY = 0.5  # Sekunden zwischen Anfragen\n",
    "SAVE_INTERVAL = 50  # Speichere alle N Abfragen\n",
    "DNB_DATA_FILE = processed_dir / 'dnb_raw_data.parquet'\n",
    "\n",
    "print(f\"\u2699\ufe0f  Konfiguration:\")\n",
    "print(f\"   Rate Limit: {RATE_LIMIT_DELAY}s pro Anfrage\")\n",
    "print(f\"   Save Interval: Alle {SAVE_INTERVAL} Queries\")\n",
    "print(f\"   Output: {DNB_DATA_FILE.name}\")\n",
    "\n",
    "# Lade vorhandene DNB-Daten (falls vorhanden)\n",
    "if DNB_DATA_FILE.exists():\n",
    "    print(f\"\\n\ud83d\udcc2 Lade vorhandene DNB-Daten...\")\n",
    "    dnb_data_df = pd.read_parquet(DNB_DATA_FILE)\n",
    "    print(f\"   Bereits abgefragt: {len(dnb_data_df):,}\")\n",
    "    print(f\"   Davon erfolgreich: {(dnb_data_df['dnb_found'] == True).sum():,}\")\n",
    "else:\n",
    "    print(f\"\\n\ud83d\udcc2 Keine vorhandenen DNB-Daten gefunden - starte neue Abfrage\")\n",
    "    dnb_data_df = pd.DataFrame(columns=[\n",
    "        'vdeh_id', 'query_type', 'query_value',\n",
    "        'dnb_found', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher'\n",
    "    ])\n",
    "\n",
    "# Sammle ISBN/ISSN aus Kandidaten\n",
    "print(f\"\\n\ud83d\udccb Extrahiere ISBN/ISSN aus {len(final_candidates):,} Kandidaten...\")\n",
    "\n",
    "queries_isbn = final_candidates[final_candidates['isbn'].notna()][['id', 'isbn']].copy()\n",
    "queries_isbn.columns = ['vdeh_id', 'query_value']\n",
    "queries_isbn['query_type'] = 'ISBN'\n",
    "\n",
    "queries_issn = final_candidates[\n",
    "    final_candidates['isbn'].isna() & final_candidates['issn'].notna()\n",
    "][['id', 'issn']].copy()\n",
    "queries_issn.columns = ['vdeh_id', 'query_value']\n",
    "queries_issn['query_type'] = 'ISSN'\n",
    "\n",
    "all_queries = pd.concat([queries_isbn, queries_issn], ignore_index=True)\n",
    "\n",
    "print(f\"   ISBN-Queries: {len(queries_isbn):,}\")\n",
    "print(f\"   ISSN-Queries: {len(queries_issn):,}\")\n",
    "print(f\"   Gesamt: {len(all_queries):,}\")\n",
    "\n",
    "# Filtere bereits abgefragte ISBN/ISSN\n",
    "if len(dnb_data_df) > 0:\n",
    "    # Erstelle Set der bereits abgefragten query_values\n",
    "    already_queried = set(dnb_data_df['query_value'])\n",
    "    \n",
    "    # Filtere nur neue Queries\n",
    "    new_queries = all_queries[~all_queries['query_value'].isin(already_queried)].copy()\n",
    "    \n",
    "    print(f\"\\n\ud83d\udd0d Abgleich mit vorhandenen Daten:\")\n",
    "    print(f\"   Bereits vorhanden: {len(all_queries) - len(new_queries):,}\")\n",
    "    print(f\"   Neu abzufragen: {len(new_queries):,}\")\n",
    "else:\n",
    "    new_queries = all_queries\n",
    "    print(f\"\\n\ud83d\udd0d Alle {len(new_queries):,} Queries sind neu\")\n",
    "\n",
    "# Nur abfragen wenn neue Queries vorhanden\n",
    "if len(new_queries) > 0:\n",
    "    print(f\"\\n\ud83d\udd04 Starte DNB-Abfrage f\u00fcr {len(new_queries):,} neue Queries...\\n\")\n",
    "    \n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    results = []\n",
    "    stats = {'found': 0, 'not_found': 0}\n",
    "    query_count = 0\n",
    "    \n",
    "    for _, row in tqdm(new_queries.iterrows(), total=len(new_queries), desc=\"\ud83d\udd0d DNB API\", unit=\"queries\"):\n",
    "        # API-Abfrage\n",
    "        dnb_result = None\n",
    "        if row['query_type'] == 'ISBN':\n",
    "            dnb_result = query_dnb_by_isbn(row['query_value'])\n",
    "        elif row['query_type'] == 'ISSN':\n",
    "            dnb_result = query_dnb_by_issn(row['query_value'])\n",
    "        \n",
    "        # Ergebnis speichern\n",
    "        result_row = {\n",
    "            'vdeh_id': row['vdeh_id'],\n",
    "            'query_type': row['query_type'],\n",
    "            'query_value': row['query_value'],\n",
    "            'dnb_found': dnb_result is not None,\n",
    "            'dnb_title': dnb_result.get('title') if dnb_result else None,\n",
    "            'dnb_authors': ', '.join(dnb_result.get('authors', [])) if dnb_result else None,\n",
    "            'dnb_year': dnb_result.get('year') if dnb_result else None,\n",
    "            'dnb_publisher': dnb_result.get('publisher') if dnb_result else None\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if dnb_result:\n",
    "            stats['found'] += 1\n",
    "        else:\n",
    "            stats['not_found'] += 1\n",
    "        \n",
    "        query_count += 1\n",
    "        \n",
    "        # Regelm\u00e4\u00dfiges Speichern (alle SAVE_INTERVAL Queries)\n",
    "        if query_count % SAVE_INTERVAL == 0:\n",
    "            # Merge mit vorhandenen Daten\n",
    "            new_results_df = pd.DataFrame(results)\n",
    "            dnb_data_df = pd.concat([dnb_data_df, new_results_df], ignore_index=True)\n",
    "            \n",
    "            # Speichern\n",
    "            dnb_data_df.to_parquet(DNB_DATA_FILE, index=False)\n",
    "            \n",
    "            # Reset results f\u00fcr n\u00e4chste Batch\n",
    "            results = []\n",
    "            \n",
    "            print(f\"\ud83d\udcbe Zwischenspeicherung: {query_count}/{len(new_queries)} Queries abgefragt\")\n",
    "        \n",
    "        # Rate Limiting\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Finale Speicherung (restliche Ergebnisse)\n",
    "    if len(results) > 0:\n",
    "        new_results_df = pd.DataFrame(results)\n",
    "        dnb_data_df = pd.concat([dnb_data_df, new_results_df], ignore_index=True)\n",
    "        dnb_data_df.to_parquet(DNB_DATA_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcbe DNB-Daten gespeichert: {DNB_DATA_FILE.name}\")\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(f\"\\n\ud83d\udcca === NEUE ABFRAGEN ===\")\n",
    "    print(f\"   Neue Queries: {len(new_queries):,}\")\n",
    "    print(f\"   \u2705 Gefunden: {stats['found']:,} ({stats['found']/len(new_queries)*100:.1f}%)\")\n",
    "    print(f\"   \u274c Nicht gefunden: {stats['not_found']:,} ({stats['not_found']/len(new_queries)*100:.1f}%)\")\n",
    "    print(f\"   \ud83d\udcbe Zwischenspeicherungen: {len(new_queries)//SAVE_INTERVAL}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n\u2705 Alle ISBN/ISSN bereits in DNB-Daten vorhanden - keine neuen Abfragen n\u00f6tig\")\n",
    "\n",
    "# Gesamtstatistik\n",
    "print(f\"\\n\ud83d\udcca === GESAMT DNB-DATEN ===\")\n",
    "print(f\"   Total Records: {len(dnb_data_df):,}\")\n",
    "print(f\"   Erfolgreich: {(dnb_data_df['dnb_found'] == True).sum():,}\")\n",
    "print(f\"   Nicht gefunden: {(dnb_data_df['dnb_found'] == False).sum():,}\")\n",
    "\n",
    "print(f\"\\n\u2705 DNB-Daten verf\u00fcgbar als: dnb_data_df\")\n",
    "print(f\"   Shape: {dnb_data_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ee36888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vdeh_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>query_value</th>\n",
       "      <th>dnb_found</th>\n",
       "      <th>dnb_title</th>\n",
       "      <th>dnb_authors</th>\n",
       "      <th>dnb_year</th>\n",
       "      <th>dnb_publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aleph-publish:000000023</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-428-05409-1</td>\n",
       "      <td>True</td>\n",
       "      <td>\u0098Die\u009c deutsche Roheisenindustrie 1871 - 1913</td>\n",
       "      <td>Krengel, Jochen</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Duncker und Humblot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aleph-publish:000000038</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-527-26070-6</td>\n",
       "      <td>True</td>\n",
       "      <td>Korrosionskunde im Experiment</td>\n",
       "      <td>Heitz, Ewald, Henkhaus, Rolf, Rahmel, Alfred</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Verlag Chemie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aleph-publish:000000039</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-802-74302-4</td>\n",
       "      <td>True</td>\n",
       "      <td>Brandschutz und Feuersicherheit in Arbeitssta\u0308...</td>\n",
       "      <td>Isterling, Fritz</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Vulkan-Verlag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aleph-publish:000000040</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-802-70475-4</td>\n",
       "      <td>True</td>\n",
       "      <td>Lagerung von staubfo\u0308rmigen Schu\u0308ttgu\u0308tern in ...</td>\n",
       "      <td>Koster, Karl H.</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Vulkan-Verlag Classen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aleph-publish:000000042</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>0-853-34164-8</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vdeh_id query_type    query_value  dnb_found  \\\n",
       "0  aleph-publish:000000023       ISBN  3-428-05409-1       True   \n",
       "1  aleph-publish:000000038       ISBN  3-527-26070-6       True   \n",
       "2  aleph-publish:000000039       ISBN  3-802-74302-4       True   \n",
       "3  aleph-publish:000000040       ISBN  3-802-70475-4       True   \n",
       "4  aleph-publish:000000042       ISBN  0-853-34164-8      False   \n",
       "\n",
       "                                           dnb_title  \\\n",
       "0       \u0098Die\u009c deutsche Roheisenindustrie 1871 - 1913   \n",
       "1                      Korrosionskunde im Experiment   \n",
       "2  Brandschutz und Feuersicherheit in Arbeitssta\u0308...   \n",
       "3  Lagerung von staubfo\u0308rmigen Schu\u0308ttgu\u0308tern in ...   \n",
       "4                                               None   \n",
       "\n",
       "                                    dnb_authors  dnb_year  \\\n",
       "0                               Krengel, Jochen    1983.0   \n",
       "1  Heitz, Ewald, Henkhaus, Rolf, Rahmel, Alfred    1983.0   \n",
       "2                              Isterling, Fritz    1984.0   \n",
       "3                               Koster, Karl H.    1983.0   \n",
       "4                                          None       NaN   \n",
       "\n",
       "           dnb_publisher  \n",
       "0    Duncker und Humblot  \n",
       "1          Verlag Chemie  \n",
       "2          Vulkan-Verlag  \n",
       "3  Vulkan-Verlag Classen  \n",
       "4                   None  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bb8db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6232 von 11383 Datens\u00e4tze bei DNB gefunden\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dnb_data_df.dnb_found.sum()} von {dnb_data_df.shape[0]} Datens\u00e4tze bei DNB gefunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97aaf6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d === DNB TITEL/AUTOR-SUCHE ===\n",
      "\n",
      "\u2699\ufe0f  Konfiguration:\n",
      "   Rate Limit: 0.5s pro Anfrage\n",
      "   Save Interval: Alle 50 Queries\n",
      "   Output: dnb_title_author_data.parquet\n",
      "   TA f\u00fcr alle Titel+Autoren: True\n",
      "\n",
      "\ud83d\udcc2 Lade vorhandene Titel/Autor-Suchdaten...\n",
      "   Bereits abgefragt: 8,901\n",
      "   Davon erfolgreich: 2,724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83d\udccb Titel/Autor-Kandidaten: 16,804\n",
      "   Mit Titel: 16,804\n",
      "   Mit Autoren: 16,804\n",
      "   Gesamt Titel/Autor-Queries (vor Deduplikation): 16,804\n",
      "\n",
      "\ud83d\udd0d Abgleich mit vorhandenen Daten:\n",
      "   Bereits vorhanden: 8,901\n",
      "   Neu abzufragen: 7,903\n",
      "\n",
      "\ud83d\udd04 Starte DNB Titel/Autor-Abfrage f\u00fcr 7,903 neue Queries...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a33d9c625964c9a8e5c44c4b82cea52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\ud83d\udd0d DNB Titel/Autor:   0%|          | 0/7903 [00:00<?, ?queries/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcbe Zwischenspeicherung: 50/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1500/7903 Queries abgefragt\n",
      "   \u26a0\ufe0f Fehler bei Titel/Autor-Suche 'Simulationstechniken in der Materialwissenschaft': HTTPSConnectionPool(host='services.dnb.de', port=443): Max retries exceeded with url: /sru/dnb?version=1.1&operation=searchRetrieve&query=tit%3DSimulationstechniken+in+der+Materialwissenschaft+and+per%3DKlimanek&recordSchema=MARC21-xml&maximumRecords=1 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "   \u26a0\ufe0f Fehler bei Titel/Autor-Suche 'Simulationstechniken in der Materialwissenschaft': HTTPSConnectionPool(host='services.dnb.de', port=443): Max retries exceeded with url: /sru/dnb?version=1.1&operation=searchRetrieve&query=tit%3DSimulationstechniken+in+der+Materialwissenschaft+and+per%3DKlimanek&recordSchema=MARC21-xml&maximumRecords=1 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "\ud83d\udcbe Zwischenspeicherung: 1550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 1950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2050/7903 Queries abgefragt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_953440/1790920450.py:109: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dnb_title_df = pd.concat([dnb_title_df, new_results_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcbe Zwischenspeicherung: 2100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 2950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 3950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 4950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 5950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 6950/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7000/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7050/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7100/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7150/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7200/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7250/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7300/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7350/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7400/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7450/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7500/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7550/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7600/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7650/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7700/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7750/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7800/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7850/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7900/7903 Queries abgefragt\n",
      "\ud83d\udcbe Zwischenspeicherung: 7900/7903 Queries abgefragt\n",
      "\n",
      "\ud83d\udcbe DNB Titel/Autor-Daten gespeichert: dnb_title_author_data.parquet\n",
      "\n",
      "\ud83d\udcca === NEUE TITEL/AUTOR-ABFRAGEN ===\n",
      "   Neue Queries: 7,903\n",
      "   \u2705 Gefunden: 3,005 (38.0%)\n",
      "   \u274c Nicht gefunden: 4,898 (62.0%)\n",
      "   \ud83d\udcbe Zwischenspeicherungen: 158\n",
      "\n",
      "\ud83d\udcca === GESAMT TITEL/AUTOR-DATEN ===\n",
      "   Total Records: 16,804\n",
      "   Erfolgreich: 5,729\n",
      "   Nicht gefunden: 11,075\n",
      "\n",
      "\u2705 Titel/Autor-Daten verf\u00fcgbar als: dnb_title_df\n",
      "   Shape: (16804, 9)\n",
      "\n",
      "\ud83d\udcbe DNB Titel/Autor-Daten gespeichert: dnb_title_author_data.parquet\n",
      "\n",
      "\ud83d\udcca === NEUE TITEL/AUTOR-ABFRAGEN ===\n",
      "   Neue Queries: 7,903\n",
      "   \u2705 Gefunden: 3,005 (38.0%)\n",
      "   \u274c Nicht gefunden: 4,898 (62.0%)\n",
      "   \ud83d\udcbe Zwischenspeicherungen: 158\n",
      "\n",
      "\ud83d\udcca === GESAMT TITEL/AUTOR-DATEN ===\n",
      "   Total Records: 16,804\n",
      "   Erfolgreich: 5,729\n",
      "   Nicht gefunden: 11,075\n",
      "\n",
      "\u2705 Titel/Autor-Daten verf\u00fcgbar als: dnb_title_df\n",
      "   Shape: (16804, 9)\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udd0d DNB TITEL/AUTOR-SUCHE (auch zus\u00e4tzlich zu ID-Variante, f\u00fcr maximale Redundanz)\n",
    "print(\"\ud83d\udd0d === DNB TITEL/AUTOR-SUCHE ===\\n\")\n",
    "\n",
    "# Konfiguration\n",
    "DNB_TITLE_DATA_FILE = processed_dir / 'dnb_title_author_data.parquet'\n",
    "ALWAYS_TA_FOR_ALL_WITH_TITLE_AUTHORS = True  # Variante A: maximale Redundanz\n",
    "\n",
    "print(f\"\u2699\ufe0f  Konfiguration:\")\n",
    "print(f\"   Rate Limit: {RATE_LIMIT_DELAY}s pro Anfrage\")\n",
    "print(f\"   Save Interval: Alle {SAVE_INTERVAL} Queries\")\n",
    "print(f\"   Output: {DNB_TITLE_DATA_FILE.name}\")\n",
    "print(f\"   TA f\u00fcr alle Titel+Autoren: {ALWAYS_TA_FOR_ALL_WITH_TITLE_AUTHORS}\")\n",
    "\n",
    "# Lade vorhandene Titel/Autor-Suchdaten (falls vorhanden)\n",
    "if DNB_TITLE_DATA_FILE.exists():\n",
    "    print(f\"\\n\ud83d\udcc2 Lade vorhandene Titel/Autor-Suchdaten...\")\n",
    "    dnb_title_df = pd.read_parquet(DNB_TITLE_DATA_FILE)\n",
    "    print(f\"   Bereits abgefragt: {len(dnb_title_df):,}\")\n",
    "    print(f\"   Davon erfolgreich: {(dnb_title_df['dnb_found'] == True).sum():,}\")\n",
    "else:\n",
    "    print(f\"\\n\ud83d\udcc2 Keine vorhandenen Titel/Autor-Suchdaten gefunden - starte neue Abfrage\")\n",
    "    dnb_title_df = pd.DataFrame(columns=[\n",
    "        'vdeh_id', 'query_type', 'title', 'author',\n",
    "        'dnb_found', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher'\n",
    "    ])\n",
    "\n",
    "# Identifiziere Kandidaten f\u00fcr Titel/Autor-Suche\n",
    "if ALWAYS_TA_FOR_ALL_WITH_TITLE_AUTHORS:\n",
    "    title_author_candidates = df_vdeh[\n",
    "        (df_vdeh['title'].notna()) &\n",
    "        (df_vdeh['authors_str'].notna()) &\n",
    "        (df_vdeh['authors_str'] != '')\n",
    "    ].copy()\n",
    "else:\n",
    "    title_author_candidates = df_vdeh[\n",
    "        (df_vdeh['isbn'].isna()) &\n",
    "        (df_vdeh['issn'].isna()) &\n",
    "        (df_vdeh['title'].notna()) &\n",
    "        (df_vdeh['authors_str'].notna()) &\n",
    "        (df_vdeh['authors_str'] != '')\n",
    "    ].copy()\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Titel/Autor-Kandidaten: {len(title_author_candidates):,}\")\n",
    "print(f\"   Mit Titel: {title_author_candidates['title'].notna().sum():,}\")\n",
    "print(f\"   Mit Autoren: {(title_author_candidates['authors_str'].notna() & (title_author_candidates['authors_str'] != '')).sum():,}\")\n",
    "\n",
    "# Erstelle Query-Liste\n",
    "title_queries = title_author_candidates[['id', 'title', 'authors_str']].copy()\n",
    "title_queries.columns = ['vdeh_id', 'title', 'author']\n",
    "title_queries['query_type'] = 'TITLE_AUTHOR'\n",
    "\n",
    "print(f\"   Gesamt Titel/Autor-Queries (vor Deduplikation): {len(title_queries):,}\")\n",
    "\n",
    "# Filtere bereits abgefragte Titel/Autor-Kombinationen\n",
    "if len(dnb_title_df) > 0:\n",
    "    # Erstelle Set der bereits abgefragten vdeh_ids\n",
    "    already_queried = set(dnb_title_df['vdeh_id'])\n",
    "    \n",
    "    # Filtere nur neue Queries\n",
    "    new_title_queries = title_queries[~title_queries['vdeh_id'].isin(already_queried)].copy()\n",
    "    \n",
    "    print(f\"\\n\ud83d\udd0d Abgleich mit vorhandenen Daten:\")\n",
    "    print(f\"   Bereits vorhanden: {len(title_queries) - len(new_title_queries):,}\")\n",
    "    print(f\"   Neu abzufragen: {len(new_title_queries):,}\")\n",
    "else:\n",
    "    new_title_queries = title_queries\n",
    "    print(f\"\\n\ud83d\udd0d Alle {len(new_title_queries):,} Titel/Autor-Queries sind neu\")\n",
    "\n",
    "# Nur abfragen wenn neue Queries vorhanden\n",
    "if len(new_title_queries) > 0:\n",
    "    print(f\"\\n\ud83d\udd04 Starte DNB Titel/Autor-Abfrage f\u00fcr {len(new_title_queries):,} neue Queries...\\n\")\n",
    "    \n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    results = []\n",
    "    stats = {'found': 0, 'not_found': 0}\n",
    "    query_count = 0\n",
    "    \n",
    "    for _, row in tqdm(new_title_queries.iterrows(), total=len(new_title_queries), desc=\"\ud83d\udd0d DNB Titel/Autor\", unit=\"queries\"):\n",
    "        # API-Abfrage\n",
    "        dnb_result = query_dnb_by_title_author(row['title'], row['author'])\n",
    "        \n",
    "        # Ergebnis speichern\n",
    "        result_row = {\n",
    "            'vdeh_id': row['vdeh_id'],\n",
    "            'query_type': row['query_type'],\n",
    "            'title': row['title'],\n",
    "            'author': row['author'],\n",
    "            'dnb_found': dnb_result is not None,\n",
    "            'dnb_title': dnb_result.get('title') if dnb_result else None,\n",
    "            'dnb_authors': ', '.join(dnb_result.get('authors', [])) if dnb_result else None,\n",
    "            'dnb_year': dnb_result.get('year') if dnb_result else None,\n",
    "            'dnb_publisher': dnb_result.get('publisher') if dnb_result else None\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if dnb_result:\n",
    "            stats['found'] += 1\n",
    "        else:\n",
    "            stats['not_found'] += 1\n",
    "        \n",
    "        query_count += 1\n",
    "        \n",
    "        # Regelm\u00e4\u00dfiges Speichern (alle SAVE_INTERVAL Queries)\n",
    "        if query_count % SAVE_INTERVAL == 0:\n",
    "            # Merge mit vorhandenen Daten\n",
    "            new_results_df = pd.DataFrame(results)\n",
    "            dnb_title_df = pd.concat([dnb_title_df, new_results_df], ignore_index=True)\n",
    "            \n",
    "            # Speichern\n",
    "            dnb_title_df.to_parquet(DNB_TITLE_DATA_FILE, index=False)\n",
    "            \n",
    "            # Reset results f\u00fcr n\u00e4chste Batch\n",
    "            results = []\n",
    "            \n",
    "            print(f\"\ud83d\udcbe Zwischenspeicherung: {query_count}/{len(new_title_queries)} Queries abgefragt\")\n",
    "        \n",
    "        # Rate Limiting\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Finale Speicherung (restliche Ergebnisse)\n",
    "    if len(results) > 0:\n",
    "        new_results_df = pd.DataFrame(results)\n",
    "        dnb_title_df = pd.concat([dnb_title_df, new_results_df], ignore_index=True)\n",
    "        dnb_title_df.to_parquet(DNB_TITLE_DATA_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcbe DNB Titel/Autor-Daten gespeichert: {DNB_TITLE_DATA_FILE.name}\")\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(f\"\\n\ud83d\udcca === NEUE TITEL/AUTOR-ABFRAGEN ===\")\n",
    "    print(f\"   Neue Queries: {len(new_title_queries):,}\")\n",
    "    print(f\"   \u2705 Gefunden: {stats['found']:,} ({stats['found']/len(new_title_queries)*100:.1f}%)\")\n",
    "    print(f\"   \u274c Nicht gefunden: {stats['not_found']:,} ({stats['not_found']/len(new_title_queries)*100:.1f}%)\")\n",
    "    print(f\"   \ud83d\udcbe Zwischenspeicherungen: {len(new_title_queries)//SAVE_INTERVAL}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n\u2705 Alle Titel/Autor-Kombinationen bereits abgefragt - keine neuen Abfragen n\u00f6tig\")\n",
    "\n",
    "# Gesamtstatistik\n",
    "print(f\"\\n\ud83d\udcca === GESAMT TITEL/AUTOR-DATEN ===\")\n",
    "print(f\"   Total Records: {len(dnb_title_df):,}\")\n",
    "print(f\"   Erfolgreich: {(dnb_title_df['dnb_found'] == True).sum():,}\")\n",
    "print(f\"   Nicht gefunden: {(dnb_title_df['dnb_found'] == False).sum():,}\")\n",
    "\n",
    "print(f\"\\n\u2705 Titel/Autor-Daten verf\u00fcgbar als: dnb_title_df\")\n",
    "print(f\"   Shape: {dnb_title_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f008b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5729"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb_title_df.dnb_found.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13f121c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd17 === DNB-DATEN MERGE ===\n",
      "\n",
      "\u2705 ISBN/ISSN-basierte DNB-Daten (ID) gemerged \u2192 Spalten: dnb_title, dnb_authors, dnb_year, dnb_publisher\n",
      "   ID-Matches: 6,232\n",
      "\u2705 Titel/Autor-basierte DNB-Daten (TA) gemerged \u2192 Spalten: dnb_*_ta\n",
      "   TA-Matches: 5,729\n",
      "\n",
      "\ud83d\udcca === MERGE ZUSAMMENFASSUNG ===\n",
      "   Total Records: 58,760\n",
      "   Mit ID-DNB: 6,232\n",
      "   Mit TA-DNB: 5,729\n",
      "\n",
      "\u2705 df_enriched erstellt und bereit zum Speichern\n",
      "   Mit TA-DNB: 5,729\n",
      "\n",
      "\u2705 df_enriched erstellt und bereit zum Speichern\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udd17 DNB-DATEN MIT VDEH-DATEN ZUSAMMENF\u00dcHREN\n",
    "print(\"\ud83d\udd17 === DNB-DATEN MERGE ===\\n\")\n",
    "\n",
    "# Starte mit VDEH-Daten\n",
    "df_enriched = df_vdeh.copy()\n",
    "\n",
    "# 1. Merge ISBN/ISSN-basierte DNB-Daten (als ID-Variante)\n",
    "if len(dnb_data_df) > 0:\n",
    "    dnb_isbn_issn = dnb_data_df[dnb_data_df['dnb_found'] == True][\n",
    "        ['vdeh_id', 'query_type', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher']\n",
    "    ].rename(columns={'query_type': 'dnb_query_method'})\n",
    "    \n",
    "    df_enriched = df_enriched.merge(\n",
    "        dnb_isbn_issn,\n",
    "        left_on='id',\n",
    "        right_on='vdeh_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    if 'vdeh_id' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=['vdeh_id'], inplace=True)\n",
    "    if 'dnb_title_dup' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=[c for c in df_enriched.columns if c.endswith('_dup')], inplace=True)\n",
    "    print(f\"\u2705 ISBN/ISSN-basierte DNB-Daten (ID) gemerged \u2192 Spalten: dnb_title, dnb_authors, dnb_year, dnb_publisher\")\n",
    "    print(f\"   ID-Matches: {df_enriched['dnb_query_method'].notna().sum():,}\")\n",
    "\n",
    "# 2. Merge Titel/Autor-basierte DNB-Daten als separate Variante (_ta)\n",
    "if len(dnb_title_df) > 0:\n",
    "    dnb_title_matches = dnb_title_df[dnb_title_df['dnb_found'] == True][\n",
    "        ['vdeh_id', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher']\n",
    "    ].copy()\n",
    "    dnb_title_matches = dnb_title_matches.rename(columns={\n",
    "        'dnb_title': 'dnb_title_ta',\n",
    "        'dnb_authors': 'dnb_authors_ta',\n",
    "        'dnb_year': 'dnb_year_ta',\n",
    "        'dnb_publisher': 'dnb_publisher_ta'\n",
    "    })\n",
    "    df_enriched = df_enriched.merge(\n",
    "        dnb_title_matches,\n",
    "        left_on='id',\n",
    "        right_on='vdeh_id',\n",
    "        how='left'\n",
    "    )\n",
    "    if 'vdeh_id' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=['vdeh_id'], inplace=True)\n",
    "    print(f\"\u2705 Titel/Autor-basierte DNB-Daten (TA) gemerged \u2192 Spalten: dnb_*_ta\")\n",
    "    print(f\"   TA-Matches: {df_enriched[['dnb_title_ta','dnb_authors_ta','dnb_year_ta','dnb_publisher_ta']].notna().any(axis=1).sum():,}\")\n",
    "\n",
    "# 3. R\u00fcckw\u00e4rtskompatibilit\u00e4t: dnb_query_method belassen (zeigt ID vs Titel/Autor als Prim\u00e4rquelle)\n",
    "#    (wird k\u00fcnftig nur noch als Hinweis genutzt; Fusion vergleicht explizit beide Varianten)\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"\\n\ud83d\udcca === MERGE ZUSAMMENFASSUNG ===\")\n",
    "print(f\"   Total Records: {len(df_enriched):,}\")\n",
    "print(f\"   Mit ID-DNB: {df_enriched['dnb_query_method'].notna().sum():,}\")\n",
    "print(f\"   Mit TA-DNB: {df_enriched[['dnb_title_ta','dnb_authors_ta','dnb_year_ta','dnb_publisher_ta']].notna().any(axis=1).sum():,}\")\n",
    "\n",
    "print(f\"\\n\u2705 df_enriched erstellt und bereit zum Speichern\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4081f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd27 === DATENTYP-NORMALISIERUNG ===\n",
      "\n",
      "   year: 33,687 \u2192 33,687 (Int64)\n",
      "   dnb_year: 6,199 \u2192 6,199 (Int64)\n",
      "   dnb_year_ta: 4,445 \u2192 4,445 (Int64)\n",
      "\n",
      "\u2705 Datentypen normalisiert - bereit zum Speichern\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udd27 DATENTYP-NORMALISIERUNG (VOR dem Speichern!)\n",
    "print(\"\ud83d\udd27 === DATENTYP-NORMALISIERUNG ===\\n\")\n",
    "\n",
    "# Konvertiere Jahr-Spalten zu Int64 (verhindert float/int Konflikte bei der Fusion)\n",
    "year_columns = ['year', 'dnb_year', 'dnb_year_ta']\n",
    "\n",
    "for col in year_columns:\n",
    "    if col in df_enriched.columns:\n",
    "        # Konvertiere zu Int64, NaN bleiben NaN\n",
    "        original_count = df_enriched[col].notna().sum()\n",
    "        df_enriched[col] = pd.to_numeric(df_enriched[col], errors='coerce').astype('Int64')\n",
    "        new_count = df_enriched[col].notna().sum()\n",
    "        \n",
    "        print(f\"   {col}: {original_count:,} \u2192 {new_count:,} (Int64)\")\n",
    "        \n",
    "        if original_count != new_count:\n",
    "            print(f\"      \u26a0\ufe0f  {original_count - new_count:,} Werte konnten nicht konvertiert werden\")\n",
    "\n",
    "print(f\"\\n\u2705 Datentypen normalisiert - bereit zum Speichern\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8de03a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcbe === DATEN SPEICHERN ===\n",
      "\n",
      "\u2705 DNB-angereicherte Daten gespeichert: 04_dnb_enriched_data.parquet\n",
      "   Records: 58,760\n",
      "   Spalten: 28\n",
      "   Gr\u00f6\u00dfe: 4.3 MB\n",
      "\n",
      "\u2705 Metadaten gespeichert: 04_metadata.json\n",
      "\n",
      "\ud83d\udcca === DNB ENRICHMENT ABGESCHLOSSEN ===\n",
      "   Input: 58,760 VDEH Records\n",
      "   Output: 58,760 Records mit DNB-Daten\n",
      "   DNB-Queries: 28,187\n",
      "   ID-Variante verf\u00fcgbar: 6,232\n",
      "   TA-Variante verf\u00fcgbar: 5,729\n",
      "\n",
      "\u27a1\ufe0f  N\u00e4chster Schritt: 05_vdeh_data_fusion.ipynb\n",
      "   KI-gest\u00fctzte Fusion von VDEH und DNB Daten (beide Varianten)\n",
      "\n",
      "\ud83c\udf89 DNB Enrichment erfolgreich abgeschlossen!\n",
      "\n",
      "\u2705 Metadaten gespeichert: 04_metadata.json\n",
      "\n",
      "\ud83d\udcca === DNB ENRICHMENT ABGESCHLOSSEN ===\n",
      "   Input: 58,760 VDEH Records\n",
      "   Output: 58,760 Records mit DNB-Daten\n",
      "   DNB-Queries: 28,187\n",
      "   ID-Variante verf\u00fcgbar: 6,232\n",
      "   TA-Variante verf\u00fcgbar: 5,729\n",
      "\n",
      "\u27a1\ufe0f  N\u00e4chster Schritt: 05_vdeh_data_fusion.ipynb\n",
      "   KI-gest\u00fctzte Fusion von VDEH und DNB Daten (beide Varianten)\n",
      "\n",
      "\ud83c\udf89 DNB Enrichment erfolgreich abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udcbe DATEN SPEICHERN (vor KI-Fusion)\n",
    "print(\"\ud83d\udcbe === DATEN SPEICHERN ===\\n\")\n",
    "\n",
    "# Output-Pfade\n",
    "output_path = processed_dir / '04_dnb_enriched_data.parquet'\n",
    "metadata_output = processed_dir / '04_metadata.json'\n",
    "\n",
    "# 1. Parquet speichern\n",
    "df_enriched.to_parquet(output_path, index=False)\n",
    "print(f\"\u2705 DNB-angereicherte Daten gespeichert: {output_path.name}\")\n",
    "print(f\"   Records: {len(df_enriched):,}\")\n",
    "print(f\"   Spalten: {len(df_enriched.columns)}\")\n",
    "print(f\"   Gr\u00f6\u00dfe: {output_path.stat().st_size / 1024**2:.1f} MB\")\n",
    "\n",
    "# 2. Metadaten erstellen\n",
    "metadata = {\n",
    "    'step': '04_dnb_enrichment',\n",
    "    'input_file': '03_language_detected_data.parquet',\n",
    "    'output_file': '04_dnb_enriched_data.parquet',\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'record_count': len(df_enriched),\n",
    "    'columns': list(df_enriched.columns),\n",
    "    \n",
    "    # DNB Query Statistiken\n",
    "    'dnb_queries': {\n",
    "        'isbn_issn': {\n",
    "            'total_queries': len(dnb_data_df) if len(dnb_data_df) > 0 else 0,\n",
    "            'successful': int((dnb_data_df['dnb_found'] == True).sum()) if len(dnb_data_df) > 0 else 0,\n",
    "            'failed': int((dnb_data_df['dnb_found'] == False).sum()) if len(dnb_data_df) > 0 else 0\n",
    "        },\n",
    "        'title_author': {\n",
    "            'total_queries': len(dnb_title_df) if len(dnb_title_df) > 0 else 0,\n",
    "            'successful': int((dnb_title_df['dnb_found'] == True).sum()) if len(dnb_title_df) > 0 else 0,\n",
    "            'failed': int((dnb_title_df['dnb_found'] == False).sum()) if len(dnb_title_df) > 0 else 0\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # DNB-Daten Verf\u00fcgbarkeit (Varianten)\n",
    "    'dnb_variants': {\n",
    "        'id_available': int(df_enriched['dnb_query_method'].notna().sum()) if 'dnb_query_method' in df_enriched.columns else 0,\n",
    "        'ta_available': int(df_enriched[['dnb_title_ta','dnb_authors_ta','dnb_year_ta','dnb_publisher_ta']].notna().any(axis=1).sum())\n",
    "    },\n",
    "    \n",
    "    # DNB-Feldverf\u00fcgbarkeit\n",
    "    'dnb_field_availability': {\n",
    "        'id': {\n",
    "            'title': int(df_enriched['dnb_title'].notna().sum()) if 'dnb_title' in df_enriched.columns else 0,\n",
    "            'authors': int(df_enriched['dnb_authors'].notna().sum()) if 'dnb_authors' in df_enriched.columns else 0,\n",
    "            'year': int(df_enriched['dnb_year'].notna().sum()) if 'dnb_year' in df_enriched.columns else 0,\n",
    "            'publisher': int(df_enriched['dnb_publisher'].notna().sum()) if 'dnb_publisher' in df_enriched.columns else 0\n",
    "        },\n",
    "        'title_author': {\n",
    "            'title': int(df_enriched['dnb_title_ta'].notna().sum()) if 'dnb_title_ta' in df_enriched.columns else 0,\n",
    "            'authors': int(df_enriched['dnb_authors_ta'].notna().sum()) if 'dnb_authors_ta' in df_enriched.columns else 0,\n",
    "            'year': int(df_enriched['dnb_year_ta'].notna().sum()) if 'dnb_year_ta' in df_enriched.columns else 0,\n",
    "            'publisher': int(df_enriched['dnb_publisher_ta'].notna().sum()) if 'dnb_publisher_ta' in df_enriched.columns else 0\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Originaldaten-Vollst\u00e4ndigkeit\n",
    "    'vdeh_completeness': {\n",
    "        'title': int(df_enriched['title'].notna().sum()),\n",
    "        'authors': int((df_enriched['authors_str'].notna() & (df_enriched['authors_str'] != '')).sum()),\n",
    "        'year': int(df_enriched['year'].notna().sum()),\n",
    "        'publisher': int(df_enriched['publisher'].notna().sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Metadaten speichern\n",
    "with open(metadata_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n\u2705 Metadaten gespeichert: {metadata_output.name}\")\n",
    "\n",
    "# 3. Zusammenfassung\n",
    "print(f\"\\n\ud83d\udcca === DNB ENRICHMENT ABGESCHLOSSEN ===\")\n",
    "print(f\"   Input: {len(df_vdeh):,} VDEH Records\")\n",
    "print(f\"   Output: {len(df_enriched):,} Records mit DNB-Daten\")\n",
    "print(f\"   DNB-Queries: {metadata['dnb_queries']['isbn_issn']['total_queries'] + metadata['dnb_queries']['title_author']['total_queries']:,}\")\n",
    "print(f\"   ID-Variante verf\u00fcgbar: {metadata['dnb_variants']['id_available']:,}\")\n",
    "print(f\"   TA-Variante verf\u00fcgbar: {metadata['dnb_variants']['ta_available']:,}\")\n",
    "\n",
    "print(f\"\\n\u27a1\ufe0f  N\u00e4chster Schritt: 05_vdeh_data_fusion.ipynb\")\n",
    "print(f\"   KI-gest\u00fctzte Fusion von VDEH und DNB Daten (beide Varianten)\")\n",
    "\n",
    "print(f\"\\n\ud83c\udf89 DNB Enrichment erfolgreich abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563eaf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibo-analysis-DoEGeq_l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}