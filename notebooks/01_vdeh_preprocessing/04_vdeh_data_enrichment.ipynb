{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b689b192",
   "metadata": {},
   "source": [
    "# VDEH Data Enrichment Pipeline\n",
    "\n",
    "**Fokus:** Datenanreicherung Ã¼ber Deutsche Nationalbibliothek (DNB) API\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "- Identifikation unvollstÃ¤ndiger DatensÃ¤tze\n",
    "- Anreicherung fehlender Metadaten via DNB API (ISBN/ISSN)\n",
    "- KonsistenzprÃ¼fung vorhandener Daten\n",
    "- Validierung und QualitÃ¤tsverbesserung\n",
    "\n",
    "## ğŸ“š Input/Output\n",
    "- **Input**: `data/vdeh/processed/03_language_detected_data.parquet`\n",
    "- **Output**: `data/vdeh/processed/04_enriched_data.parquet`\n",
    "\n",
    "## ğŸ”— API\n",
    "- **DNB SRU API**: https://www.dnb.de/DE/Professionell/Metadatendienste/Datenbezug/SRU/sru_node.html\n",
    "- **Abfrage**: ISBN/ISSN basierte Suche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0dfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 11:07:32 - utils.notebook_utils - INFO - Searching for project root...\n",
      "2025-12-09 11:07:32 - utils.notebook_utils - INFO - Project root found: /media/sz/Data/Bibo/analysis\n",
      "2025-12-09 11:07:32 - utils.notebook_utils - INFO - Loading configuration...\n",
      "2025-12-09 11:07:32 - config_loader - INFO - Configuration loaded from /media/sz/Data/Bibo/analysis/config.yaml\n",
      "2025-12-09 11:07:32 - utils.notebook_utils - INFO - Configuration loaded successfully: Dual-Source Bibliothek Bestandsvergleich\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project root: /media/sz/Data/Bibo/analysis\n",
      "âœ… Project: Dual-Source Bibliothek Bestandsvergleich v2.0.0\n",
      "âœ… DNB API Funktionen geladen\n"
     ]
    }
   ],
   "source": [
    "# ğŸ› ï¸ SETUP UND DATEN LADEN\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / 'config.yaml').exists() and project_root.parent != project_root:\n",
    "    project_root = project_root.parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from utils.notebook_utils import setup_notebook\n",
    "\n",
    "project_root, config = setup_notebook()\n",
    "print(f\"âœ… Project root: {project_root}\")\n",
    "print(f\"âœ… Project: {config.get('project.name')} v{config.get('project.version')}\")\n",
    "\n",
    "# DNB API laden\n",
    "from dnb_api import DNB_SRU_BASE, query_dnb_by_isbn, query_dnb_by_issn, query_dnb_by_title_author\n",
    "print(f\"âœ… DNB API Funktionen geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16182926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Daten geladen aus: /media/sz/Data/Bibo/analysis/data/vdeh/processed/03_language_detected_data.parquet\n",
      "ğŸ“Š Records: 58,305\n",
      "ğŸ“‹ Spalten: ['id', 'title', 'authors', 'authors_affiliation', 'year', 'publisher', 'isbn', 'issn', 'pages', 'language', 'authors_str', 'num_authors', 'authors_affiliation_str', 'num_authors_affiliation', 'isbn_valid', 'isbn_status', 'issn_valid', 'issn_status', 'detected_language', 'detected_language_confidence', 'detected_language_name']\n",
      "ğŸ’¾ Memory: 54.5 MB\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ DATEN AUS VORHERIGER STUFE LADEN\n",
    "processed_dir = config.project_root / config.get('paths.data.vdeh.processed')\n",
    "input_path = processed_dir / '03_language_detected_data.parquet'\n",
    "metadata_path = processed_dir / '03_metadata.json'\n",
    "\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Input-Datei nicht gefunden: {input_path}\\n\"\n",
    "                          \"Bitte fÃ¼hren Sie zuerst 03_vdeh_language_detection.ipynb aus.\")\n",
    "\n",
    "# Daten laden\n",
    "df_vdeh = pd.read_parquet(input_path)\n",
    "\n",
    "# Vorherige Metadaten laden\n",
    "with open(metadata_path, 'r') as f:\n",
    "    prev_metadata = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“‚ Daten geladen aus: {input_path}\")\n",
    "print(f\"ğŸ“Š Records: {len(df_vdeh):,}\")\n",
    "print(f\"ğŸ“‹ Spalten: {list(df_vdeh.columns)}\")\n",
    "print(f\"ğŸ’¾ Memory: {df_vdeh.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Quality Scores anzeigen\n",
    "if 'completeness_score' in df_vdeh.columns:\n",
    "    avg_completeness = df_vdeh['completeness_score'].mean()\n",
    "    print(f\"ğŸ“Š Durchschnittliche VollstÃ¤ndigkeit: {avg_completeness:.1f}%\")\n",
    "    \n",
    "    if 'quality_category' in df_vdeh.columns:\n",
    "        quality_dist = df_vdeh['quality_category'].value_counts()\n",
    "        print(f\"ğŸ“Š QualitÃ¤ts-Verteilung:\")\n",
    "        for cat, count in quality_dist.items():\n",
    "            print(f\"   {cat}: {count:,} ({count/len(df_vdeh)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003af9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” === KANDIDATEN-IDENTIFIKATION ===\n",
      "\n",
      "ğŸ“‹ Kriterium 1: ISBN vorhanden (PrÃ¼fung aller DatensÃ¤tze mit ISBN)\n",
      "   ISBN-Kandidaten (alle): 10,507\n",
      "     - VollstÃ¤ndige DatensÃ¤tze: 7,810\n",
      "     - UnvollstÃ¤ndig (Titel): 0\n",
      "     - UnvollstÃ¤ndig (Autoren): 2,664\n",
      "     - UnvollstÃ¤ndig (Jahr): 87\n",
      "\n",
      "   ISSN-Kandidaten (nur unvollstÃ¤ndig): 671\n",
      "     - Fehlender Titel: 0\n",
      "     - Fehlende Autoren: 503\n",
      "     - Fehlendes Jahr: 644\n",
      "\n",
      "âœ… Gesamt Anreicherungs-Kandidaten (mit ISBN/ISSN): 11,172\n",
      "\n",
      "ğŸ“‹ Kriterium 2: Ohne ISBN aber mit Titel + Autoren (DNB Titel/Autor-Suche)\n",
      "   Kandidaten: 9,645\n",
      "     - Mit Titel: 9,645\n",
      "     - Mit Autoren: 9,645\n",
      "\n",
      "ğŸ¯ Finale Anreicherungs-Kandidaten: 20,152\n",
      "   Mit ISBN: 10,507\n",
      "   Mit ISSN: 213\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” KANDIDATEN FÃœR ANREICHERUNG IDENTIFIZIEREN\n",
    "print(\"ğŸ” === KANDIDATEN-IDENTIFIKATION ===\\n\")\n",
    "\n",
    "# Kriterien fÃ¼r Anreicherungskandidaten\n",
    "enrichment_candidates = pd.DataFrame()\n",
    "\n",
    "# 1. Alle Records mit ISBN (unabhÃ¤ngig von VollstÃ¤ndigkeit)\n",
    "print(\"ğŸ“‹ Kriterium 1: ISBN vorhanden (PrÃ¼fung aller DatensÃ¤tze mit ISBN)\")\n",
    "\n",
    "# ISBN-basierte Kandidaten - ALLE mit ISBN\n",
    "if 'isbn' in df_vdeh.columns:\n",
    "    has_isbn = df_vdeh['isbn'].notna()\n",
    "    \n",
    "    isbn_candidates = df_vdeh[has_isbn].copy()\n",
    "    \n",
    "    # Statistiken fÃ¼r Ãœberblick\n",
    "    missing_title = isbn_candidates['title'].isna()\n",
    "    missing_authors = (isbn_candidates['authors_str'].isna()) | (isbn_candidates['authors_str'] == '')\n",
    "    missing_year = isbn_candidates['year'].isna()\n",
    "    \n",
    "    print(f\"   ISBN-Kandidaten (alle): {len(isbn_candidates):,}\")\n",
    "    print(f\"     - VollstÃ¤ndige DatensÃ¤tze: {(~missing_title & ~missing_authors & ~missing_year).sum():,}\")\n",
    "    print(f\"     - UnvollstÃ¤ndig (Titel): {missing_title.sum():,}\")\n",
    "    print(f\"     - UnvollstÃ¤ndig (Autoren): {missing_authors.sum():,}\")\n",
    "    print(f\"     - UnvollstÃ¤ndig (Jahr): {missing_year.sum():,}\")\n",
    "\n",
    "# ISSN-basierte Kandidaten - nur bei unvollstÃ¤ndigen Metadaten\n",
    "if 'issn' in df_vdeh.columns:\n",
    "    has_issn = df_vdeh['issn'].notna()\n",
    "    missing_title = df_vdeh['title'].isna()\n",
    "    missing_authors = (df_vdeh['authors_str'].isna()) | (df_vdeh['authors_str'] == '')\n",
    "    missing_year = df_vdeh['year'].isna()\n",
    "    \n",
    "    issn_candidates = df_vdeh[\n",
    "        has_issn & (missing_title | missing_authors | missing_year)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"\\n   ISSN-Kandidaten (nur unvollstÃ¤ndig): {len(issn_candidates):,}\")\n",
    "    print(f\"     - Fehlender Titel: {issn_candidates['title'].isna().sum():,}\")\n",
    "    print(f\"     - Fehlende Autoren: {(issn_candidates['authors_str'].isna() | (issn_candidates['authors_str'] == '')).sum():,}\")\n",
    "    print(f\"     - Fehlendes Jahr: {issn_candidates['year'].isna().sum():,}\")\n",
    "\n",
    "# Kombiniere Kandidaten\n",
    "all_candidates = pd.concat([isbn_candidates, issn_candidates]).drop_duplicates(subset=['id'])\n",
    "print(f\"\\nâœ… Gesamt Anreicherungs-Kandidaten (mit ISBN/ISSN): {len(all_candidates):,}\")\n",
    "\n",
    "# 2. Records OHNE ISBN aber MIT Titel + Autoren (fÃ¼r DNB-Suche via Titel/Autor)\n",
    "no_isbn_but_searchable = df_vdeh[\n",
    "    (df_vdeh['isbn'].isna()) &\n",
    "    (df_vdeh['title'].notna()) &\n",
    "    (df_vdeh['authors_str'].notna()) &\n",
    "    (df_vdeh['authors_str'] != '')\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nğŸ“‹ Kriterium 2: Ohne ISBN aber mit Titel + Autoren (DNB Titel/Autor-Suche)\")\n",
    "print(f\"   Kandidaten: {len(no_isbn_but_searchable):,}\")\n",
    "print(f\"     - Mit Titel: {no_isbn_but_searchable['title'].notna().sum():,}\")\n",
    "print(f\"     - Mit Autoren: {(no_isbn_but_searchable['authors_str'].notna() & (no_isbn_but_searchable['authors_str'] != '')).sum():,}\")\n",
    "\n",
    "# Finale Kandidatenliste (unique): ISBN-Kandidaten ODER Titel+Autor-Kandidaten\n",
    "final_candidates = df_vdeh[\n",
    "    # ENTWEDER: ISBN vorhanden (unabhÃ¤ngig von VollstÃ¤ndigkeit)\n",
    "    (df_vdeh['isbn'].notna()) |\n",
    "    # ODER: Kein ISBN aber Titel + Autoren vorhanden\n",
    "    (\n",
    "        (df_vdeh['isbn'].isna()) &\n",
    "        (df_vdeh['title'].notna()) &\n",
    "        (df_vdeh['authors_str'].notna()) &\n",
    "        (df_vdeh['authors_str'] != '')\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nğŸ¯ Finale Anreicherungs-Kandidaten: {len(final_candidates):,}\")\n",
    "print(f\"   Mit ISBN: {final_candidates['isbn'].notna().sum():,}\")\n",
    "print(f\"   Mit ISSN: {final_candidates['issn'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57f67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ === DNB API STATUS ===\n",
      "\n",
      "âœ… DNB API Funktionen aus src/dnb_api.py geladen\n",
      "   Base URL: https://services.dnb.de/sru/dnb\n",
      "   Schema: MARC21-xml\n",
      "   VerfÃ¼gbare Funktionen:\n",
      "     - query_dnb_by_isbn(isbn, max_records=1)\n",
      "     - query_dnb_by_issn(issn, max_records=1)\n",
      "     - query_dnb_by_title_author(title, author=None, max_records=1)\n"
     ]
    }
   ],
   "source": [
    "# ğŸŒ DNB API STATUS\n",
    "print(\"ğŸŒ === DNB API STATUS ===\\n\")\n",
    "\n",
    "print(\"âœ… DNB API Funktionen aus src/dnb_api.py geladen\")\n",
    "print(f\"   Base URL: {DNB_SRU_BASE}\")\n",
    "print(f\"   Schema: MARC21-xml\")\n",
    "print(f\"   VerfÃ¼gbare Funktionen:\")\n",
    "print(f\"     - query_dnb_by_isbn(isbn, max_records=1)\")\n",
    "print(f\"     - query_dnb_by_issn(issn, max_records=1)\")\n",
    "print(f\"     - query_dnb_by_title_author(title, author=None, max_records=1)\")\n",
    "print(f\"     - query_dnb_by_title_year(title, year, max_records=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e86af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ === DNB DATENABFRAGE ===\n",
      "\n",
      "âš™ï¸  Konfiguration:\n",
      "   Rate Limit: 1.0s pro Anfrage\n",
      "   Save Interval: Alle 50 Queries\n",
      "   Output: dnb_raw_data.parquet\n",
      "\n",
      "ğŸ“‚ Lade vorhandene DNB-Daten...\n",
      "   Bereits abgefragt: 6,350\n",
      "   Davon erfolgreich: 3,286\n",
      "\n",
      "ğŸ“‹ Extrahiere ISBN/ISSN aus 20,152 Kandidaten...\n",
      "   ISBN-Queries: 10,507\n",
      "   ISSN-Queries: 194\n",
      "   Gesamt: 10,701\n",
      "\n",
      "ğŸ” Abgleich mit vorhandenen Daten:\n",
      "   Bereits vorhanden: 6,386\n",
      "   Neu abzufragen: 4,315\n",
      "\n",
      "ğŸ”„ Starte DNB-Abfrage fÃ¼r 4,315 neue Queries...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4484d3cf8124bee886edcd75c655bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ” DNB API:   0%|          | 0/4315 [00:00<?, ?queries/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Zwischenspeicherung: 50/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 100/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 150/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 200/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 250/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 300/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 350/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 400/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 450/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 500/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 550/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 600/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 650/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 700/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 750/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 800/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 850/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 900/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 950/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1000/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1050/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1100/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1150/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1200/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1250/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1300/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1350/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1400/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1450/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1500/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1550/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1600/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1650/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1700/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1750/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1800/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1850/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1900/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 1950/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2000/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2050/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2100/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2150/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2200/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2250/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2300/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2350/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2400/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2450/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2500/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2550/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2600/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2650/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2700/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2750/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2800/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2850/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2900/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 2950/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3000/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3050/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3100/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3150/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3200/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3250/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3300/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3350/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3400/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3450/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3500/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3550/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3600/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3650/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3700/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3750/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3800/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3850/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3900/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 3950/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 4000/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 4050/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 4100/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 4150/4315 Queries abgefragt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19216/2756518088.py:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dnb_data_df = pd.concat([dnb_data_df, new_results_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Zwischenspeicherung: 4200/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 4250/4315 Queries abgefragt\n",
      "ğŸ’¾ Zwischenspeicherung: 4300/4315 Queries abgefragt\n",
      "\n",
      "ğŸ’¾ DNB-Daten gespeichert: dnb_raw_data.parquet\n",
      "\n",
      "ğŸ“Š === NEUE ABFRAGEN ===\n",
      "   Neue Queries: 4,315\n",
      "   âœ… Gefunden: 2,484 (57.6%)\n",
      "   âŒ Nicht gefunden: 1,831 (42.4%)\n",
      "   ğŸ’¾ Zwischenspeicherungen: 86\n",
      "\n",
      "ğŸ“Š === GESAMT DNB-DATEN ===\n",
      "   Total Records: 10,665\n",
      "   Erfolgreich: 5,770\n",
      "   Nicht gefunden: 4,895\n",
      "   ğŸ“š Mit DNB-ISBN: 5,770\n",
      "   ğŸ“° Mit DNB-ISSN: 43\n",
      "\n",
      "âœ… DNB-Daten verfÃ¼gbar als: dnb_data_df\n",
      "   Shape: (10665, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19216/2756518088.py:123: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dnb_data_df = pd.concat([dnb_data_df, new_results_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ DNB DATENABFRAGE\n",
    "print(\"ğŸš€ === DNB DATENABFRAGE ===\\n\")\n",
    "\n",
    "# Konfiguration\n",
    "RATE_LIMIT_DELAY = 1.0  # Sekunden zwischen Anfragen (erhÃ¶ht von 0.5s wegen Timeouts)\n",
    "SAVE_INTERVAL = 50  # Speichere alle N Abfragen\n",
    "DNB_DATA_FILE = processed_dir / 'dnb_raw_data.parquet'\n",
    "\n",
    "print(f\"âš™ï¸  Konfiguration:\")\n",
    "print(f\"   Rate Limit: {RATE_LIMIT_DELAY}s pro Anfrage\")\n",
    "print(f\"   Save Interval: Alle {SAVE_INTERVAL} Queries\")\n",
    "print(f\"   Output: {DNB_DATA_FILE.name}\")\n",
    "\n",
    "# Lade vorhandene DNB-Daten (falls vorhanden)\n",
    "if DNB_DATA_FILE.exists():\n",
    "    print(f\"\\nğŸ“‚ Lade vorhandene DNB-Daten...\")\n",
    "    dnb_data_df = pd.read_parquet(DNB_DATA_FILE)\n",
    "    print(f\"   Bereits abgefragt: {len(dnb_data_df):,}\")\n",
    "    print(f\"   Davon erfolgreich: {(dnb_data_df['dnb_found'] == True).sum():,}\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“‚ Keine vorhandenen DNB-Daten gefunden - starte neue Abfrage\")\n",
    "    dnb_data_df = pd.DataFrame(columns=[\n",
    "        'vdeh_id', 'query_type', 'query_value',\n",
    "        'dnb_found', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher',\n",
    "        'dnb_isbn', 'dnb_issn'\n",
    "    ])\n",
    "\n",
    "# Sammle ISBN/ISSN aus Kandidaten\n",
    "print(f\"\\nğŸ“‹ Extrahiere ISBN/ISSN aus {len(final_candidates):,} Kandidaten...\")\n",
    "\n",
    "queries_isbn = final_candidates[final_candidates['isbn'].notna()][['id', 'isbn']].copy()\n",
    "queries_isbn.columns = ['vdeh_id', 'query_value']\n",
    "queries_isbn['query_type'] = 'ISBN'\n",
    "\n",
    "queries_issn = final_candidates[\n",
    "    final_candidates['isbn'].isna() & final_candidates['issn'].notna()\n",
    "][['id', 'issn']].copy()\n",
    "queries_issn.columns = ['vdeh_id', 'query_value']\n",
    "queries_issn['query_type'] = 'ISSN'\n",
    "\n",
    "all_queries = pd.concat([queries_isbn, queries_issn], ignore_index=True)\n",
    "\n",
    "print(f\"   ISBN-Queries: {len(queries_isbn):,}\")\n",
    "print(f\"   ISSN-Queries: {len(queries_issn):,}\")\n",
    "print(f\"   Gesamt: {len(all_queries):,}\")\n",
    "\n",
    "# Filtere bereits abgefragte ISBN/ISSN\n",
    "if len(dnb_data_df) > 0:\n",
    "    # Erstelle Set der bereits abgefragten query_values\n",
    "    already_queried = set(dnb_data_df['query_value'])\n",
    "    \n",
    "    # Filtere nur neue Queries\n",
    "    new_queries = all_queries[~all_queries['query_value'].isin(already_queried)].copy()\n",
    "    \n",
    "    print(f\"\\nğŸ” Abgleich mit vorhandenen Daten:\")\n",
    "    print(f\"   Bereits vorhanden: {len(all_queries) - len(new_queries):,}\")\n",
    "    print(f\"   Neu abzufragen: {len(new_queries):,}\")\n",
    "else:\n",
    "    new_queries = all_queries\n",
    "    print(f\"\\nğŸ” Alle {len(new_queries):,} Queries sind neu\")\n",
    "\n",
    "# Nur abfragen wenn neue Queries vorhanden\n",
    "if len(new_queries) > 0:\n",
    "    print(f\"\\nğŸ”„ Starte DNB-Abfrage fÃ¼r {len(new_queries):,} neue Queries...\\n\")\n",
    "    \n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    results = []\n",
    "    stats = {'found': 0, 'not_found': 0}\n",
    "    query_count = 0\n",
    "    \n",
    "    for _, row in tqdm(new_queries.iterrows(), total=len(new_queries), desc=\"ğŸ” DNB API\", unit=\"queries\"):\n",
    "        # API-Abfrage\n",
    "        dnb_result = None\n",
    "        if row['query_type'] == 'ISBN':\n",
    "            dnb_result = query_dnb_by_isbn(row['query_value'])\n",
    "        elif row['query_type'] == 'ISSN':\n",
    "            dnb_result = query_dnb_by_issn(row['query_value'])\n",
    "        \n",
    "        # Ergebnis speichern (inkl. ISBN/ISSN aus DNB-Antwort!)\n",
    "        result_row = {\n",
    "            'vdeh_id': row['vdeh_id'],\n",
    "            'query_type': row['query_type'],\n",
    "            'query_value': row['query_value'],\n",
    "            'dnb_found': dnb_result is not None,\n",
    "            'dnb_title': dnb_result.get('title') if dnb_result else None,\n",
    "            'dnb_authors': ', '.join(dnb_result.get('authors', [])) if dnb_result else None,\n",
    "            'dnb_year': dnb_result.get('year') if dnb_result else None,\n",
    "            'dnb_publisher': dnb_result.get('publisher') if dnb_result else None,\n",
    "            'dnb_isbn': dnb_result.get('isbn') if dnb_result else None,\n",
    "            'dnb_issn': dnb_result.get('issn') if dnb_result else None,\n",
    "            'dnb_pages': dnb_result.get('pages') if dnb_result else None\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if dnb_result:\n",
    "            stats['found'] += 1\n",
    "        else:\n",
    "            stats['not_found'] += 1\n",
    "        \n",
    "        query_count += 1\n",
    "        \n",
    "        # RegelmÃ¤ÃŸiges Speichern (alle SAVE_INTERVAL Queries)\n",
    "        if query_count % SAVE_INTERVAL == 0:\n",
    "            # Merge mit vorhandenen Daten\n",
    "            new_results_df = pd.DataFrame(results)\n",
    "            dnb_data_df = pd.concat([dnb_data_df, new_results_df], ignore_index=True)\n",
    "            \n",
    "            # Speichern\n",
    "            dnb_data_df.to_parquet(DNB_DATA_FILE, index=False)\n",
    "            \n",
    "            # Reset results fÃ¼r nÃ¤chste Batch\n",
    "            results = []\n",
    "            \n",
    "            print(f\"ğŸ’¾ Zwischenspeicherung: {query_count}/{len(new_queries)} Queries abgefragt\")\n",
    "        \n",
    "        # Rate Limiting\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Finale Speicherung (restliche Ergebnisse)\n",
    "    if len(results) > 0:\n",
    "        new_results_df = pd.DataFrame(results)\n",
    "        dnb_data_df = pd.concat([dnb_data_df, new_results_df], ignore_index=True)\n",
    "        dnb_data_df.to_parquet(DNB_DATA_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ DNB-Daten gespeichert: {DNB_DATA_FILE.name}\")\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(f\"\\nğŸ“Š === NEUE ABFRAGEN ===\")\n",
    "    print(f\"   Neue Queries: {len(new_queries):,}\")\n",
    "    print(f\"   âœ… Gefunden: {stats['found']:,} ({stats['found']/len(new_queries)*100:.1f}%)\")\n",
    "    print(f\"   âŒ Nicht gefunden: {stats['not_found']:,} ({stats['not_found']/len(new_queries)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ’¾ Zwischenspeicherungen: {len(new_queries)//SAVE_INTERVAL}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâœ… Alle ISBN/ISSN bereits in DNB-Daten vorhanden - keine neuen Abfragen nÃ¶tig\")\n",
    "\n",
    "# Gesamtstatistik\n",
    "print(f\"\\nğŸ“Š === GESAMT DNB-DATEN ===\")\n",
    "print(f\"   Total Records: {len(dnb_data_df):,}\")\n",
    "print(f\"   Erfolgreich: {(dnb_data_df['dnb_found'] == True).sum():,}\")\n",
    "print(f\"   Nicht gefunden: {(dnb_data_df['dnb_found'] == False).sum():,}\")\n",
    "\n",
    "# Neue Statistik: ISBN/ISSN-Gewinn\n",
    "if 'dnb_isbn' in dnb_data_df.columns:\n",
    "    isbn_from_dnb = (dnb_data_df['dnb_found'] == True) & dnb_data_df['dnb_isbn'].notna()\n",
    "    issn_from_dnb = (dnb_data_df['dnb_found'] == True) & dnb_data_df['dnb_issn'].notna()\n",
    "    print(f\"   ğŸ“š Mit DNB-ISBN: {isbn_from_dnb.sum():,}\")\n",
    "    print(f\"   ğŸ“° Mit DNB-ISSN: {issn_from_dnb.sum():,}\")\n",
    "\n",
    "print(f\"\\nâœ… DNB-Daten verfÃ¼gbar als: dnb_data_df\")\n",
    "print(f\"   Shape: {dnb_data_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee36888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vdeh_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>query_value</th>\n",
       "      <th>dnb_found</th>\n",
       "      <th>dnb_title</th>\n",
       "      <th>dnb_authors</th>\n",
       "      <th>dnb_year</th>\n",
       "      <th>dnb_publisher</th>\n",
       "      <th>dnb_isbn</th>\n",
       "      <th>dnb_issn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000023</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-428-05409-1</td>\n",
       "      <td>True</td>\n",
       "      <td>Â˜DieÂœ deutsche Roheisenindustrie 1871 - 1913</td>\n",
       "      <td>Krengel, Jochen</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Duncker und Humblot</td>\n",
       "      <td>3428054091</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000038</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-527-26070-6</td>\n",
       "      <td>True</td>\n",
       "      <td>Korrosionskunde im Experiment</td>\n",
       "      <td>Heitz, Ewald, Henkhaus, Rolf, Rahmel, Alfred</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Verlag Chemie</td>\n",
       "      <td>3527260706</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000039</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-802-74302-4</td>\n",
       "      <td>True</td>\n",
       "      <td>Brandschutz und Feuersicherheit in ArbeitsstaÌˆ...</td>\n",
       "      <td>Isterling, Fritz</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Vulkan-Verlag</td>\n",
       "      <td>3802743024</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000040</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>3-802-70475-4</td>\n",
       "      <td>True</td>\n",
       "      <td>Lagerung von staubfoÌˆrmigen SchuÌˆttguÌˆtern in ...</td>\n",
       "      <td>Koster, Karl H., Haus der Technik</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>Vulkan-Verlag Classen</td>\n",
       "      <td>3802704754</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000042</td>\n",
       "      <td>ISBN</td>\n",
       "      <td>0-853-34164-8</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     vdeh_id query_type    query_value  dnb_found  \\\n",
       "0  000000023       ISBN  3-428-05409-1       True   \n",
       "1  000000038       ISBN  3-527-26070-6       True   \n",
       "2  000000039       ISBN  3-802-74302-4       True   \n",
       "3  000000040       ISBN  3-802-70475-4       True   \n",
       "4  000000042       ISBN  0-853-34164-8      False   \n",
       "\n",
       "                                           dnb_title  \\\n",
       "0       Â˜DieÂœ deutsche Roheisenindustrie 1871 - 1913   \n",
       "1                      Korrosionskunde im Experiment   \n",
       "2  Brandschutz und Feuersicherheit in ArbeitsstaÌˆ...   \n",
       "3  Lagerung von staubfoÌˆrmigen SchuÌˆttguÌˆtern in ...   \n",
       "4                                               None   \n",
       "\n",
       "                                    dnb_authors  dnb_year  \\\n",
       "0                               Krengel, Jochen    1983.0   \n",
       "1  Heitz, Ewald, Henkhaus, Rolf, Rahmel, Alfred    1983.0   \n",
       "2                              Isterling, Fritz    1984.0   \n",
       "3             Koster, Karl H., Haus der Technik    1983.0   \n",
       "4                                          None       NaN   \n",
       "\n",
       "           dnb_publisher    dnb_isbn dnb_issn  \n",
       "0    Duncker und Humblot  3428054091     None  \n",
       "1          Verlag Chemie  3527260706     None  \n",
       "2          Vulkan-Verlag  3802743024     None  \n",
       "3  Vulkan-Verlag Classen  3802704754     None  \n",
       "4                   None        None     None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb8db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5770 von 10665 DatensÃ¤tze bei DNB gefunden\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dnb_data_df.dnb_found.sum()} von {dnb_data_df.shape[0]} DatensÃ¤tze bei DNB gefunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97aaf6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” === DNB TITEL/AUTOR-SUCHE ===\n",
      "\n",
      "âš™ï¸  Konfiguration:\n",
      "   Rate Limit: 1.0s pro Anfrage\n",
      "   Save Interval: Alle 50 Queries\n",
      "   Output: dnb_title_author_data.parquet\n",
      "   TA fÃ¼r alle Titel+Autoren: True\n",
      "   ğŸ”„ Verbesserter Suchalgorithmus aktiv (4-stufige Strategie)\n",
      "\n",
      "ğŸ“‚ Keine vorhandenen Titel/Autor-Suchdaten gefunden - starte neue Abfrage\n",
      "\n",
      "ğŸ“‹ Titel/Autor-Kandidaten: 17,488\n",
      "   Mit Titel: 17,488\n",
      "   Mit Autoren: 17,488\n",
      "   Gesamt Titel/Autor-Queries (vor Deduplikation): 17,488\n",
      "\n",
      "ğŸ” Alle 17,488 Titel/Autor-Queries sind neu\n",
      "\n",
      "ğŸ”„ Starte DNB Titel/Autor-Abfrage fÃ¼r 17,488 neue Queries...\n",
      "   ğŸ“š Verwende verbesserte 4-stufige Suchstrategie:\n",
      "\n",
      "      1. Titel (Phrase) + Autor\n",
      "      2. Titel (WÃ¶rter) + Autor\n",
      "      3. Nur Titel (Phrase)\n",
      "      4. Nur Titel (WÃ¶rter)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ea3fe7e82f4bb6b0b1a24a3f14ebf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ” DNB Titel/Autor:   0%|          | 0/17488 [00:00<?, ?queries/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19216/1770775344.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dnb_title_df = pd.concat([dnb_title_df, new_results_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Zwischenstand: 50/17488 | Erfolgsrate: 20.0%\n",
      "ğŸ’¾ Zwischenstand: 100/17488 | Erfolgsrate: 28.0%\n",
      "ğŸ’¾ Zwischenstand: 150/17488 | Erfolgsrate: 36.0%\n",
      "ğŸ’¾ Zwischenstand: 200/17488 | Erfolgsrate: 45.0%\n",
      "ğŸ’¾ Zwischenstand: 250/17488 | Erfolgsrate: 46.0%\n",
      "ğŸ’¾ Zwischenstand: 300/17488 | Erfolgsrate: 44.7%\n",
      "ğŸ’¾ Zwischenstand: 350/17488 | Erfolgsrate: 45.4%\n",
      "ğŸ’¾ Zwischenstand: 400/17488 | Erfolgsrate: 47.5%\n",
      "ğŸ’¾ Zwischenstand: 450/17488 | Erfolgsrate: 46.7%\n",
      "ğŸ’¾ Zwischenstand: 500/17488 | Erfolgsrate: 46.6%\n",
      "ğŸ’¾ Zwischenstand: 550/17488 | Erfolgsrate: 46.2%\n",
      "ğŸ’¾ Zwischenstand: 600/17488 | Erfolgsrate: 45.2%\n",
      "ğŸ’¾ Zwischenstand: 650/17488 | Erfolgsrate: 44.9%\n",
      "ğŸ’¾ Zwischenstand: 700/17488 | Erfolgsrate: 47.1%\n",
      "ğŸ’¾ Zwischenstand: 750/17488 | Erfolgsrate: 49.1%\n",
      "ğŸ’¾ Zwischenstand: 800/17488 | Erfolgsrate: 48.6%\n",
      "ğŸ’¾ Zwischenstand: 850/17488 | Erfolgsrate: 48.4%\n",
      "ğŸ’¾ Zwischenstand: 900/17488 | Erfolgsrate: 49.1%\n",
      "ğŸ’¾ Zwischenstand: 950/17488 | Erfolgsrate: 48.9%\n",
      "ğŸ’¾ Zwischenstand: 1000/17488 | Erfolgsrate: 48.5%\n",
      "ğŸ’¾ Zwischenstand: 1050/17488 | Erfolgsrate: 48.9%\n",
      "ğŸ’¾ Zwischenstand: 1100/17488 | Erfolgsrate: 48.5%\n",
      "ğŸ’¾ Zwischenstand: 1150/17488 | Erfolgsrate: 48.4%\n",
      "ğŸ’¾ Zwischenstand: 1200/17488 | Erfolgsrate: 47.8%\n",
      "ğŸ’¾ Zwischenstand: 1250/17488 | Erfolgsrate: 47.7%\n",
      "ğŸ’¾ Zwischenstand: 1300/17488 | Erfolgsrate: 47.8%\n",
      "ğŸ’¾ Zwischenstand: 1350/17488 | Erfolgsrate: 47.7%\n",
      "ğŸ’¾ Zwischenstand: 1400/17488 | Erfolgsrate: 47.0%\n",
      "ğŸ’¾ Zwischenstand: 1450/17488 | Erfolgsrate: 46.3%\n",
      "ğŸ’¾ Zwischenstand: 1500/17488 | Erfolgsrate: 46.7%\n",
      "ğŸ’¾ Zwischenstand: 1550/17488 | Erfolgsrate: 46.3%\n",
      "ğŸ’¾ Zwischenstand: 1600/17488 | Erfolgsrate: 45.6%\n",
      "ğŸ’¾ Zwischenstand: 1650/17488 | Erfolgsrate: 45.1%\n",
      "ğŸ’¾ Zwischenstand: 1700/17488 | Erfolgsrate: 45.4%\n",
      "ğŸ’¾ Zwischenstand: 1750/17488 | Erfolgsrate: 45.1%\n",
      "ğŸ’¾ Zwischenstand: 1800/17488 | Erfolgsrate: 44.9%\n",
      "ğŸ’¾ Zwischenstand: 1850/17488 | Erfolgsrate: 45.5%\n",
      "ğŸ’¾ Zwischenstand: 1900/17488 | Erfolgsrate: 45.7%\n",
      "ğŸ’¾ Zwischenstand: 1950/17488 | Erfolgsrate: 45.6%\n",
      "ğŸ’¾ Zwischenstand: 2000/17488 | Erfolgsrate: 45.3%\n",
      "ğŸ’¾ Zwischenstand: 2050/17488 | Erfolgsrate: 44.9%\n",
      "ğŸ’¾ Zwischenstand: 2100/17488 | Erfolgsrate: 44.1%\n",
      "ğŸ’¾ Zwischenstand: 2150/17488 | Erfolgsrate: 44.5%\n",
      "ğŸ’¾ Zwischenstand: 2200/17488 | Erfolgsrate: 44.6%\n",
      "ğŸ’¾ Zwischenstand: 2250/17488 | Erfolgsrate: 44.5%\n",
      "ğŸ’¾ Zwischenstand: 2300/17488 | Erfolgsrate: 44.7%\n",
      "ğŸ’¾ Zwischenstand: 2350/17488 | Erfolgsrate: 44.9%\n",
      "ğŸ’¾ Zwischenstand: 2400/17488 | Erfolgsrate: 45.2%\n",
      "ğŸ’¾ Zwischenstand: 2450/17488 | Erfolgsrate: 45.8%\n",
      "ğŸ’¾ Zwischenstand: 2500/17488 | Erfolgsrate: 46.2%\n",
      "ğŸ’¾ Zwischenstand: 2550/17488 | Erfolgsrate: 46.4%\n",
      "ğŸ’¾ Zwischenstand: 2600/17488 | Erfolgsrate: 45.7%\n",
      "ğŸ’¾ Zwischenstand: 2650/17488 | Erfolgsrate: 45.1%\n",
      "ğŸ’¾ Zwischenstand: 2700/17488 | Erfolgsrate: 45.0%\n",
      "ğŸ’¾ Zwischenstand: 2750/17488 | Erfolgsrate: 44.7%\n",
      "ğŸ’¾ Zwischenstand: 2800/17488 | Erfolgsrate: 44.8%\n",
      "ğŸ’¾ Zwischenstand: 2850/17488 | Erfolgsrate: 44.9%\n",
      "ğŸ’¾ Zwischenstand: 2900/17488 | Erfolgsrate: 44.8%\n",
      "ğŸ’¾ Zwischenstand: 2950/17488 | Erfolgsrate: 44.7%\n",
      "ğŸ’¾ Zwischenstand: 3000/17488 | Erfolgsrate: 44.4%\n",
      "ğŸ’¾ Zwischenstand: 3050/17488 | Erfolgsrate: 44.5%\n",
      "ğŸ’¾ Zwischenstand: 3100/17488 | Erfolgsrate: 44.4%\n",
      "ğŸ’¾ Zwischenstand: 3150/17488 | Erfolgsrate: 44.3%\n",
      "ğŸ’¾ Zwischenstand: 3200/17488 | Erfolgsrate: 44.8%\n",
      "ğŸ’¾ Zwischenstand: 3250/17488 | Erfolgsrate: 44.7%\n",
      "ğŸ’¾ Zwischenstand: 3300/17488 | Erfolgsrate: 44.4%\n",
      "ğŸ’¾ Zwischenstand: 3350/17488 | Erfolgsrate: 44.5%\n",
      "ğŸ’¾ Zwischenstand: 3400/17488 | Erfolgsrate: 44.4%\n",
      "ğŸ’¾ Zwischenstand: 3450/17488 | Erfolgsrate: 44.6%\n",
      "ğŸ’¾ Zwischenstand: 3500/17488 | Erfolgsrate: 44.3%\n",
      "ğŸ’¾ Zwischenstand: 3550/17488 | Erfolgsrate: 44.1%\n",
      "ğŸ’¾ Zwischenstand: 3600/17488 | Erfolgsrate: 44.0%\n",
      "ğŸ’¾ Zwischenstand: 3650/17488 | Erfolgsrate: 44.1%\n",
      "ğŸ’¾ Zwischenstand: 3700/17488 | Erfolgsrate: 43.8%\n",
      "ğŸ’¾ Zwischenstand: 3750/17488 | Erfolgsrate: 43.8%\n",
      "ğŸ’¾ Zwischenstand: 3800/17488 | Erfolgsrate: 43.4%\n",
      "ğŸ’¾ Zwischenstand: 3850/17488 | Erfolgsrate: 43.5%\n",
      "ğŸ’¾ Zwischenstand: 3900/17488 | Erfolgsrate: 43.3%\n",
      "ğŸ’¾ Zwischenstand: 3950/17488 | Erfolgsrate: 43.2%\n",
      "ğŸ’¾ Zwischenstand: 4000/17488 | Erfolgsrate: 43.2%\n",
      "ğŸ’¾ Zwischenstand: 4050/17488 | Erfolgsrate: 43.4%\n",
      "ğŸ’¾ Zwischenstand: 4100/17488 | Erfolgsrate: 43.2%\n",
      "ğŸ’¾ Zwischenstand: 4150/17488 | Erfolgsrate: 43.3%\n",
      "ğŸ’¾ Zwischenstand: 4200/17488 | Erfolgsrate: 43.2%\n",
      "ğŸ’¾ Zwischenstand: 4250/17488 | Erfolgsrate: 42.9%\n",
      "ğŸ’¾ Zwischenstand: 4300/17488 | Erfolgsrate: 42.7%\n",
      "ğŸ’¾ Zwischenstand: 4350/17488 | Erfolgsrate: 42.5%\n",
      "ğŸ’¾ Zwischenstand: 4400/17488 | Erfolgsrate: 42.5%\n",
      "ğŸ’¾ Zwischenstand: 4450/17488 | Erfolgsrate: 42.2%\n",
      "ğŸ’¾ Zwischenstand: 4500/17488 | Erfolgsrate: 42.4%\n",
      "ğŸ’¾ Zwischenstand: 4550/17488 | Erfolgsrate: 42.4%\n",
      "ğŸ’¾ Zwischenstand: 4600/17488 | Erfolgsrate: 42.3%\n",
      "ğŸ’¾ Zwischenstand: 4650/17488 | Erfolgsrate: 42.2%\n",
      "ğŸ’¾ Zwischenstand: 4700/17488 | Erfolgsrate: 41.8%\n",
      "ğŸ’¾ Zwischenstand: 4750/17488 | Erfolgsrate: 41.5%\n",
      "ğŸ’¾ Zwischenstand: 4800/17488 | Erfolgsrate: 41.4%\n",
      "ğŸ’¾ Zwischenstand: 4850/17488 | Erfolgsrate: 41.4%\n",
      "ğŸ’¾ Zwischenstand: 4900/17488 | Erfolgsrate: 41.3%\n",
      "ğŸ’¾ Zwischenstand: 4950/17488 | Erfolgsrate: 41.1%\n",
      "ğŸ’¾ Zwischenstand: 5000/17488 | Erfolgsrate: 40.9%\n",
      "ğŸ’¾ Zwischenstand: 5050/17488 | Erfolgsrate: 40.5%\n",
      "ğŸ’¾ Zwischenstand: 5100/17488 | Erfolgsrate: 40.4%\n",
      "ğŸ’¾ Zwischenstand: 5150/17488 | Erfolgsrate: 40.4%\n",
      "ğŸ’¾ Zwischenstand: 5200/17488 | Erfolgsrate: 40.5%\n",
      "ğŸ’¾ Zwischenstand: 5250/17488 | Erfolgsrate: 40.3%\n",
      "ğŸ’¾ Zwischenstand: 5300/17488 | Erfolgsrate: 40.2%\n",
      "ğŸ’¾ Zwischenstand: 5350/17488 | Erfolgsrate: 40.1%\n",
      "ğŸ’¾ Zwischenstand: 5400/17488 | Erfolgsrate: 40.2%\n",
      "ğŸ’¾ Zwischenstand: 5450/17488 | Erfolgsrate: 40.1%\n",
      "ğŸ’¾ Zwischenstand: 5500/17488 | Erfolgsrate: 40.1%\n",
      "ğŸ’¾ Zwischenstand: 5550/17488 | Erfolgsrate: 40.0%\n",
      "ğŸ’¾ Zwischenstand: 5600/17488 | Erfolgsrate: 40.0%\n",
      "ğŸ’¾ Zwischenstand: 5650/17488 | Erfolgsrate: 40.0%\n",
      "ğŸ’¾ Zwischenstand: 5700/17488 | Erfolgsrate: 39.9%\n",
      "ğŸ’¾ Zwischenstand: 5750/17488 | Erfolgsrate: 39.9%\n",
      "ğŸ’¾ Zwischenstand: 5800/17488 | Erfolgsrate: 39.7%\n",
      "ğŸ’¾ Zwischenstand: 5850/17488 | Erfolgsrate: 39.7%\n",
      "ğŸ’¾ Zwischenstand: 5900/17488 | Erfolgsrate: 39.6%\n",
      "ğŸ’¾ Zwischenstand: 5950/17488 | Erfolgsrate: 39.4%\n",
      "ğŸ’¾ Zwischenstand: 6000/17488 | Erfolgsrate: 39.4%\n",
      "ğŸ’¾ Zwischenstand: 6050/17488 | Erfolgsrate: 39.2%\n",
      "ğŸ’¾ Zwischenstand: 6100/17488 | Erfolgsrate: 39.1%\n",
      "ğŸ’¾ Zwischenstand: 6150/17488 | Erfolgsrate: 38.9%\n",
      "ğŸ’¾ Zwischenstand: 6200/17488 | Erfolgsrate: 39.0%\n",
      "ğŸ’¾ Zwischenstand: 6250/17488 | Erfolgsrate: 39.0%\n",
      "ğŸ’¾ Zwischenstand: 6300/17488 | Erfolgsrate: 39.1%\n",
      "ğŸ’¾ Zwischenstand: 6350/17488 | Erfolgsrate: 39.1%\n",
      "ğŸ’¾ Zwischenstand: 6400/17488 | Erfolgsrate: 38.9%\n",
      "ğŸ’¾ Zwischenstand: 6450/17488 | Erfolgsrate: 39.0%\n",
      "ğŸ’¾ Zwischenstand: 6500/17488 | Erfolgsrate: 38.9%\n",
      "ğŸ’¾ Zwischenstand: 6550/17488 | Erfolgsrate: 39.1%\n",
      "ğŸ’¾ Zwischenstand: 6600/17488 | Erfolgsrate: 39.2%\n",
      "ğŸ’¾ Zwischenstand: 6650/17488 | Erfolgsrate: 39.5%\n",
      "ğŸ’¾ Zwischenstand: 6700/17488 | Erfolgsrate: 39.4%\n",
      "ğŸ’¾ Zwischenstand: 6750/17488 | Erfolgsrate: 39.5%\n",
      "ğŸ’¾ Zwischenstand: 6800/17488 | Erfolgsrate: 39.5%\n",
      "ğŸ’¾ Zwischenstand: 6850/17488 | Erfolgsrate: 39.3%\n",
      "ğŸ’¾ Zwischenstand: 6900/17488 | Erfolgsrate: 39.1%\n",
      "ğŸ’¾ Zwischenstand: 6950/17488 | Erfolgsrate: 38.9%\n",
      "ğŸ’¾ Zwischenstand: 7000/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 7050/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 7100/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 7150/17488 | Erfolgsrate: 38.5%\n",
      "ğŸ’¾ Zwischenstand: 7200/17488 | Erfolgsrate: 38.5%\n",
      "ğŸ’¾ Zwischenstand: 7250/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 7300/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 7350/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 7400/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 7450/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 7500/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 7550/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 7600/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 7650/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 7700/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 7750/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 7800/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 7850/17488 | Erfolgsrate: 38.5%\n",
      "ğŸ’¾ Zwischenstand: 7900/17488 | Erfolgsrate: 38.5%\n",
      "ğŸ’¾ Zwischenstand: 7950/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 8000/17488 | Erfolgsrate: 38.5%\n",
      "ğŸ’¾ Zwischenstand: 8050/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 8100/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 8150/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 8200/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 8250/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 8300/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 8350/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 8400/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 8450/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 8500/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8550/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8600/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8650/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8700/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8750/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8800/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 8850/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8900/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 8950/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9000/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 9050/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9100/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 9150/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9200/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9250/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9300/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9350/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 9400/17488 | Erfolgsrate: 38.7%\n",
      "ğŸ’¾ Zwischenstand: 9450/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 9500/17488 | Erfolgsrate: 38.6%\n",
      "ğŸ’¾ Zwischenstand: 9550/17488 | Erfolgsrate: 38.5%\n",
      "ğŸ’¾ Zwischenstand: 9600/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 9650/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 9700/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 9750/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 9800/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 9850/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 9900/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 9950/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10000/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10050/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 10100/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 10150/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 10200/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 10250/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 10300/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 10350/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 10400/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 10450/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 10500/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10550/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10600/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10650/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10700/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 10750/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 10800/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 10850/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 10900/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 10950/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 11000/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 11050/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 11100/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 11150/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 11200/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 11250/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 11300/17488 | Erfolgsrate: 38.4%\n",
      "ğŸ’¾ Zwischenstand: 11350/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 11400/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 11450/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 11500/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 11550/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11600/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11650/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11700/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11750/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11800/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11850/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 11900/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 11950/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 12000/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 12050/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 12100/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 12150/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 12200/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 12250/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 12300/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12350/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12400/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12450/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12500/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12550/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12600/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 12650/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12700/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12750/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12800/17488 | Erfolgsrate: 37.7%\n",
      "ğŸ’¾ Zwischenstand: 12850/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12900/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 12950/17488 | Erfolgsrate: 37.7%\n",
      "ğŸ’¾ Zwischenstand: 13000/17488 | Erfolgsrate: 37.7%\n",
      "ğŸ’¾ Zwischenstand: 13050/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 13100/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 13150/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13200/17488 | Erfolgsrate: 37.8%\n",
      "ğŸ’¾ Zwischenstand: 13250/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13300/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13350/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13400/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13450/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 13500/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 13550/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 13600/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 13650/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13700/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 13750/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 13800/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 13850/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 13900/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 13950/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14000/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 14050/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 14100/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 14150/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14200/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14250/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 14300/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 14350/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 14400/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14450/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14500/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14550/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14600/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 14650/17488 | Erfolgsrate: 37.9%\n",
      "ğŸ’¾ Zwischenstand: 14700/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14750/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 14800/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 14850/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 14900/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 14950/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15000/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15050/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15100/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15150/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15200/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15250/17488 | Erfolgsrate: 38.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 19:14:52 - dnb_api - WARNING - DNB query error for 'tit=\"Praktische Sozialpolitiker aus allen StÃ¤nden : : vom Throne bis zur WerkstÃ¤tte, vom Palast bis zur HÃ¼tte\" and per=SchÃ¼tz': HTTPSConnectionPool(host='services.dnb.de', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Zwischenstand: 15300/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15350/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15400/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15450/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15500/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15550/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15600/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15650/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15700/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15750/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15800/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15850/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15900/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 15950/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16000/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16050/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16100/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16150/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16200/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16250/17488 | Erfolgsrate: 38.0%\n",
      "ğŸ’¾ Zwischenstand: 16300/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16350/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16400/17488 | Erfolgsrate: 38.1%\n",
      "ğŸ’¾ Zwischenstand: 16450/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 16500/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16550/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16600/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16650/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16700/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16750/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16800/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 16850/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 16900/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 16950/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17000/17488 | Erfolgsrate: 38.2%\n",
      "ğŸ’¾ Zwischenstand: 17050/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17100/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17150/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17200/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17250/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17300/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17350/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17400/17488 | Erfolgsrate: 38.3%\n",
      "ğŸ’¾ Zwischenstand: 17450/17488 | Erfolgsrate: 38.3%\n",
      "\n",
      "ğŸ’¾ DNB Titel/Autor-Daten gespeichert: dnb_title_author_data.parquet\n",
      "\n",
      "ğŸ“Š === NEUE TITEL/AUTOR-ABFRAGEN ===\n",
      "   Neue Queries: 17,488\n",
      "   âœ… Gefunden: 6,697 (38.3%)\n",
      "   âŒ Nicht gefunden: 10,791 (61.7%)\n",
      "   ğŸ’¾ Zwischenspeicherungen: 349\n",
      "\n",
      "ğŸ“Š === GESAMT TITEL/AUTOR-DATEN ===\n",
      "   Total Records: 17,488\n",
      "   Erfolgreich: 6,697\n",
      "   Nicht gefunden: 10,791\n",
      "   ğŸ“ˆ Erfolgsrate: 38.3%\n",
      "   ğŸ“š Mit DNB-ISBN (via TA): 3,675\n",
      "   ğŸ“° Mit DNB-ISSN (via TA): 172\n",
      "\n",
      "âœ… Titel/Autor-Daten verfÃ¼gbar als: dnb_title_df\n",
      "   Shape: (17488, 11)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” DNB TITEL/AUTOR-SUCHE (mit verbesserter Suchstrategie!)\n",
    "print(\"ğŸ” === DNB TITEL/AUTOR-SUCHE ===\\n\")\n",
    "\n",
    "# Konfiguration\n",
    "DNB_TITLE_DATA_FILE = processed_dir / 'dnb_title_author_data.parquet'\n",
    "ALWAYS_TA_FOR_ALL_WITH_TITLE_AUTHORS = True  # Variante A: maximale Redundanz\n",
    "RESET_TA_SEARCH = False  # Set to True to reset and re-run with improved strategy\n",
    "\n",
    "print(f\"âš™ï¸  Konfiguration:\")\n",
    "print(f\"   Rate Limit: {RATE_LIMIT_DELAY}s pro Anfrage\")\n",
    "print(f\"   Save Interval: Alle {SAVE_INTERVAL} Queries\")\n",
    "print(f\"   Output: {DNB_TITLE_DATA_FILE.name}\")\n",
    "print(f\"   TA fÃ¼r alle Titel+Autoren: {ALWAYS_TA_FOR_ALL_WITH_TITLE_AUTHORS}\")\n",
    "print(f\"   ğŸ”„ Verbesserter Suchalgorithmus aktiv (4-stufige Strategie)\")\n",
    "\n",
    "# Reset wenn gewÃ¼nscht\n",
    "if RESET_TA_SEARCH and DNB_TITLE_DATA_FILE.exists():\n",
    "    backup_file = processed_dir / f'dnb_title_author_data_OLD_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")}.parquet'\n",
    "    DNB_TITLE_DATA_FILE.rename(backup_file)\n",
    "    print(f\"\\nğŸ”„ TA-Suche wird zurÃ¼ckgesetzt - alte Datei gesichert: {backup_file.name}\")\n",
    "\n",
    "# Lade vorhandene Titel/Autor-Suchdaten (falls vorhanden)\n",
    "if DNB_TITLE_DATA_FILE.exists():\n",
    "    print(f\"\\nğŸ“‚ Lade vorhandene Titel/Autor-Suchdaten...\")\n",
    "    dnb_title_df = pd.read_parquet(DNB_TITLE_DATA_FILE)\n",
    "    print(f\"   Bereits abgefragt: {len(dnb_title_df):,}\")\n",
    "    print(f\"   Davon erfolgreich: {(dnb_title_df['dnb_found'] == True).sum():,}\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“‚ Keine vorhandenen Titel/Autor-Suchdaten gefunden - starte neue Abfrage\")\n",
    "    dnb_title_df = pd.DataFrame(columns=[\n",
    "        'vdeh_id', 'query_type', 'title', 'author',\n",
    "        'dnb_found', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher',\n",
    "        'dnb_isbn', 'dnb_issn'\n",
    "    ])\n",
    "\n",
    "# Identifiziere Kandidaten fÃ¼r Titel/Autor-Suche\n",
    "if ALWAYS_TA_FOR_ALL_WITH_TITLE_AUTHORS:\n",
    "    title_author_candidates = df_vdeh[\n",
    "        (df_vdeh['title'].notna()) &\n",
    "        (df_vdeh['authors_str'].notna()) &\n",
    "        (df_vdeh['authors_str'] != '')\n",
    "    ].copy()\n",
    "else:\n",
    "    title_author_candidates = df_vdeh[\n",
    "        (df_vdeh['isbn'].isna()) &\n",
    "        (df_vdeh['issn'].isna()) &\n",
    "        (df_vdeh['title'].notna()) &\n",
    "        (df_vdeh['authors_str'].notna()) &\n",
    "        (df_vdeh['authors_str'] != '')\n",
    "    ].copy()\n",
    "\n",
    "print(f\"\\nğŸ“‹ Titel/Autor-Kandidaten: {len(title_author_candidates):,}\")\n",
    "print(f\"   Mit Titel: {title_author_candidates['title'].notna().sum():,}\")\n",
    "print(f\"   Mit Autoren: {(title_author_candidates['authors_str'].notna() & (title_author_candidates['authors_str'] != '')).sum():,}\")\n",
    "\n",
    "# Erstelle Query-Liste\n",
    "title_queries = title_author_candidates[['id', 'title', 'authors_str']].copy()\n",
    "title_queries.columns = ['vdeh_id', 'title', 'author']\n",
    "title_queries['query_type'] = 'TITLE_AUTHOR'\n",
    "\n",
    "print(f\"   Gesamt Titel/Autor-Queries (vor Deduplikation): {len(title_queries):,}\")\n",
    "\n",
    "# Filtere bereits abgefragte Titel/Autor-Kombinationen\n",
    "if len(dnb_title_df) > 0:\n",
    "    # Erstelle Set der bereits abgefragten vdeh_ids\n",
    "    already_queried = set(dnb_title_df['vdeh_id'])\n",
    "    \n",
    "    # Filtere nur neue Queries\n",
    "    new_title_queries = title_queries[~title_queries['vdeh_id'].isin(already_queried)].copy()\n",
    "    \n",
    "    print(f\"\\nğŸ” Abgleich mit vorhandenen Daten:\")\n",
    "    print(f\"   Bereits vorhanden: {len(title_queries) - len(new_title_queries):,}\")\n",
    "    print(f\"   Neu abzufragen: {len(new_title_queries):,}\")\n",
    "else:\n",
    "    new_title_queries = title_queries\n",
    "    print(f\"\\nğŸ” Alle {len(new_title_queries):,} Titel/Autor-Queries sind neu\")\n",
    "\n",
    "# Nur abfragen wenn neue Queries vorhanden\n",
    "if len(new_title_queries) > 0:\n",
    "    print(f\"\\nğŸ”„ Starte DNB Titel/Autor-Abfrage fÃ¼r {len(new_title_queries):,} neue Queries...\")\n",
    "    print(f\"   ğŸ“š Verwende verbesserte 4-stufige Suchstrategie:\\n\")\n",
    "    print(f\"      1. Titel (Phrase) + Autor\")\n",
    "    print(f\"      2. Titel (WÃ¶rter) + Autor\")\n",
    "    print(f\"      3. Nur Titel (Phrase)\")\n",
    "    print(f\"      4. Nur Titel (WÃ¶rter)\\n\")\n",
    "    \n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    results = []\n",
    "    stats = {'found': 0, 'not_found': 0}\n",
    "    query_count = 0\n",
    "    \n",
    "    for _, row in tqdm(new_title_queries.iterrows(), total=len(new_title_queries), desc=\"ğŸ” DNB Titel/Autor\", unit=\"queries\"):\n",
    "        # API-Abfrage (mit verbesserter Strategie + ISBN/ISSN-Extraktion!)\n",
    "        dnb_result = query_dnb_by_title_author(row['title'], row['author'])\n",
    "        \n",
    "        # Ergebnis speichern (inkl. ISBN/ISSN!)\n",
    "        result_row = {\n",
    "            'vdeh_id': row['vdeh_id'],\n",
    "            'query_type': row['query_type'],\n",
    "            'title': row['title'],\n",
    "            'author': row['author'],\n",
    "            'dnb_found': dnb_result is not None,\n",
    "            'dnb_title': dnb_result.get('title') if dnb_result else None,\n",
    "            'dnb_authors': ', '.join(dnb_result.get('authors', [])) if dnb_result else None,\n",
    "            'dnb_year': dnb_result.get('year') if dnb_result else None,\n",
    "            'dnb_publisher': dnb_result.get('publisher') if dnb_result else None,\n",
    "            'dnb_isbn': dnb_result.get('isbn') if dnb_result else None,\n",
    "            'dnb_issn': dnb_result.get('issn') if dnb_result else None,\n",
    "            'dnb_pages': dnb_result.get('pages') if dnb_result else None\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if dnb_result:\n",
    "            stats['found'] += 1\n",
    "        else:\n",
    "            stats['not_found'] += 1\n",
    "        \n",
    "        query_count += 1\n",
    "        \n",
    "        # RegelmÃ¤ÃŸiges Speichern (alle SAVE_INTERVAL Queries)\n",
    "        if query_count % SAVE_INTERVAL == 0:\n",
    "            # Merge mit vorhandenen Daten\n",
    "            new_results_df = pd.DataFrame(results)\n",
    "            dnb_title_df = pd.concat([dnb_title_df, new_results_df], ignore_index=True)\n",
    "            \n",
    "            # Speichern\n",
    "            dnb_title_df.to_parquet(DNB_TITLE_DATA_FILE, index=False)\n",
    "            \n",
    "            # Reset results fÃ¼r nÃ¤chste Batch\n",
    "            results = []\n",
    "            \n",
    "            current_rate = stats['found'] / query_count * 100\n",
    "            print(f\"ğŸ’¾ Zwischenstand: {query_count}/{len(new_title_queries)} | Erfolgsrate: {current_rate:.1f}%\")\n",
    "        \n",
    "        # Rate Limiting\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Finale Speicherung (restliche Ergebnisse)\n",
    "    if len(results) > 0:\n",
    "        new_results_df = pd.DataFrame(results)\n",
    "        dnb_title_df = pd.concat([dnb_title_df, new_results_df], ignore_index=True)\n",
    "        dnb_title_df.to_parquet(DNB_TITLE_DATA_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ DNB Titel/Autor-Daten gespeichert: {DNB_TITLE_DATA_FILE.name}\")\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(f\"\\nğŸ“Š === NEUE TITEL/AUTOR-ABFRAGEN ===\")\n",
    "    print(f\"   Neue Queries: {len(new_title_queries):,}\")\n",
    "    print(f\"   âœ… Gefunden: {stats['found']:,} ({stats['found']/len(new_title_queries)*100:.1f}%)\")\n",
    "    print(f\"   âŒ Nicht gefunden: {stats['not_found']:,} ({stats['not_found']/len(new_title_queries)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ’¾ Zwischenspeicherungen: {len(new_title_queries)//SAVE_INTERVAL}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâœ… Alle Titel/Autor-Kombinationen bereits abgefragt - keine neuen Abfragen nÃ¶tig\")\n",
    "\n",
    "# Gesamtstatistik\n",
    "print(f\"\\nğŸ“Š === GESAMT TITEL/AUTOR-DATEN ===\")\n",
    "print(f\"   Total Records: {len(dnb_title_df):,}\")\n",
    "print(f\"   Erfolgreich: {(dnb_title_df['dnb_found'] == True).sum():,}\")\n",
    "print(f\"   Nicht gefunden: {(dnb_title_df['dnb_found'] == False).sum():,}\")\n",
    "print(f\"   ğŸ“ˆ Erfolgsrate: {(dnb_title_df['dnb_found'] == True).sum()/len(dnb_title_df)*100:.1f}%\")\n",
    "\n",
    "# Neue Statistik: ISBN/ISSN-Gewinn via TA-Suche\n",
    "if 'dnb_isbn' in dnb_title_df.columns:\n",
    "    isbn_from_ta = (dnb_title_df['dnb_found'] == True) & dnb_title_df['dnb_isbn'].notna()\n",
    "    issn_from_ta = (dnb_title_df['dnb_found'] == True) & dnb_title_df['dnb_issn'].notna()\n",
    "    print(f\"   ğŸ“š Mit DNB-ISBN (via TA): {isbn_from_ta.sum():,}\")\n",
    "    print(f\"   ğŸ“° Mit DNB-ISSN (via TA): {issn_from_ta.sum():,}\")\n",
    "\n",
    "print(f\"\\nâœ… Titel/Autor-Daten verfÃ¼gbar als: dnb_title_df\")\n",
    "print(f\"   Shape: {dnb_title_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6afabbe",
   "metadata": {},
   "source": [
    "# ğŸ” DNB TITEL/JAHR-SUCHE (Neue Methode fÃ¼r Records ohne ISBN/ISSN!)\n",
    "print(\"ğŸ” === DNB TITEL/JAHR-SUCHE ===\\n\")\n",
    "\n",
    "# Import new function\n",
    "from dnb_api import query_dnb_by_title_year\n",
    "\n",
    "# Konfiguration\n",
    "DNB_TITLE_YEAR_DATA_FILE = processed_dir / 'dnb_title_year_data.parquet'\n",
    "RESET_TY_SEARCH = False  # Set to True to reset and re-run\n",
    "\n",
    "print(f\"âš™ï¸  Konfiguration:\")\n",
    "print(f\"   Rate Limit: {RATE_LIMIT_DELAY}s pro Anfrage\")\n",
    "print(f\"   Save Interval: Alle {SAVE_INTERVAL} Queries\")\n",
    "print(f\"   Output: {DNB_TITLE_YEAR_DATA_FILE.name}\")\n",
    "print(f\"   ğŸ†• Neue Suchmethode: Titel + Jahr (fÃ¼r Records ohne ISBN/ISSN/Autoren)\")\n",
    "\n",
    "# Reset wenn gewÃ¼nscht\n",
    "if RESET_TY_SEARCH and DNB_TITLE_YEAR_DATA_FILE.exists():\n",
    "    backup_file = processed_dir / f'dnb_title_year_data_OLD_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")}.parquet'\n",
    "    DNB_TITLE_YEAR_DATA_FILE.rename(backup_file)\n",
    "    print(f\"\\nğŸ”„ TY-Suche wird zurÃ¼ckgesetzt - alte Datei gesichert: {backup_file.name}\")\n",
    "\n",
    "# Lade vorhandene Titel/Jahr-Suchdaten (falls vorhanden)\n",
    "if DNB_TITLE_YEAR_DATA_FILE.exists():\n",
    "    print(f\"\\nğŸ“‚ Lade vorhandene Titel/Jahr-Suchdaten...\")\n",
    "    dnb_ty_df = pd.read_parquet(DNB_TITLE_YEAR_DATA_FILE)\n",
    "    print(f\"   Bereits abgefragt: {len(dnb_ty_df):,}\")\n",
    "    print(f\"   Davon erfolgreich: {(dnb_ty_df['dnb_found'] == True).sum():,}\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“‚ Keine vorhandenen Titel/Jahr-Suchdaten gefunden - starte neue Abfrage\")\n",
    "    dnb_ty_df = pd.DataFrame(columns=[\n",
    "        'vdeh_id', 'query_type', 'title', 'year',\n",
    "        'dnb_found', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher',\n",
    "        'dnb_isbn', 'dnb_issn'\n",
    "    ])\n",
    "\n",
    "# Identifiziere Kandidaten fÃ¼r Titel/Jahr-Suche\n",
    "# Nur Records OHNE ISBN/ISSN UND OHNE Autoren, aber MIT Titel und Jahr\n",
    "title_year_candidates = df_vdeh[\n",
    "    (df_vdeh['isbn'].isna()) &\n",
    "    (df_vdeh['issn'].isna()) &\n",
    "    ((df_vdeh['authors_str'].isna()) | (df_vdeh['authors_str'] == '')) &\n",
    "    (df_vdeh['title'].notna()) &\n",
    "    (df_vdeh['year'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nğŸ“‹ Titel/Jahr-Kandidaten: {len(title_year_candidates):,}\")\n",
    "print(f\"   Ohne ISBN/ISSN: {(title_year_candidates['isbn'].isna() & title_year_candidates['issn'].isna()).sum():,}\")\n",
    "print(f\"   Ohne Autoren: {((title_year_candidates['authors_str'].isna()) | (title_year_candidates['authors_str'] == '')).sum():,}\")\n",
    "print(f\"   Mit Titel: {title_year_candidates['title'].notna().sum():,}\")\n",
    "print(f\"   Mit Jahr: {title_year_candidates['year'].notna().sum():,}\")\n",
    "\n",
    "# Erstelle Query-Liste\n",
    "ty_queries = title_year_candidates[['id', 'title', 'year']].copy()\n",
    "ty_queries.columns = ['vdeh_id', 'title', 'year']\n",
    "ty_queries['query_type'] = 'TITLE_YEAR'\n",
    "\n",
    "print(f\"   Gesamt Titel/Jahr-Queries: {len(ty_queries):,}\")\n",
    "\n",
    "# Filtere bereits abgefragte Titel/Jahr-Kombinationen\n",
    "if len(dnb_ty_df) > 0:\n",
    "    already_queried = set(dnb_ty_df['vdeh_id'])\n",
    "    new_ty_queries = ty_queries[~ty_queries['vdeh_id'].isin(already_queried)].copy()\n",
    "    \n",
    "    print(f\"\\nğŸ” Abgleich mit vorhandenen Daten:\")\n",
    "    print(f\"   Bereits vorhanden: {len(ty_queries) - len(new_ty_queries):,}\")\n",
    "    print(f\"   Neu abzufragen: {len(new_ty_queries):,}\")\n",
    "else:\n",
    "    new_ty_queries = ty_queries\n",
    "    print(f\"\\nğŸ” Alle {len(new_ty_queries):,} Titel/Jahr-Queries sind neu\")\n",
    "\n",
    "# Nur abfragen wenn neue Queries vorhanden\n",
    "if len(new_ty_queries) > 0:\n",
    "    print(f\"\\nğŸ”„ Starte DNB Titel/Jahr-Abfrage fÃ¼r {len(new_ty_queries):,} neue Queries...\")\n",
    "    print(f\"   ğŸ“š 4-stufige Suchstrategie:\\n\")\n",
    "    print(f\"      1. Titel (Phrase) + exaktes Jahr\")\n",
    "    print(f\"      2. Titel (WÃ¶rter) + exaktes Jahr\")\n",
    "    print(f\"      3. Titel (Phrase) + Jahr Â±1\")\n",
    "    print(f\"      4. Titel (WÃ¶rter) + Jahr Â±1\\n\")\n",
    "    \n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    results = []\n",
    "    stats = {'found': 0, 'not_found': 0}\n",
    "    query_count = 0\n",
    "    \n",
    "    for _, row in tqdm(new_ty_queries.iterrows(), total=len(new_ty_queries), desc=\"ğŸ” DNB Titel/Jahr\", unit=\"queries\"):\n",
    "        # API-Abfrage\n",
    "        dnb_result = query_dnb_by_title_year(row['title'], int(row['year']))\n",
    "        \n",
    "        # Ergebnis speichern\n",
    "        result_row = {\n",
    "            'vdeh_id': row['vdeh_id'],\n",
    "            'query_type': row['query_type'],\n",
    "            'title': row['title'],\n",
    "            'year': row['year'],\n",
    "            'dnb_found': dnb_result is not None,\n",
    "            'dnb_title': dnb_result.get('title') if dnb_result else None,\n",
    "            'dnb_authors': ', '.join(dnb_result.get('authors', [])) if dnb_result else None,\n",
    "            'dnb_year': dnb_result.get('year') if dnb_result else None,\n",
    "            'dnb_publisher': dnb_result.get('publisher') if dnb_result else None,\n",
    "            'dnb_isbn': dnb_result.get('isbn') if dnb_result else None,\n",
    "            'dnb_issn': dnb_result.get('issn') if dnb_result else None,\n",
    "            'dnb_pages': dnb_result.get('pages') if dnb_result else None\n",
    "        }\n",
    "        \n",
    "        results.append(result_row)\n",
    "        \n",
    "        if dnb_result:\n",
    "            stats['found'] += 1\n",
    "        else:\n",
    "            stats['not_found'] += 1\n",
    "        \n",
    "        query_count += 1\n",
    "        \n",
    "        # RegelmÃ¤ÃŸiges Speichern\n",
    "        if query_count % SAVE_INTERVAL == 0:\n",
    "            new_results_df = pd.DataFrame(results)\n",
    "            dnb_ty_df = pd.concat([dnb_ty_df, new_results_df], ignore_index=True)\n",
    "            dnb_ty_df.to_parquet(DNB_TITLE_YEAR_DATA_FILE, index=False)\n",
    "            results = []\n",
    "            \n",
    "            current_rate = stats['found'] / query_count * 100\n",
    "            print(f\"ğŸ’¾ Zwischenstand: {query_count}/{len(new_ty_queries)} | Erfolgsrate: {current_rate:.1f}%\")\n",
    "        \n",
    "        # Rate Limiting\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Finale Speicherung\n",
    "    if len(results) > 0:\n",
    "        new_results_df = pd.DataFrame(results)\n",
    "        dnb_ty_df = pd.concat([dnb_ty_df, new_results_df], ignore_index=True)\n",
    "        dnb_ty_df.to_parquet(DNB_TITLE_YEAR_DATA_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ DNB Titel/Jahr-Daten gespeichert: {DNB_TITLE_YEAR_DATA_FILE.name}\")\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(f\"\\nğŸ“Š === NEUE TITEL/JAHR-ABFRAGEN ===\" )\n",
    "    print(f\"   Neue Queries: {len(new_ty_queries):,}\")\n",
    "    print(f\"   âœ… Gefunden: {stats['found']:,} ({stats['found']/len(new_ty_queries)*100:.1f}%)\")\n",
    "    print(f\"   âŒ Nicht gefunden: {stats['not_found']:,} ({stats['not_found']/len(new_ty_queries)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ’¾ Zwischenspeicherungen: {len(new_ty_queries)//SAVE_INTERVAL}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâœ… Alle Titel/Jahr-Kombinationen bereits abgefragt - keine neuen Abfragen nÃ¶tig\")\n",
    "\n",
    "# Gesamtstatistik\n",
    "print(f\"\\nğŸ“Š === GESAMT TITEL/JAHR-DATEN ===\" )\n",
    "print(f\"   Total Records: {len(dnb_ty_df):,}\")\n",
    "print(f\"   Erfolgreich: {(dnb_ty_df['dnb_found'] == True).sum():,}\")\n",
    "print(f\"   Nicht gefunden: {(dnb_ty_df['dnb_found'] == False).sum():,}\")\n",
    "if len(dnb_ty_df) > 0:\n",
    "    print(f\"   ğŸ“ˆ Erfolgsrate: {(dnb_ty_df['dnb_found'] == True).sum()/len(dnb_ty_df)*100:.1f}%\")\n",
    "\n",
    "# ISBN/ISSN-Gewinn via TY-Suche\n",
    "if 'dnb_isbn' in dnb_ty_df.columns and len(dnb_ty_df) > 0:\n",
    "    isbn_from_ty = (dnb_ty_df['dnb_found'] == True) & dnb_ty_df['dnb_isbn'].notna()\n",
    "    issn_from_ty = (dnb_ty_df['dnb_found'] == True) & dnb_ty_df['dnb_issn'].notna()\n",
    "    authors_from_ty = (dnb_ty_df['dnb_found'] == True) & dnb_ty_df['dnb_authors'].notna()\n",
    "    print(f\"   ğŸ“š Mit DNB-ISBN (via TY): {isbn_from_ty.sum():,}\")\n",
    "    print(f\"   ğŸ“° Mit DNB-ISSN (via TY): {issn_from_ty.sum():,}\")\n",
    "    print(f\"   âœï¸  Mit DNB-Autoren (via TY): {authors_from_ty.sum():,}\")\n",
    "\n",
    "print(f\"\\nâœ… Titel/Jahr-Daten verfÃ¼gbar als: dnb_ty_df\")\n",
    "print(f\"   Shape: {dnb_ty_df.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f008b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vdeh_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>dnb_found</th>\n",
       "      <th>dnb_title</th>\n",
       "      <th>dnb_authors</th>\n",
       "      <th>dnb_year</th>\n",
       "      <th>dnb_publisher</th>\n",
       "      <th>dnb_isbn</th>\n",
       "      <th>dnb_issn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000004</td>\n",
       "      <td>TITLE_AUTHOR</td>\n",
       "      <td>Untersuchung der Gleichgewichte zwischen flÃ¼ss...</td>\n",
       "      <td>Thielmann, R.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000005</td>\n",
       "      <td>TITLE_AUTHOR</td>\n",
       "      <td>Electromagnetic stirring of steel during solid...</td>\n",
       "      <td>Marr, H.S. | Ludlow, V. | Summers, C.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000006</td>\n",
       "      <td>TITLE_AUTHOR</td>\n",
       "      <td>Optimierung der Schwingbeanspruchungen von Ant...</td>\n",
       "      <td>Gudehus, H.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000007</td>\n",
       "      <td>TITLE_AUTHOR</td>\n",
       "      <td>Optimierung der Schwingbeanspruchungen von Ant...</td>\n",
       "      <td>Peuker, G. | Reimann, D.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000008</td>\n",
       "      <td>TITLE_AUTHOR</td>\n",
       "      <td>Optimierung der Schwingbeanspruchungen von Ant...</td>\n",
       "      <td>WÃ¼nsch, D. | Harmeyer, G. | John, F.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     vdeh_id    query_type                                              title  \\\n",
       "0  000000004  TITLE_AUTHOR  Untersuchung der Gleichgewichte zwischen flÃ¼ss...   \n",
       "1  000000005  TITLE_AUTHOR  Electromagnetic stirring of steel during solid...   \n",
       "2  000000006  TITLE_AUTHOR  Optimierung der Schwingbeanspruchungen von Ant...   \n",
       "3  000000007  TITLE_AUTHOR  Optimierung der Schwingbeanspruchungen von Ant...   \n",
       "4  000000008  TITLE_AUTHOR  Optimierung der Schwingbeanspruchungen von Ant...   \n",
       "\n",
       "                                  author dnb_found dnb_title dnb_authors  \\\n",
       "0                          Thielmann, R.     False      None        None   \n",
       "1  Marr, H.S. | Ludlow, V. | Summers, C.     False      None        None   \n",
       "2                            Gudehus, H.     False      None        None   \n",
       "3               Peuker, G. | Reimann, D.     False      None        None   \n",
       "4   WÃ¼nsch, D. | Harmeyer, G. | John, F.     False      None        None   \n",
       "\n",
       "   dnb_year dnb_publisher dnb_isbn dnb_issn  \n",
       "0       NaN          None     None     None  \n",
       "1       NaN          None     None     None  \n",
       "2       NaN          None     None     None  \n",
       "3       NaN          None     None     None  \n",
       "4       NaN          None     None     None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnb_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f121c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— === DNB-DATEN MERGE ===\n",
      "\n",
      "âœ… ISBN/ISSN-basierte DNB-Daten (ID) gemerged â†’ Spalten: dnb_title, dnb_authors, dnb_year, dnb_publisher\n",
      "   + dnb_isbn, dnb_issn\n",
      "   ID-Matches: 5,770\n",
      "âœ… Titel/Autor-basierte DNB-Daten (TA) gemerged â†’ Spalten: dnb_*_ta\n",
      "   + dnb_isbn_ta, dnb_issn_ta\n",
      "   TA-Matches: 6,697\n",
      "\n",
      "ğŸ“Š === MERGE ZUSAMMENFASSUNG ===\n",
      "   Total Records: 58,305\n",
      "   Mit ID-DNB: 5,770\n",
      "   Mit TA-DNB: 6,697\n",
      "   Mit DNB-ISBN (ID): 5,770\n",
      "   Mit DNB-ISBN (TA): 3,675\n",
      "   Mit DNB-ISSN (ID): 43\n",
      "   Mit DNB-ISSN (TA): 172\n",
      "\n",
      "âœ… df_enriched erstellt und bereit zum Speichern\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”— DNB-DATEN MIT VDEH-DATEN ZUSAMMENFÃœHREN\n",
    "print(\"ğŸ”— === DNB-DATEN MERGE ===\\n\")\n",
    "\n",
    "# Starte mit VDEH-Daten\n",
    "df_enriched = df_vdeh.copy()\n",
    "\n",
    "# 1. Merge ISBN/ISSN-basierte DNB-Daten (als ID-Variante)\n",
    "if len(dnb_data_df) > 0:\n",
    "    # PrÃ¼fe ob ISBN/ISSN-Spalten existieren (RÃ¼ckwÃ¤rtskompatibilitÃ¤t)\n",
    "    cols_to_merge = ['vdeh_id', 'query_type', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher']\n",
    "    if 'dnb_isbn' in dnb_data_df.columns:\n",
    "        cols_to_merge.append('dnb_isbn')\n",
    "    if 'dnb_issn' in dnb_data_df.columns:\n",
    "        cols_to_merge.append('dnb_issn')\n",
    "    \n",
    "    dnb_isbn_issn = dnb_data_df[dnb_data_df['dnb_found'] == True][cols_to_merge].rename(\n",
    "        columns={'query_type': 'dnb_query_method'}\n",
    "    )\n",
    "    \n",
    "    df_enriched = df_enriched.merge(\n",
    "        dnb_isbn_issn,\n",
    "        left_on='id',\n",
    "        right_on='vdeh_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    if 'vdeh_id' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=['vdeh_id'], inplace=True)\n",
    "    if 'dnb_title_dup' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=[c for c in df_enriched.columns if c.endswith('_dup')], inplace=True)\n",
    "    \n",
    "    print(f\"âœ… ISBN/ISSN-basierte DNB-Daten (ID) gemerged â†’ Spalten: dnb_title, dnb_authors, dnb_year, dnb_publisher\")\n",
    "    if 'dnb_isbn' in df_enriched.columns:\n",
    "        print(f\"   + dnb_isbn, dnb_issn\")\n",
    "    print(f\"   ID-Matches: {df_enriched['dnb_query_method'].notna().sum():,}\")\n",
    "\n",
    "# 2. Merge Titel/Autor-basierte DNB-Daten als separate Variante (_ta)\n",
    "if len(dnb_title_df) > 0:\n",
    "    # PrÃ¼fe ob ISBN/ISSN-Spalten existieren (RÃ¼ckwÃ¤rtskompatibilitÃ¤t)\n",
    "    cols_to_merge_ta = ['vdeh_id', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher']\n",
    "    if 'dnb_isbn' in dnb_title_df.columns:\n",
    "        cols_to_merge_ta.append('dnb_isbn')\n",
    "    if 'dnb_issn' in dnb_title_df.columns:\n",
    "        cols_to_merge_ta.append('dnb_issn')\n",
    "    \n",
    "    dnb_title_matches = dnb_title_df[dnb_title_df['dnb_found'] == True][cols_to_merge_ta].copy()\n",
    "    \n",
    "    # Rename mit _ta Suffix\n",
    "    rename_map = {\n",
    "        'dnb_title': 'dnb_title_ta',\n",
    "        'dnb_authors': 'dnb_authors_ta',\n",
    "        'dnb_year': 'dnb_year_ta',\n",
    "        'dnb_publisher': 'dnb_publisher_ta'\n",
    "    }\n",
    "    if 'dnb_isbn' in cols_to_merge_ta:\n",
    "        rename_map['dnb_isbn'] = 'dnb_isbn_ta'\n",
    "    if 'dnb_issn' in cols_to_merge_ta:\n",
    "        rename_map['dnb_issn'] = 'dnb_issn_ta'\n",
    "    if 'dnb_pages' in cols_to_merge_ta:\n",
    "        rename_map['dnb_pages'] = 'dnb_pages_ta'\n",
    "    \n",
    "    dnb_title_matches = dnb_title_matches.rename(columns=rename_map)\n",
    "    \n",
    "    df_enriched = df_enriched.merge(\n",
    "        dnb_title_matches,\n",
    "        left_on='id',\n",
    "        right_on='vdeh_id',\n",
    "        how='left'\n",
    "    )\n",
    "    if 'vdeh_id' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=['vdeh_id'], inplace=True)\n",
    "    \n",
    "    print(f\"âœ… Titel/Autor-basierte DNB-Daten (TA) gemerged â†’ Spalten: dnb_*_ta\")\n",
    "    if 'dnb_isbn_ta' in df_enriched.columns:\n",
    "        print(f\"   + dnb_isbn_ta, dnb_issn_ta\")\n",
    "    print(f\"   TA-Matches: {df_enriched[['dnb_title_ta','dnb_authors_ta','dnb_year_ta','dnb_publisher_ta']].notna().any(axis=1).sum():,}\")\n",
    "\n",
    "# 3. RÃ¼ckwÃ¤rtskompatibilitÃ¤t: dnb_query_method belassen (zeigt ID vs Titel/Autor als PrimÃ¤rquelle)\n",
    "#    (wird kÃ¼nftig nur noch als Hinweis genutzt; Fusion vergleicht explizit beide Varianten)\n",
    "\n",
    "# 3. Merge Titel/Jahr-basierte DNB-Daten als separate Variante (_ty)\n",
    "if len(dnb_ty_df) > 0:\n",
    "    # PrÃ¼fe ob ISBN/ISSN-Spalten existieren\n",
    "    cols_to_merge_ty = ['vdeh_id', 'dnb_title', 'dnb_authors', 'dnb_year', 'dnb_publisher']\n",
    "    if 'dnb_isbn' in dnb_ty_df.columns:\n",
    "        cols_to_merge_ty.append('dnb_isbn')\n",
    "    if 'dnb_issn' in dnb_ty_df.columns:\n",
    "        cols_to_merge_ty.append('dnb_issn')\n",
    "\n",
    "    dnb_ty_matches = dnb_ty_df[dnb_ty_df['dnb_found'] == True][cols_to_merge_ty].copy()\n",
    "\n",
    "    # Rename mit _ty Suffix\n",
    "    rename_map = {\n",
    "        'dnb_title': 'dnb_title_ty',\n",
    "        'dnb_authors': 'dnb_authors_ty',\n",
    "        'dnb_year': 'dnb_year_ty',\n",
    "        'dnb_publisher': 'dnb_publisher_ty'\n",
    "    }\n",
    "    if 'dnb_isbn' in cols_to_merge_ty:\n",
    "        rename_map['dnb_isbn'] = 'dnb_isbn_ty'\n",
    "    if 'dnb_issn' in cols_to_merge_ty:\n",
    "        rename_map['dnb_issn'] = 'dnb_issn_ty'\n",
    "    if 'dnb_pages' in cols_to_merge_ty:\n",
    "        rename_map['dnb_pages'] = 'dnb_pages_ty'\n",
    "\n",
    "    dnb_ty_matches = dnb_ty_matches.rename(columns=rename_map)\n",
    "\n",
    "    df_enriched = df_enriched.merge(\n",
    "        dnb_ty_matches,\n",
    "        left_on='id',\n",
    "        right_on='vdeh_id',\n",
    "        how='left'\n",
    "    )\n",
    "    if 'vdeh_id' in df_enriched.columns:\n",
    "        df_enriched.drop(columns=['vdeh_id'], inplace=True)\n",
    "\n",
    "    print(f\"âœ… Titel/Jahr-basierte DNB-Daten (TY) gemerged â†’ Spalten: dnb_*_ty\")\n",
    "    if 'dnb_isbn_ty' in df_enriched.columns:\n",
    "        print(f\"   + dnb_isbn_ty, dnb_issn_ty\")\n",
    "    print(f\"   TY-Matches: {df_enriched[['dnb_title_ty','dnb_authors_ty','dnb_year_ty','dnb_publisher_ty']].notna().any(axis=1).sum():,}\")\n",
    "\n",
    "# 4. RÃ¼ckwÃ¤rtskompatibilitÃ¤t\n",
    "#    dnb_query_method zeigt nur noch ID-Quelle; Fusion vergleicht alle drei Varianten (ID, TA, TY)\n",
    "\n",
    "# # Zusammenfassung\n",
    "print(f\"\\nğŸ“Š === MERGE ZUSAMMENFASSUNG ===\")\n",
    "print(f\"   Total Records: {len(df_enriched):,}\")\n",
    "print(f\"   Mit ID-DNB: {df_enriched['dnb_query_method'].notna().sum():,}\")\n",
    "print(f\"   Mit TA-DNB: {df_enriched[['dnb_title_ta','dnb_authors_ta','dnb_year_ta','dnb_publisher_ta']].notna().any(axis=1).sum():,}\")\n",
    "print(f\"   Mit TY-DNB: {df_enriched[['dnb_title_ty','dnb_authors_ty','dnb_year_ty','dnb_publisher_ty']].notna().any(axis=1).sum() if 'dnb_title_ty' in df_enriched.columns else 0:,}\")\n",
    "\n",
    "# ISBN/ISSN-Statistik\n",
    "if 'dnb_isbn' in df_enriched.columns:\n",
    "    isbn_id_count = df_enriched['dnb_isbn'].notna().sum()\n",
    "    isbn_ta_count = df_enriched.get('dnb_isbn_ta', pd.Series()).notna().sum() if 'dnb_isbn_ta' in df_enriched.columns else 0\n",
    "    print(f\"   Mit DNB-ISBN (ID): {isbn_id_count:,}\")\n",
    "    print(f\"   Mit DNB-ISBN (TA): {isbn_ta_count:,}\")\n",
    "    \n",
    "if 'dnb_issn' in df_enriched.columns:\n",
    "    issn_id_count = df_enriched['dnb_issn'].notna().sum()\n",
    "    issn_ta_count = df_enriched.get('dnb_issn_ta', pd.Series()).notna().sum() if 'dnb_issn_ta' in df_enriched.columns else 0\n",
    "    print(f\"   Mit DNB-ISSN (ID): {issn_id_count:,}\")\n",
    "    print(f\"   Mit DNB-ISSN (TA): {issn_ta_count:,}\")\n",
    "\n",
    "if 'dnb_isbn_ty' in df_enriched.columns:\n",
    "    isbn_ty_count = df_enriched['dnb_isbn_ty'].notna().sum()\n",
    "    issn_ty_count = df_enriched.get('dnb_issn_ty', pd.Series()).notna().sum() if 'dnb_issn_ty' in df_enriched.columns else 0\n",
    "    authors_ty_count = df_enriched['dnb_authors_ty'].notna().sum() if 'dnb_authors_ty' in df_enriched.columns else 0\n",
    "    print(f\"   Mit DNB-ISBN (TY): {isbn_ty_count:,}\")\n",
    "    print(f\"   Mit DNB-ISSN (TY): {issn_ty_count:,}\")\n",
    "    print(f\"   Mit DNB-Autoren (TY): {authors_ty_count:,}\")\n",
    "\n",
    "print(f\"\\nâœ… df_enriched erstellt und bereit zum Speichern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4081f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ === DATENTYP-NORMALISIERUNG ===\n",
      "\n",
      "   year: 33,313 â†’ 33,313 (Int64)\n",
      "   dnb_year: 5,746 â†’ 5,746 (Int64)\n",
      "   dnb_year_ta: 5,195 â†’ 5,195 (Int64)\n",
      "\n",
      "âœ… Datentypen normalisiert - bereit zum Speichern\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ DATENTYP-NORMALISIERUNG (VOR dem Speichern!)\n",
    "print(\"ğŸ”§ === DATENTYP-NORMALISIERUNG ===\\n\")\n",
    "\n",
    "# Konvertiere Jahr-Spalten zu Int64 (verhindert float/int Konflikte bei der Fusion)\n",
    "year_columns = ['year', 'dnb_year', 'dnb_year_ta']\n",
    "\n",
    "for col in year_columns:\n",
    "    if col in df_enriched.columns:\n",
    "        # Konvertiere zu Int64, NaN bleiben NaN\n",
    "        original_count = df_enriched[col].notna().sum()\n",
    "        df_enriched[col] = pd.to_numeric(df_enriched[col], errors='coerce').astype('Int64')\n",
    "        new_count = df_enriched[col].notna().sum()\n",
    "        \n",
    "        print(f\"   {col}: {original_count:,} â†’ {new_count:,} (Int64)\")\n",
    "        \n",
    "        if original_count != new_count:\n",
    "            print(f\"      âš ï¸  {original_count - new_count:,} Werte konnten nicht konvertiert werden\")\n",
    "\n",
    "print(f\"\\nâœ… Datentypen normalisiert - bereit zum Speichern\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de03a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ === DATEN SPEICHERN ===\n",
      "\n",
      "âœ… DNB-angereicherte Daten gespeichert: 04_dnb_enriched_data.parquet\n",
      "   Records: 58,305\n",
      "   Spalten: 34\n",
      "   GrÃ¶ÃŸe: 5.0 MB\n",
      "\n",
      "âœ… Metadaten gespeichert: 04_metadata.json\n",
      "\n",
      "ğŸ“Š === DNB ENRICHMENT ABGESCHLOSSEN ===\n",
      "   Input: 58,305 VDEH Records\n",
      "   Output: 58,305 Records mit DNB-Daten\n",
      "   DNB-Queries: 28,153\n",
      "   ID-Variante verfÃ¼gbar: 5,770\n",
      "   TA-Variante verfÃ¼gbar: 6,697\n",
      "\n",
      "â¡ï¸  NÃ¤chster Schritt: 05_vdeh_data_fusion.ipynb\n",
      "   KI-gestÃ¼tzte Fusion von VDEH und DNB Daten (beide Varianten)\n",
      "\n",
      "ğŸ‰ DNB Enrichment erfolgreich abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ DATEN SPEICHERN (vor KI-Fusion)\n",
    "print(\"ğŸ’¾ === DATEN SPEICHERN ===\\n\")\n",
    "\n",
    "# Output-Pfade\n",
    "output_path = processed_dir / '04_dnb_enriched_data.parquet'\n",
    "metadata_output = processed_dir / '04_metadata.json'\n",
    "\n",
    "# 1. Parquet speichern\n",
    "df_enriched.to_parquet(output_path, index=False)\n",
    "print(f\"âœ… DNB-angereicherte Daten gespeichert: {output_path.name}\")\n",
    "print(f\"   Records: {len(df_enriched):,}\")\n",
    "print(f\"   Spalten: {len(df_enriched.columns)}\")\n",
    "print(f\"   GrÃ¶ÃŸe: {output_path.stat().st_size / 1024**2:.1f} MB\")\n",
    "\n",
    "# 2. Metadaten erstellen\n",
    "metadata = {\n",
    "    'step': '04_dnb_enrichment',\n",
    "    'input_file': '03_language_detected_data.parquet',\n",
    "    'output_file': '04_dnb_enriched_data.parquet',\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'record_count': len(df_enriched),\n",
    "    'columns': list(df_enriched.columns),\n",
    "    \n",
    "    # DNB Query Statistiken\n",
    "    'dnb_queries': {\n",
    "        'isbn_issn': {\n",
    "            'total_queries': len(dnb_data_df) if len(dnb_data_df) > 0 else 0,\n",
    "            'successful': int((dnb_data_df['dnb_found'] == True).sum()) if len(dnb_data_df) > 0 else 0,\n",
    "            'failed': int((dnb_data_df['dnb_found'] == False).sum()) if len(dnb_data_df) > 0 else 0\n",
    "        },\n",
    "        'title_author': {\n",
    "            'total_queries': len(dnb_title_df) if len(dnb_title_df) > 0 else 0,\n",
    "            'successful': int((dnb_title_df['dnb_found'] == True).sum()) if len(dnb_title_df) > 0 else 0,\n",
    "            'failed': int((dnb_title_df['dnb_found'] == False).sum()) if len(dnb_title_df) > 0 else 0\n",
    "        },\n",
    "        'title_year': {\n",
    "            'total_queries': len(dnb_ty_df) if 'dnb_ty_df' in locals() and len(dnb_ty_df) > 0 else 0,\n",
    "            'successful': int((dnb_ty_df['dnb_found'] == True).sum()) if 'dnb_ty_df' in locals() and len(dnb_ty_df) > 0 else 0,\n",
    "            'failed': int((dnb_ty_df['dnb_found'] == False).sum()) if 'dnb_ty_df' in locals() and len(dnb_ty_df) > 0 else 0\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # DNB-Daten VerfÃ¼gbarkeit (Varianten)\n",
    "    'dnb_variants': {\n",
    "        'id_available': int(df_enriched['dnb_query_method'].notna().sum()) if 'dnb_query_method' in df_enriched.columns else 0,\n",
    "        'ta_available': int(df_enriched[['dnb_title_ta','dnb_authors_ta','dnb_year_ta','dnb_publisher_ta']].notna().any(axis=1).sum()),\n",
    "        'ty_available': int(df_enriched[['dnb_title_ty','dnb_authors_ty','dnb_year_ty','dnb_publisher_ty']].notna().any(axis=1).sum()) if 'dnb_title_ty' in df_enriched.columns else 0\n",
    "    },\n",
    "    \n",
    "    # DNB-FeldverfÃ¼gbarkeit\n",
    "    'dnb_field_availability': {\n",
    "        'id': {\n",
    "            'title': int(df_enriched['dnb_title'].notna().sum()) if 'dnb_title' in df_enriched.columns else 0,\n",
    "            'authors': int(df_enriched['dnb_authors'].notna().sum()) if 'dnb_authors' in df_enriched.columns else 0,\n",
    "            'year': int(df_enriched['dnb_year'].notna().sum()) if 'dnb_year' in df_enriched.columns else 0,\n",
    "            'publisher': int(df_enriched['dnb_publisher'].notna().sum()) if 'dnb_publisher' in df_enriched.columns else 0\n",
    "        },\n",
    "        'title_author': {\n",
    "            'title': int(df_enriched['dnb_title_ta'].notna().sum()) if 'dnb_title_ta' in df_enriched.columns else 0,\n",
    "            'authors': int(df_enriched['dnb_authors_ta'].notna().sum()) if 'dnb_authors_ta' in df_enriched.columns else 0,\n",
    "            'year': int(df_enriched['dnb_year_ta'].notna().sum()) if 'dnb_year_ta' in df_enriched.columns else 0,\n",
    "            'publisher': int(df_enriched['dnb_publisher_ta'].notna().sum()) if 'dnb_publisher_ta' in df_enriched.columns else 0\n",
    "        },\n",
    "        'title_year': {\n",
    "            'title': int(df_enriched['dnb_title_ty'].notna().sum()) if 'dnb_title_ty' in df_enriched.columns else 0,\n",
    "            'authors': int(df_enriched['dnb_authors_ty'].notna().sum()) if 'dnb_authors_ty' in df_enriched.columns else 0,\n",
    "            'year': int(df_enriched['dnb_year_ty'].notna().sum()) if 'dnb_year_ty' in df_enriched.columns else 0,\n",
    "            'publisher': int(df_enriched['dnb_publisher_ty'].notna().sum()) if 'dnb_publisher_ty' in df_enriched.columns else 0\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Originaldaten-VollstÃ¤ndigkeit\n",
    "    'vdeh_completeness': {\n",
    "        'title': int(df_enriched['title'].notna().sum()),\n",
    "        'authors': int((df_enriched['authors_str'].notna() & (df_enriched['authors_str'] != '')).sum()),\n",
    "        'year': int(df_enriched['year'].notna().sum()),\n",
    "        'publisher': int(df_enriched['publisher'].notna().sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Metadaten speichern\n",
    "with open(metadata_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ… Metadaten gespeichert: {metadata_output.name}\")\n",
    "\n",
    "# 3. Zusammenfassung\n",
    "print(f\"\\nğŸ“Š === DNB ENRICHMENT ABGESCHLOSSEN ===\")\n",
    "print(f\"   Input: {len(df_vdeh):,} VDEH Records\")\n",
    "print(f\"   Output: {len(df_enriched):,} Records mit DNB-Daten\")\n",
    "print(f\"   DNB-Queries: {metadata['dnb_queries']['isbn_issn']['total_queries'] + metadata['dnb_queries']['title_author']['total_queries']:,}\")\n",
    "print(f\"   ID-Variante verfÃ¼gbar: {metadata['dnb_variants']['id_available']:,}\")\n",
    "print(f\"   TA-Variante verfÃ¼gbar: {metadata['dnb_variants']['ta_available']:,}\")\n",
    "print(f\"   TY-Variante verfÃ¼gbar: {metadata['dnb_variants']['ty_available']:,}\")\n",
    "\n",
    "print(f\"\\nâ¡ï¸  NÃ¤chster Schritt: 05_vdeh_data_fusion.ipynb\")\n",
    "print(f\"   KI-gestÃ¼tzte Fusion von VDEH und DNB Daten (alle drei Varianten: ID, TA, TY)\")\n",
    "\n",
    "print(f\"\\nğŸ‰ DNB Enrichment erfolgreich abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563eaf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bibo-analysis-DoEGeq_l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}