# Title/Year Search Implementation

## Ãœberblick

Die **Title/Year (TY)** Suchmethode ist die dritte DNB-Enrichment-Strategie, die Records ohne ISBN/ISSN und ohne Autoren erreichen kann.

## Motivation

**Problem:**
- 40,769 Records fehlen Autoren
- Nur 3,161 (7.8%) haben ISBN/ISSN â†’ kÃ¶nnen via ID-Suche angereichert werden
- Nur ~1,200 (2.9%) haben Autoren â†’ kÃ¶nnen via Title/Author-Suche angereichert werden
- **37,608 Records (92.2%) haben WEDER ISBN/ISSN NOCH Autoren**

**LÃ¶sung:**
- Title/Year Suche fÃ¼r Records mit Titel + Jahr (aber ohne ISBN/ISSN/Autoren)
- Potenzial: 16,458 Records
- Erwartete Ausbeute: 1,645-2,468 zusÃ¤tzliche Autoren (20-30% DNB-Abdeckung)

## Implementierung

### 1. DNB API Extension ([src/dnb_api.py](../src/dnb_api.py))

Neue Funktion: `query_dnb_by_title_year(title, year, max_records=1, max_retries=3)`

**4-stufige Suchstrategie:**
1. Exakter Titel (mit Quotes) + exaktes Jahr
2. Titel ohne Quotes + exaktes Jahr
3. Exakter Titel + Jahr Â±1 (fÃ¼r Publikationsvarianten)
4. Titel ohne Quotes + Jahr Â±1

**SRU Query Format:**
```python
# Strategie 1
query = f'tit="{title_clean}" and jhr={year}'

# Strategie 3
query = f'tit="{title_clean}" and jhr>={year-1} and jhr<={year+1}'
```

**Features:**
- Automatische Retry-Logik mit exponentialem Backoff
- MARC21-XML Parsing
- Extraktion: title, authors, year, publisher, isbn, issn

### 2. Notebook 04 Extension ([notebooks/01_vdeh_preprocessing/04_vdeh_data_enrichment.ipynb](../notebooks/01_vdeh_preprocessing/04_vdeh_data_enrichment.ipynb))

**Neue Zelle:** Title/Year Enrichment (nach Title/Author)

**Kandidaten-Identifikation:**
```python
title_year_candidates = df_vdeh[
    (df_vdeh['isbn'].isna()) &
    (df_vdeh['issn'].isna()) &
    ((df_vdeh['authors_str'].isna()) | (df_vdeh['authors_str'] == '')) &
    (df_vdeh['title'].notna()) &
    (df_vdeh['year'].notna())
]
```

**Neue Spalten:**
- `dnb_title_ty`
- `dnb_authors_ty`
- `dnb_year_ty`
- `dnb_publisher_ty`
- `dnb_isbn_ty`
- `dnb_issn_ty`

**Persistierung:**
- `data/vdeh/processed/dnb_title_year_data.parquet`

### 3. Fusion Engine Extension ([src/fusion/fusion_engine.py](../src/fusion/fusion_engine.py))

**Strategie:** TY als **Fallback mit Similarity-Validierung**

**Logik:**
```python
# Fall 1: Nur TY verfÃ¼gbar (kein ID, kein TA)
if dnb_id is None and dnb_ta is None and dnb_ty is not None:
    # Berechne Titel-Ã„hnlichkeit
    similarity = calculate_title_similarity(vdeh_title, dnb_ty_title)

    # Akzeptiere nur wenn Similarity â‰¥ 70%
    if similarity >= 0.7:
        # Nutze TY als Gap-Filling
        # VDEH-Werte haben PrioritÃ¤t, TY fÃ¼llt nur leere Felder
    else:
        # Reject - zu unsicher
        return vdeh_data
```

**Similarity-Threshold: 70%**
- **Eliminiert False Positives:** Kurze generische Titel ("Casting", "Corrosion") werden abgelehnt
- **Akzeptiert hochwertige Matches:** Spezifische Titel mit >70% Ãœbereinstimmung
- **Balance:** 57.6% der TY-Matches werden akzeptiert (193 von 335)
- **Vorteil:** DatenqualitÃ¤t > DatenquantitÃ¤t

**Warum Similarity statt AI?**
- TY-Records haben keine ISBN/ISSN/Autoren zum Abgleichen
- Titel-Vergleich ist ausreichend und schneller als AI
- AI-Validierung wÃ¼rde bei fehlenden Feldern nichts bringen
- ID/TA haben PrioritÃ¤t (werden via AI validiert)

**Fusion-Hierarchie:**
1. **ID-Variante** (ISBN/ISSN) - hÃ¶chste PrioritÃ¤t (AI-validiert)
2. **TA-Variante** (Title/Author) - zweite PrioritÃ¤t (AI-validiert)
3. **TY-Variante** (Title/Year) - Fallback mit Similarity-Filter (â‰¥70%)
4. **VDEH** - Original immer als Basis

### 4. Testing

**Test-Skripte:**
- `scripts/test_title_year_search.py` - Initiale Tests
- `scripts/test_title_year_with_known_books.py` - Validation mit bekannten BÃ¼chern
- `scripts/analyze_title_year_potential.py` - Potenzial-Analyse

**Test-Ergebnisse:**
- âœ… 6/7 bekannte deutsche BÃ¼cher gefunden (86% Erfolg)
- âš ï¸ VDEH-Records (technische Berichte) nicht in DNB
- ğŸ“Š ~50% VDEH-Kandidaten sind technische Berichte (niedrige DNB-Abdeckung)
- ğŸ“Š ~50% VDEH-Kandidaten sind potenziell publizierte BÃ¼cher (20-30% DNB-Abdeckung)

## TatsÃ¤chliche Ergebnisse (mit 70% Similarity-Filter)

### Vorher (nur ID + TA):
- Autoren gefÃ¼llt: 371 von 40,769 (0.9%)
- ISBN gefÃ¼llt: 604
- ISSN gefÃ¼llt: 127

### Nachher (mit TY + Similarity-Filter):
- **Hochwertige TY-Matches:** 193 von 335 Raw-Matches (57.6% Akzeptanz)
- **Neue Autoren:** ~101 zusÃ¤tzliche Records mit Autoren
- **Autoren gefÃ¼llt:** **~472** (371 + 101) von 40,769 (**1.2%**)
  - **Verbesserung:** +27% (nicht 5-8x wie initial erwartet)
- **ISBN gefÃ¼llt:** ~607 (+3, TY-Records haben selten ISBN)
- **ISSN gefÃ¼llt:** ~241 (+114, viele Zeitschriften)
- **Publisher gefÃ¼llt:** +190 zusÃ¤tzliche Records

### Warum weniger als erwartet?

**Initial geschÃ¤tzt:** 1,645-2,468 neue Autoren (10-15% DNB-Abdeckung)

**TatsÃ¤chlich:** ~101 neue Autoren (0.6% der 16,458 TY-Kandidaten)

**GrÃ¼nde:**
1. **DNB-Abdeckung nur 2%** (statt 10-15%)
   - 95.2% der TY-Queries fanden kein DNB-Match
   - VDEH-Bestand enthÃ¤lt viele technische Berichte, Normen, Standards (nicht in DNB)

2. **Similarity-Filter eliminiert 42.4%**
   - Von 335 Raw-Matches â†’ 193 akzeptiert, 142 abgelehnt
   - Notwendig um False Positives zu vermeiden

3. **Impact trotzdem wertvoll:**
   - **+27% mehr Autoren** (371 â†’ 472)
   - **+90% mehr ISSN** (127 â†’ 241)
   - **Hohe DatenqualitÃ¤t** durch Similarity-Validierung

### API-Kosten:
- ~16,458 neue Queries (vollstÃ¤ndig durchgefÃ¼hrt)
- Bei 1 Query/sec: ~4.6 Stunden
- Rate-Limiting: 1s Pause pro Query
- **TatsÃ¤chlicher Ertrag:** 193 hochwertige Matches

## Datenfluss

```
01_loaded_data.parquet (MARC21)
    â†“
04_dnb_enriched_data.parquet
    â”œâ”€â”€ dnb_*        (ID-Variante: ISBN/ISSN)
    â”œâ”€â”€ dnb_*_ta     (TA-Variante: Title/Author)
    â””â”€â”€ dnb_*_ty     (TY-Variante: Title/Year) â† NEU
    â†“
05_fused_data.parquet
    â”œâ”€â”€ fusion_*_source
    â”‚   â”œâ”€â”€ 'vdeh'
    â”‚   â”œâ”€â”€ 'dnb_id'
    â”‚   â”œâ”€â”€ 'dnb_title_author'
    â”‚   â””â”€â”€ 'dnb_title_year' â† NEU
    â””â”€â”€ dnb_variant_selected
        â”œâ”€â”€ 'id'
        â”œâ”€â”€ 'title_author'
        â””â”€â”€ 'title_year' â† NEU
```

## Verwendung

### DNB API:
```python
from src.dnb_api import query_dnb_by_title_year

result = query_dnb_by_title_year('Die Verwandlung', 1915)
if result:
    print(result['title'])    # "Die Verwandlung"
    print(result['authors'])  # ['Kafka, Franz']
    print(result['year'])     # 1915
    print(result['isbn'])     # None (alte Ausgabe ohne ISBN)
```

### Fusion:
```python
# Automatisch in FusionEngine.merge_record()
# TY wird nur genutzt wenn ID und TA beide None sind
```

### Notebook 04 ausfÃ¼hren:
```bash
poetry run papermill \
    notebooks/01_vdeh_preprocessing/04_vdeh_data_enrichment.ipynb \
    output.ipynb
```

## EinschrÃ¤nkungen

1. **DNB-Abdeckung:** Technische Berichte nicht in DNB
   - ~50% VDEH-Kandidaten sind Conference Proceedings / Forschungsberichte
   - DNB fokussiert auf publizierte BÃ¼cher, Zeitschriften, Dissertationen

2. **Genauigkeit:** Titel+Jahr weniger prÃ¤zise als ISBN
   - Mehrere Ausgaben desselben Werks mÃ¶glich
   - Â±1 Jahr-Toleranz kann zu falschen Matches fÃ¼hren
   - Daher nur als Fallback ohne AI-Validierung

3. **Performance:** ~4.6 Stunden fÃ¼r volle Abfrage
   - 16,458 Queries Ã  1 Sekunde
   - Kann parallelisiert werden (mit Vorsicht wegen Rate-Limiting)

## NÃ¤chste Schritte

1. âœ… API-Funktion implementiert
2. âœ… Notebook 04 erweitert
3. âœ… Fusion-Engine angepasst
4. â³ Pipeline komplett ausfÃ¼hren
5. â³ Ergebnisse analysieren
6. â³ Reports aktualisieren

## Ã„nderungshistorie

- **2025-12-12:** Initiale Implementierung
  - DNB API Extension
  - Notebook 04 Title/Year Cell
  - Fusion Engine Fallback-Logik
  - Testing und Validation
  - Potenzial-Analyse
