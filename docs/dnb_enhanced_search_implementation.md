# DNB Enhanced Search Strategy - Implementation Documentation

**Version:** 2.2.0
**Datum:** 13. Dezember 2025
**Status:** âœ… Implementiert und getestet

## ğŸ“‹ Ãœbersicht

Diese Dokumentation beschreibt die erweiterte DNB-Abfragestrategie, die entwickelt wurde um die Erfolgsquote bei DNB-Queries trotz unvollstÃ¤ndiger/fehlerhafter Daten zu erhÃ¶hen.

## ğŸ¯ Zielsetzung

**Problem:** Viele DNB-Queries scheitern aufgrund von:
- Tippfehlern in Titeln
- Umlauten/Sonderzeichen-Unterschiede
- Sehr langen Titeln (DNB-API-Limits)
- Fehlende Validierung fÃ¼hrt zu False Positives

**LÃ¶sung:** Mehrstufige tolerantere Suchstrategie mit:
1. **Text-Normalisierung** fÃ¼r Umlaute/Sonderzeichen
2. **Truncated Search** fÃ¼r lange Titel
3. **Erweiterte Validierung** gegen False Positives

## ğŸ”§ Implementierung

### 1. Text-Normalisierung (`_normalize_for_search`)

**Location:** `src/dnb_api.py`

**Funktion:**
```python
def _normalize_for_search(text: str) -> str:
    """Normalisiert Text fÃ¼r tolerantere DNB-Suche."""
```

**Was wird normalisiert:**
- **Umlaute/Akzente:** "Ã¼ber" â†’ "uber", "MÃ¼ller" â†’ "Muller"
- **Sonderzeichen:** "C++" â†’ "C", "â€“" â†’ " "
- **Mehrfache Leerzeichen:** "  " â†’ " "

**Beispiele:**
| Original | Normalisiert |
|----------|-------------|
| Ãœber die PrÃ¼fung von StÃ¤hlen | Uber die Prufung von Stahlen |
| C++ Programmierung | C Programmierung |
| Stahlbau â€“ Grundlagen | Stahlbau Grundlagen |
| MÃ¼ller, JÃ¼rgen | Muller Jurgen |

**Technische Details:**
- Unicode NFKD-Normalisierung (zerlegt Zeichen mit Akzenten)
- ASCII-Encoding (entfernt Non-ASCII-Zeichen)
- Regex-basierte Sonderzeichen-Entfernung

### 2. Erweiterte Titel/Autor-Suche

**Location:** `src/dnb_api.py::query_dnb_by_title_author()`

**Suchstrategie (8 Stufen):**

#### Gruppe 1: Mit Autor (wenn vorhanden)
1. **Original Titel (Phrase) + Autor**
   - Query: `tit="Stahlbau Grundlagen" and per=MÃ¼ller`
   - HÃ¶chste PrÃ¤zision

2. **Original Titel (WÃ¶rter) + Autor**
   - Query: `tit=Stahlbau Grundlagen and per=MÃ¼ller`
   - Toleranter bzgl. Wortstellung

3. **Normalisierter Titel + Autor** âœ¨ NEU
   - Query: `tit=Uber Stahlwerkstoffe and per=Muller`
   - FÃ¼r Umlaute/Sonderzeichen-Probleme

4. **Truncated Titel + Autor** âœ¨ NEU
   - Query: `tit=Very long title about steel construction and and per=Schmidt`
   - FÃ¼r Titel >60 Zeichen

#### Gruppe 2: Nur Titel (Fallback)
5-8. Gleiche Strategien wie 1-4, aber ohne Autor

**Code-Beispiel:**
```python
result = query_dnb_by_title_author(
    title="Ãœber die PrÃ¼fung von StÃ¤hlen",
    author="MÃ¼ller, Hans"
)
# Versucht automatisch:
# 1. "Ãœber die PrÃ¼fung von StÃ¤hlen" + MÃ¼ller
# 2. Ãœber die PrÃ¼fung von StÃ¤hlen + MÃ¼ller
# 3. Uber die Prufung von Stahlen + Muller  â† Normalisiert!
# ... (insgesamt 8 Versuche)
```

### 3. Erweiterte Titel/Jahr-Suche

**Location:** `src/dnb_api.py::query_dnb_by_title_year()`

**Suchstrategie (8 Stufen):**

#### Gruppe 1: Exaktes Jahr
1-4. Wie bei Titel/Autor, aber mit exaktem Jahr
   - Query: `tit="..." and jhr=2010`

#### Gruppe 2: Jahr-Range Â±1
5-8. Gleiche Strategien mit Jahr-Toleranz
   - Query: `tit="..." and jhr>=2009 and jhr<=2011`

**Logging:**
- Erfolgreiche Matches via Normalisierung/Truncation werden geloggt:
```
INFO: TY match via normalized title: 'Uber die Prufung...'
INFO: Match via truncated title: 'Very long title about steel...'
```

### 4. Match-Validierung

**Location:** `src/fusion/fusion_engine.py::validate_dnb_match()`

**Funktion:**
```python
def validate_dnb_match(
    vdeh_data: Dict,
    dnb_data: Dict,
    min_title_similarity: float = 0.5,
    max_year_diff: int = 2,
    max_pages_diff: float = 0.2
) -> Tuple[bool, str]:
    """Validiert DNB-Match gegen False Positives."""
```

**Validierungskriterien:**

| Kriterium | Schwellwert | Aktion bei Ãœberschreitung |
|-----------|-------------|---------------------------|
| Titel-Similarity | < 50% | âŒ Reject |
| Jahr-Differenz | > 2 Jahre | âŒ Reject |
| Seiten-Differenz | > 20% | âŒ Reject |

**Validierungslogik:**
1. **Titel-Ã„hnlichkeit** (SequenceMatcher)
   - Vergleicht normalisierte Titel (lowercase, stripped)
   - 100% = identisch, 0% = komplett unterschiedlich

2. **Jahr-Validierung**
   - Erlaubt Â±2 Jahre Abweichung
   - BerÃ¼cksichtigt Neuauflagen/Reprints

3. **Seiten-Validierung**
   - Extrahiert Zahlen aus "350 S.", "XV, 250 p.", etc.
   - Berechnet prozentuale Differenz
   - Akzeptiert bis zu 20% Abweichung

**Beispiele:**

âœ… **Akzeptiert:**
```python
VDEH: {'title': 'Stahlbau Grundlagen', 'year': 2010, 'pages': '350 S.'}
DNB:  {'title': 'Stahlbau: Grundlagen', 'year': 2010, 'pages': '352 S.'}
â†’ Similarity: 97.4%, Jahr gleich, Pages: 0.6% diff
```

âŒ **Abgelehnt (Titel zu unterschiedlich):**
```python
VDEH: {'title': 'Korrosionsschutz', 'year': 2015, 'pages': '200 S.'}
DNB:  {'title': 'WerkstoffprÃ¼fung', 'year': 2015, 'pages': '205 S.'}
â†’ Similarity: 25.0% (< 50% Schwellwert)
```

âŒ **Abgelehnt (Jahr zu weit weg):**
```python
VDEH: {'title': 'Stahlwerkstoffe', 'year': 2010, 'pages': '300 S.'}
DNB:  {'title': 'Stahlwerkstoffe', 'year': 2015, 'pages': '305 S.'}
â†’ Jahr-Differenz: 5 Jahre (> 2 Jahre)
```

âŒ **Abgelehnt (Seitenzahl zu unterschiedlich):**
```python
VDEH: {'title': 'Werkstoffkunde', 'year': 2012, 'pages': '500 S.'}
DNB:  {'title': 'Werkstoffkunde', 'year': 2012, 'pages': '150 S.'}
â†’ Pages: 107.7% diff (> 20%)
```

## ğŸ“Š Erwartete Verbesserungen

### Vorher (v2.1.0):
| Methode | Erfolgsrate |
|---------|-------------|
| ISBN/ISSN | 54.1% |
| Titel/Autor | 23.8% |
| Titel/Jahr | ~15% (geschÃ¤tzt) |

### Nachher (v2.2.0 - erwartet):
| Methode | Erfolgsrate | Verbesserung |
|---------|-------------|--------------|
| ISBN/ISSN | ~60% | +5-6% |
| Titel/Autor | **35-40%** | **+11-16%** âœ¨ |
| Titel/Jahr | **25-30%** | **+10-15%** âœ¨ |

**Gesamtabdeckung:**
- **Vorher:** ~40% der Records mit DNB-Daten
- **Nachher:** **50-55%** (+10-15 Prozentpunkte)

### GrÃ¼nde fÃ¼r Verbesserung:

1. **Normalisierung** rettet ~5-10% der Queries
   - Umlaute-Probleme: "Ãœber" vs "Uber"
   - Sonderzeichen: "C++" vs "C Plus Plus"

2. **Truncation** rettet ~3-5% der Queries
   - Lange Titel werden korrekt abgeschnitten
   - DNB-API-Limits umgangen

3. **Validierung** verhindert ~2-5% False Positives
   - Falsche Matches werden erkannt
   - DatenqualitÃ¤t steigt

## ğŸ§ª Testing

**Test-Script:** `scripts/test_dnb_enhanced_search.py`

**AusfÃ¼hren:**
```bash
poetry run python scripts/test_dnb_enhanced_search.py
```

**Test-Abdeckung:**
- âœ… Normalisierung (5 Tests)
- âœ… Titel/Autor-Suche (3 Beispiele)
- âœ… Match-Validierung (4 Tests)
- âœ… Titel-Ã„hnlichkeit (5 Tests)

**Letzter Test-Lauf:** 13.12.2025 - **Alle Tests bestanden** âœ…

## ğŸ“ Nutzung in der Pipeline

### In Notebooks:

```python
# In 04_vdeh_data_enrichment.ipynb
from dnb_api import query_dnb_by_title_author, query_dnb_by_title_year

# Queries nutzen automatisch erweiterte Suchstrategie
result = query_dnb_by_title_author(
    title="Ãœber Stahlwerkstoffe",
    author="MÃ¼ller"
)
# â†’ Versucht automatisch 8 verschiedene Strategien
```

### In Fusion:

```python
# In 05_vdeh_data_fusion.ipynb
from fusion.fusion_engine import FusionEngine

# Validierung wird automatisch angewendet
engine = FusionEngine(ollama_client)
result = engine.merge_record(row)
# â†’ AI-Auswahl + automatische Validierung
```

## âš™ï¸ Konfiguration

### Validierungs-Schwellwerte anpassen:

```python
# In fusion_engine.py
is_valid, reason = FusionEngine.validate_dnb_match(
    vdeh_data,
    dnb_data,
    min_title_similarity=0.5,   # 50% Minimum (anpassbar)
    max_year_diff=2,            # Â±2 Jahre (anpassbar)
    max_pages_diff=0.2          # 20% Maximum (anpassbar)
)
```

### TY-Similarity-Threshold:

```python
# FÃ¼r Titel/Jahr-Matches
engine = FusionEngine(
    ollama_client,
    ty_similarity_threshold=0.7  # 70% Minimum (default)
)
```

## ğŸ” Monitoring & Debugging

### Logging aktivieren:

```python
import logging
logging.basicConfig(level=logging.INFO)

# Zeigt erfolgreiche Normalisierungs-/Truncation-Matches:
# INFO: Match via normalized title: 'Uber die Prufung...'
# INFO: TY match via truncated title: 'Very long title...'

# Zeigt abgelehnte Validierungen:
# WARNING: DNB id match rejected by validation: Titel zu unterschiedlich
```

### Statistiken tracken:

```python
# In Fusion-Prozess
rejected_count = (df_fused['dnb_match_rejected'] == True).sum()
rejection_reasons = df_fused[df_fused['dnb_match_rejected'] == True]['rejection_reason'].value_counts()

print(f"Abgelehnte Matches: {rejected_count}")
print(f"GrÃ¼nde:\n{rejection_reasons}")
```

## ğŸ“Œ Best Practices

### DO âœ…:
- Normalisierung fÃ¼r alle Text-basierten Queries nutzen
- Validierung bei allen DNB-Matches anwenden
- Logging aktivieren um erfolgreiche Rettungen zu tracken
- Test-Script bei Ã„nderungen ausfÃ¼hren

### DON'T âŒ:
- Validierungs-Schwellwerte zu niedrig setzen (False Positives!)
- Truncation-LÃ¤nge < 40 Zeichen (zu ungenau)
- Normalisierung Ã¼berspringen (Umlaute-Probleme!)

## ğŸš€ WeiterfÃ¼hrende Verbesserungen

MÃ¶gliche zukÃ¼nftige Erweiterungen:

1. **Fuzzy String Matching** (Levenshtein Distance)
   - FÃ¼r Tippfehler-Toleranz
   - Beispiel: "Korrosion" â‰ˆ "Korossion"

2. **Machine Learning-basierte Validierung**
   - Trainiert auf bestÃ¤tigten Matches
   - Erkennt komplexere Muster

3. **Caching-Layer**
   - Speichert erfolgreiche Queries
   - Vermeidet doppelte API-Calls

4. **A/B-Testing**
   - Vergleicht alte vs. neue Strategie
   - Misst echte Verbesserung

## ğŸ“š Referenzen

- **DNB SRU API:** https://www.dnb.de/DE/Professionell/Metadatendienste/Datenbezug/SRU/sru_node.html
- **Unicode Normalization:** https://docs.python.org/3/library/unicodedata.html
- **SequenceMatcher:** https://docs.python.org/3/library/difflib.html#difflib.SequenceMatcher

## ğŸ“„ Changelog

### v2.2.0 (2025-12-13)
- âœ¨ Text-Normalisierung implementiert
- âœ¨ Truncated Search fÃ¼r lange Titel
- âœ¨ Erweiterte Match-Validierung
- âœ… Umfassende Test-Suite
- ğŸ“ VollstÃ¤ndige Dokumentation

---

**Autor:** Sebastian Zug & Claude Sonnet 4.5
**Projekt:** Dual-Source Bibliothek Bestandsvergleich
**Lizenz:** MIT
