#!/usr/bin/env python3
"""Add gap-filling logic to fusion notebook."""

import json

# Read notebook
with open('notebooks/01_vdeh_preprocessing/05_vdeh_data_fusion.ipynb', 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Create new cell for gap filling
gap_filling_cell = {
    "cell_type": "code",
    "execution_count": None,
    "id": "gap_filling_logic",
    "metadata": {},
    "outputs": [],
    "source": [
        "# üìù GAP FILLING: Fehlende Felder aus DNB-Daten erg√§nzen\n",
        "print(\"\\nüìù === GAP FILLING ===\\n\")\n",
        "\n",
        "print(\"F√ºlle fehlende Metadaten aus DNB-Daten...\\n\")\n",
        "\n",
        "# Statistics BEFORE gap filling\n",
        "before_gap_filling = {\n",
        "    'isbn': df_enriched['isbn'].notna().sum(),\n",
        "    'issn': df_enriched['issn'].notna().sum() if 'issn' in df_enriched.columns else 0,\n",
        "}\n",
        "\n",
        "filled_count = {\n",
        "    'isbn': 0,\n",
        "    'issn': 0,\n",
        "    'authors': 0,\n",
        "    'year': 0,\n",
        "    'publisher': 0\n",
        "}\n",
        "\n",
        "# 1. ISBN Gap Filling\n",
        "# Priority: dnb_isbn_ta (from title/author search - finds new ISBNs) > dnb_isbn (from ISBN search - only duplicates)\n",
        "if 'dnb_isbn_ta' in df_enriched.columns:\n",
        "    # Records with no ISBN but DNB has one\n",
        "    no_isbn = df_enriched['isbn'].isna()\n",
        "    has_dnb_isbn_ta = df_enriched['dnb_isbn_ta'].notna()\n",
        "    \n",
        "    fill_isbn_mask = no_isbn & has_dnb_isbn_ta\n",
        "    filled_count['isbn'] = fill_isbn_mask.sum()\n",
        "    \n",
        "    if filled_count['isbn'] > 0:\n",
        "        df_enriched.loc[fill_isbn_mask, 'isbn'] = df_enriched.loc[fill_isbn_mask, 'dnb_isbn_ta']\n",
        "        # Mark source\n",
        "        if 'isbn_source' not in df_enriched.columns:\n",
        "            df_enriched['isbn_source'] = None\n",
        "        df_enriched.loc[fill_isbn_mask, 'isbn_source'] = 'dnb_title_author'\n",
        "        \n",
        "        print(f\"   ISBN: {filled_count['isbn']:,} neu gef√ºllt aus dnb_isbn_ta\")\n",
        "\n",
        "# 2. ISSN Gap Filling\n",
        "if 'issn' in df_enriched.columns and 'dnb_issn_ta' in df_enriched.columns:\n",
        "    no_issn = df_enriched['issn'].isna()\n",
        "    has_dnb_issn_ta = df_enriched['dnb_issn_ta'].notna()\n",
        "    \n",
        "    fill_issn_mask = no_issn & has_dnb_issn_ta\n",
        "    filled_count['issn'] = fill_issn_mask.sum()\n",
        "    \n",
        "    if filled_count['issn'] > 0:\n",
        "        df_enriched.loc[fill_issn_mask, 'issn'] = df_enriched.loc[fill_issn_mask, 'dnb_issn_ta']\n",
        "        # Mark source\n",
        "        if 'issn_source' not in df_enriched.columns:\n",
        "            df_enriched['issn_source'] = None\n",
        "        df_enriched.loc[fill_issn_mask, 'issn_source'] = 'dnb_title_author'\n",
        "        \n",
        "        print(f\"   ISSN: {filled_count['issn']:,} neu gef√ºllt aus dnb_issn_ta\")\n",
        "\n",
        "# 3. Authors Gap Filling (from DNB where fusion didn't already fill)\n",
        "# This fills authors that were NOT handled by fusion (e.g., records without fusion)\n",
        "no_authors = (df_enriched['authors_str'].isna() | (df_enriched['authors_str'] == ''))\n",
        "not_fused = df_enriched['fusion_authors_source'].isna()\n",
        "\n",
        "# Try dnb_authors_ta first\n",
        "if 'dnb_authors_ta' in df_enriched.columns:\n",
        "    has_dnb_authors_ta = (df_enriched['dnb_authors_ta'].notna() & (df_enriched['dnb_authors_ta'] != ''))\n",
        "    fill_authors_mask = no_authors & not_fused & has_dnb_authors_ta\n",
        "    \n",
        "    if fill_authors_mask.sum() > 0:\n",
        "        df_enriched.loc[fill_authors_mask, 'authors_str'] = df_enriched.loc[fill_authors_mask, 'dnb_authors_ta']\n",
        "        df_enriched.loc[fill_authors_mask, 'fusion_authors_source'] = 'dnb_title_author_gap_fill'\n",
        "        filled_count['authors'] += fill_authors_mask.sum()\n",
        "\n",
        "# Then try dnb_authors\n",
        "if 'dnb_authors' in df_enriched.columns:\n",
        "    no_authors = (df_enriched['authors_str'].isna() | (df_enriched['authors_str'] == ''))\n",
        "    not_fused = df_enriched['fusion_authors_source'].isna()\n",
        "    has_dnb_authors = (df_enriched['dnb_authors'].notna() & (df_enriched['dnb_authors'] != ''))\n",
        "    fill_authors_mask = no_authors & not_fused & has_dnb_authors\n",
        "    \n",
        "    if fill_authors_mask.sum() > 0:\n",
        "        df_enriched.loc[fill_authors_mask, 'authors_str'] = df_enriched.loc[fill_authors_mask, 'dnb_authors']\n",
        "        df_enriched.loc[fill_authors_mask, 'fusion_authors_source'] = 'dnb_id_gap_fill'\n",
        "        filled_count['authors'] += fill_authors_mask.sum()\n",
        "\n",
        "if filled_count['authors'] > 0:\n",
        "    print(f\"   Authors: {filled_count['authors']:,} neu gef√ºllt aus DNB\")\n",
        "\n",
        "# 4. Year Gap Filling\n",
        "no_year = df_enriched['year'].isna()\n",
        "not_fused = df_enriched['fusion_year_source'].isna()\n",
        "\n",
        "# Try dnb_year_ta first\n",
        "if 'dnb_year_ta' in df_enriched.columns:\n",
        "    has_dnb_year_ta = df_enriched['dnb_year_ta'].notna()\n",
        "    fill_year_mask = no_year & not_fused & has_dnb_year_ta\n",
        "    \n",
        "    if fill_year_mask.sum() > 0:\n",
        "        df_enriched.loc[fill_year_mask, 'year'] = df_enriched.loc[fill_year_mask, 'dnb_year_ta']\n",
        "        df_enriched.loc[fill_year_mask, 'fusion_year_source'] = 'dnb_title_author_gap_fill'\n",
        "        filled_count['year'] += fill_year_mask.sum()\n",
        "\n",
        "# Then try dnb_year\n",
        "if 'dnb_year' in df_enriched.columns:\n",
        "    no_year = df_enriched['year'].isna()\n",
        "    not_fused = df_enriched['fusion_year_source'].isna()\n",
        "    has_dnb_year = df_enriched['dnb_year'].notna()\n",
        "    fill_year_mask = no_year & not_fused & has_dnb_year\n",
        "    \n",
        "    if fill_year_mask.sum() > 0:\n",
        "        df_enriched.loc[fill_year_mask, 'year'] = df_enriched.loc[fill_year_mask, 'dnb_year']\n",
        "        df_enriched.loc[fill_year_mask, 'fusion_year_source'] = 'dnb_id_gap_fill'\n",
        "        filled_count['year'] += fill_year_mask.sum()\n",
        "\n",
        "if filled_count['year'] > 0:\n",
        "    print(f\"   Year: {filled_count['year']:,} neu gef√ºllt aus DNB\")\n",
        "\n",
        "# 5. Publisher Gap Filling\n",
        "no_publisher = df_enriched['publisher'].isna()\n",
        "not_fused = df_enriched['fusion_publisher_source'].isna()\n",
        "\n",
        "# Try dnb_publisher_ta first\n",
        "if 'dnb_publisher_ta' in df_enriched.columns:\n",
        "    has_dnb_pub_ta = df_enriched['dnb_publisher_ta'].notna()\n",
        "    fill_pub_mask = no_publisher & not_fused & has_dnb_pub_ta\n",
        "    \n",
        "    if fill_pub_mask.sum() > 0:\n",
        "        df_enriched.loc[fill_pub_mask, 'publisher'] = df_enriched.loc[fill_pub_mask, 'dnb_publisher_ta']\n",
        "        df_enriched.loc[fill_pub_mask, 'fusion_publisher_source'] = 'dnb_title_author_gap_fill'\n",
        "        filled_count['publisher'] += fill_pub_mask.sum()\n",
        "\n",
        "# Then try dnb_publisher\n",
        "if 'dnb_publisher' in df_enriched.columns:\n",
        "    no_publisher = df_enriched['publisher'].isna()\n",
        "    not_fused = df_enriched['fusion_publisher_source'].isna()\n",
        "    has_dnb_pub = df_enriched['dnb_publisher'].notna()\n",
        "    fill_pub_mask = no_publisher & not_fused & has_dnb_pub\n",
        "    \n",
        "    if fill_pub_mask.sum() > 0:\n",
        "        df_enriched.loc[fill_pub_mask, 'publisher'] = df_enriched.loc[fill_pub_mask, 'dnb_publisher']\n",
        "        df_enriched.loc[fill_pub_mask, 'fusion_publisher_source'] = 'dnb_id_gap_fill'\n",
        "        filled_count['publisher'] += fill_pub_mask.sum()\n",
        "\n",
        "if filled_count['publisher'] > 0:\n",
        "    print(f\"   Publisher: {filled_count['publisher']:,} neu gef√ºllt aus DNB\")\n",
        "\n",
        "# Statistics AFTER gap filling\n",
        "after_gap_filling = {\n",
        "    'isbn': df_enriched['isbn'].notna().sum(),\n",
        "    'issn': df_enriched['issn'].notna().sum() if 'issn' in df_enriched.columns else 0,\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Gap Filling Zusammenfassung:\")\n",
        "total_filled = sum(filled_count.values())\n",
        "print(f\"   Gesamt neu gef√ºllt: {total_filled:,} Felder\")\n",
        "print(f\"   ISBN: {before_gap_filling['isbn']:,} ‚Üí {after_gap_filling['isbn']:,} (+{filled_count['isbn']:,})\")\n",
        "print(f\"   ISSN: {before_gap_filling['issn']:,} ‚Üí {after_gap_filling['issn']:,} (+{filled_count['issn']:,})\")\n",
        "\n",
        "print(\"\\n‚úÖ Gap Filling abgeschlossen\")\n"
    ]
}

# Find the index to insert (before the last cell which is the save cell)
# Insert after "abc12345" (fusion statistics) and before "def45678" (final save)
insert_index = None
for i, cell in enumerate(nb['cells']):
    if cell.get('id') == 'abc12345':
        insert_index = i + 1
        break

if insert_index is None:
    print("‚ùå Could not find insertion point")
    exit(1)

# Insert the new cell
nb['cells'].insert(insert_index, gap_filling_cell)

# Write updated notebook
with open('notebooks/01_vdeh_preprocessing/05_vdeh_data_fusion.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print("‚úÖ Gap filling cell added to fusion notebook!")
print(f"   Inserted at position {insert_index} (after fusion statistics)")
